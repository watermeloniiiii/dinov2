I20240604 11:35:41 712955 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240604 11:35:41 712955 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/dinov2/dinov2/configs/train/vitl16_short.yaml
eval: 
eval_only: False
no_resume: True
opts: ['true', '--output-dir', '/NAS6/Members/linchenxi/projects/DINOV2', 'train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
I20240604 11:35:41 712955 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240604 11:35:41 712955 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500
'true': null
--output-dir: null
/NAS6/Members/linchenxi/projects/DINOV2: null

I20240604 11:35:41 712955 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 11:35:45 712955 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240604 11:35:48 712955 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240604 11:35:49 712955 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240604 11:35:49 712955 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0): BlockChunk(
          (0-5): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (1): BlockChunk(
          (0-5): 6 x Identity()
          (6-11): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (2): BlockChunk(
          (0-11): 12 x Identity()
          (12-17): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (3): BlockChunk(
          (0-17): 18 x Identity()
          (18-23): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
      )
      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
    (dino_head): DINOHead(
      (mlp): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2048, out_features=2048, bias=True)
        (3): GELU(approximate='none')
        (4): Linear(in_features=2048, out_features=256, bias=True)
      )
      (last_layer): Linear(in_features=256, out_features=65536, bias=False)
    )
  )
  (teacher): ModuleDict(
    (backbone): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0): BlockChunk(
          (0-5): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (1): BlockChunk(
          (0-5): 6 x Identity()
          (6-11): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (2): BlockChunk(
          (0-11): 12 x Identity()
          (12-17): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (3): BlockChunk(
          (0-17): 18 x Identity()
          (18-23): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
      )
      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
    (dino_head): DINOHead(
      (mlp): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2048, out_features=2048, bias=True)
        (3): GELU(approximate='none')
        (4): Linear(in_features=2048, out_features=256, bias=True)
      )
      (last_layer): Linear(in_features=256, out_features=65536, bias=False)
    )
  )
)
I20240604 11:35:49 712955 dinov2 param_groups.py:54] chunked fsdp
I20240604 11:35:49 712955 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:35:49 712955 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 11:35:50 712955 dinov2 param_groups.py:64] else code branch
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:35:50 712955 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 11:35:50 712955 dinov2 train.py:102] Schedulers ready.
I20240604 11:36:00 712955 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240604 11:36:26 713531 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240604 11:36:26 713531 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/dinov2/dinov2/configs/train/vitl16_short.yaml
eval: 
eval_only: False
no_resume: True
opts: ['true', '--output-dir', '/NAS6/Members/linchenxi/projects/DINOV2', 'train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
I20240604 11:36:26 713531 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240604 11:36:26 713531 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500
'true': null
--output-dir: null
/NAS6/Members/linchenxi/projects/DINOV2: null

I20240604 11:36:26 713531 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 11:36:30 713531 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240604 11:36:33 713531 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240604 11:36:34 713531 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240604 11:36:35 713531 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0): BlockChunk(
          (0-5): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (1): BlockChunk(
          (0-5): 6 x Identity()
          (6-11): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (2): BlockChunk(
          (0-11): 12 x Identity()
          (12-17): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (3): BlockChunk(
          (0-17): 18 x Identity()
          (18-23): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
      )
      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
    (dino_head): DINOHead(
      (mlp): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2048, out_features=2048, bias=True)
        (3): GELU(approximate='none')
        (4): Linear(in_features=2048, out_features=256, bias=True)
      )
      (last_layer): Linear(in_features=256, out_features=65536, bias=False)
    )
  )
  (teacher): ModuleDict(
    (backbone): DinoVisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (blocks): ModuleList(
        (0): BlockChunk(
          (0-5): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (1): BlockChunk(
          (0-5): 6 x Identity()
          (6-11): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (2): BlockChunk(
          (0-11): 12 x Identity()
          (12-17): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (3): BlockChunk(
          (0-17): 18 x Identity()
          (18-23): 6 x NestedTensorBlock(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=1024, out_features=3072, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
      )
      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (head): Identity()
    )
    (dino_head): DINOHead(
      (mlp): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=2048, out_features=2048, bias=True)
        (3): GELU(approximate='none')
        (4): Linear(in_features=2048, out_features=256, bias=True)
      )
      (last_layer): Linear(in_features=256, out_features=65536, bias=False)
    )
  )
)
I20240604 11:36:35 713531 dinov2 param_groups.py:54] chunked fsdp
I20240604 11:36:35 713531 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 11:36:35 713531 dinov2 param_groups.py:64] else code branch
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 11:36:35 713531 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 11:36:35 713531 dinov2 train.py:102] Schedulers ready.
I20240604 11:39:48 713531 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240604 12:47:05 733107 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240604 12:47:05 733107 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/dinov2/dinov2/configs/train/vitl16_short.yaml
eval: 
eval_only: False
no_resume: True
opts: ['true', '--output-dir', '/NAS6/Members/linchenxi/projects/DINOV2', 'train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
I20240604 12:47:05 733107 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240604 12:47:05 733107 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500
'true': null
--output-dir: null
/NAS6/Members/linchenxi/projects/DINOV2: null

I20240604 12:47:05 733107 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 12:47:09 733107 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240604 12:47:13 733107 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240604 12:47:14 733107 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240604 12:47:14 733107 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240604 12:47:15 733107 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240604 12:47:15 733107 dinov2 param_groups.py:54] chunked fsdp
I20240604 12:47:15 733107 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 12:47:15 733107 dinov2 param_groups.py:64] else code branch
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:47:15 733107 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 12:47:15 733107 dinov2 train.py:102] Schedulers ready.
I20240604 12:47:15 733107 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240604 12:47:15 733107 dinov2 augmentations.py:34] ###################################
I20240604 12:47:15 733107 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240604 12:47:15 733107 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240604 12:47:15 733107 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240604 12:47:15 733107 dinov2 augmentations.py:38] local_crops_number: 8
I20240604 12:47:15 733107 dinov2 augmentations.py:39] global_crops_size: 224
I20240604 12:47:15 733107 dinov2 augmentations.py:40] local_crops_size: 96
I20240604 12:47:15 733107 dinov2 augmentations.py:41] ###################################
I20240604 12:47:15 733107 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN"
I20240604 12:49:00 733624 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240604 12:49:00 733624 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/dinov2/dinov2/configs/train/vitl16_short.yaml
eval: 
eval_only: False
no_resume: True
opts: ['true', '--output-dir', '/NAS6/Members/linchenxi/projects/DINOV2', 'train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
I20240604 12:49:00 733624 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240604 12:49:00 733624 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500
'true': null
--output-dir: null
/NAS6/Members/linchenxi/projects/DINOV2: null

I20240604 12:49:00 733624 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 12:49:04 733624 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240604 12:49:07 733624 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240604 12:49:08 733624 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240604 12:49:09 733624 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240604 12:49:09 733624 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240604 12:49:09 733624 dinov2 param_groups.py:54] chunked fsdp
I20240604 12:49:09 733624 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:09 733624 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 12:49:10 733624 dinov2 param_groups.py:64] else code branch
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240604 12:49:10 733624 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240604 12:49:10 733624 dinov2 train.py:102] Schedulers ready.
I20240604 12:49:22 733624 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240604 12:50:23 733624 dinov2 augmentations.py:34] ###################################
I20240604 12:50:23 733624 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240604 12:50:23 733624 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240604 12:50:23 733624 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240604 12:50:23 733624 dinov2 augmentations.py:38] local_crops_number: 8
I20240604 12:50:23 733624 dinov2 augmentations.py:39] global_crops_size: 224
I20240604 12:50:23 733624 dinov2 augmentations.py:40] local_crops_size: 96
I20240604 12:50:23 733624 dinov2 augmentations.py:41] ###################################
I20240604 12:50:56 733624 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN"
I20240613 10:28:17 3771778 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 10:28:17 3771778 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vitg14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: https://dl.fbaipublicfiles.com/dinov2/dinov2_vitg14/dinov2_vitg14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 10:28:17 3771778 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 10:28:17 3771778 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_giant2
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 10:28:17 3771778 dinov2 vision_transformer.py:129] using SwiGLU layer as FFN
I20240613 10:29:20 3771778 dinov2 utils.py:33] Pretrained weights found at https://dl.fbaipublicfiles.com/dinov2/dinov2_vitg14/dinov2_vitg14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 10:46:23 3780438 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 10:46:23 3780438 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vitg14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 10:46:23 3780438 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 10:46:24 3780438 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_giant2
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: swiglufused
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 10:46:24 3780438 dinov2 vision_transformer.py:129] using SwiGLU layer as FFN
I20240613 10:48:48 3781335 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 10:48:48 3781335 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 10:48:48 3781335 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 10:48:48 3781335 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 10:48:48 3781335 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 10:48:48 3781335 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 10:56:18 3784709 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 10:56:18 3784709 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 10:56:18 3784709 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 10:56:18 3784709 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 10:56:19 3784709 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 10:56:19 3784709 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 11:04:14 3784709 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:04:14 3784709 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 11:05:53 3784709 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 11:07:28 3789122 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 11:07:28 3789122 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 11:07:28 3789122 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 11:07:28 3789122 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 11:07:28 3789122 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 11:07:28 3789122 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 11:07:43 3789398 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 11:07:43 3789398 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 11:07:43 3789398 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 11:07:43 3789398 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 11:07:43 3789398 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 11:07:43 3789398 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 11:07:44 3789398 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:07:44 3789398 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 11:07:47 3789398 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 11:07:47 3789398 dinov2 loaders.py:122] sampler: sharded infinite
I20240613 11:07:47 3789398 dinov2 loaders.py:206] using PyTorch data loader
I20240613 11:07:47 3789398 dinov2 loaders.py:221] infinite data loader
I20240613 11:07:47 3789398 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:07:47 3789398 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 11:07:47 3789398 dinov2 loaders.py:147] sampler: distributed
I20240613 11:07:47 3789398 dinov2 loaders.py:206] using PyTorch data loader
I20240613 11:07:47 3789398 dinov2 loaders.py:219] # of batches: 10,010
I20240613 11:07:47 3789398 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 11:07:47 3789398 dinov2 linear.py:338] Starting training from iteration 0
I20240613 11:08:00 3789398 dinov2 helpers.py:102] Training  [    0/12500]  eta: 1 day, 21:42:10  loss: 341.1960 (341.1960)  lr: 0.0000 (0.0000)  time: 13.162427  data: 12.287056  max mem: 1270
I20240613 11:08:00 3789398 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20240613 11:08:01 3789398 dinov2 helpers.py:102] Training  [   10/12500]  eta: 4:36:57  loss: 330.6245 (335.9103)  lr: 0.0000 (0.0000)  time: 1.330440  data: 1.118725  max mem: 1750
I20240613 11:08:03 3789398 dinov2 helpers.py:102] Training  [   20/12500]  eta: 2:38:10  loss: 330.6245 (330.0078)  lr: 0.0000 (0.0000)  time: 0.140372  data: 0.001881  max mem: 1750
I20240613 11:08:04 3789398 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:55:59  loss: 318.2028 (323.3990)  lr: 0.0000 (0.0000)  time: 0.133347  data: 0.002011  max mem: 1750
I20240613 11:08:05 3789398 dinov2 helpers.py:102] Training  [   40/12500]  eta: 1:34:20  loss: 318.2028 (317.9932)  lr: 0.0000 (0.0000)  time: 0.132822  data: 0.002163  max mem: 1750
I20240613 11:08:07 3789398 dinov2 helpers.py:102] Training  [   50/12500]  eta: 1:21:07  loss: 303.5725 (313.2203)  lr: 0.0000 (0.0000)  time: 0.131774  data: 0.002038  max mem: 1750
I20240613 11:08:08 3789398 dinov2 helpers.py:102] Training  [   60/12500]  eta: 1:12:15  loss: 303.5725 (309.3869)  lr: 0.0000 (0.0000)  time: 0.131746  data: 0.002042  max mem: 1750
I20240613 11:08:09 3789398 dinov2 helpers.py:102] Training  [   70/12500]  eta: 1:05:19  loss: 296.3700 (305.1055)  lr: 0.0000 (0.0000)  time: 0.122611  data: 0.002064  max mem: 1750
I20240613 11:08:11 3789398 dinov2 helpers.py:102] Training  [   80/12500]  eta: 1:01:43  loss: 296.3700 (300.8369)  lr: 0.0000 (0.0000)  time: 0.144633  data: 0.051314  max mem: 1750
I20240613 11:08:12 3789398 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:57:54  loss: 289.3560 (297.0512)  lr: 0.0000 (0.0000)  time: 0.154540  data: 0.052072  max mem: 1750
I20240613 11:08:14 3789398 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:54:47  loss: 289.3560 (293.5453)  lr: 0.0000 (0.0000)  time: 0.131308  data: 0.002683  max mem: 1750
I20240613 11:08:15 3789398 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:52:51  loss: 286.3863 (290.5227)  lr: 0.0000 (0.0000)  time: 0.146785  data: 0.028780  max mem: 1750
I20240613 11:08:17 3789398 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:50:42  loss: 286.3863 (287.3819)  lr: 0.0000 (0.0000)  time: 0.147872  data: 0.032573  max mem: 1750
I20240613 11:08:18 3789398 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:48:53  loss: 275.1359 (284.5425)  lr: 0.0000 (0.0000)  time: 0.132321  data: 0.005656  max mem: 1750
I20240613 11:08:19 3789398 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:47:19  loss: 275.1359 (282.6986)  lr: 0.0000 (0.0000)  time: 0.132682  data: 0.001888  max mem: 1750
I20240613 11:08:21 3789398 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:45:57  loss: 266.6883 (280.4336)  lr: 0.0000 (0.0000)  time: 0.132404  data: 0.002045  max mem: 1750
I20240613 11:08:22 3789398 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:44:45  loss: 266.6883 (278.4005)  lr: 0.0000 (0.0000)  time: 0.132338  data: 0.002135  max mem: 1750
I20240613 11:08:23 3789398 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:43:42  loss: 262.9794 (276.7328)  lr: 0.0000 (0.0000)  time: 0.132700  data: 0.002076  max mem: 1750
I20240613 11:08:25 3789398 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:42:45  loss: 262.9794 (274.5143)  lr: 0.0000 (0.0000)  time: 0.132584  data: 0.001901  max mem: 1750
I20240613 11:08:26 3789398 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:41:54  loss: 258.4866 (272.7591)  lr: 0.0000 (0.0000)  time: 0.132594  data: 0.002126  max mem: 1750
I20240613 11:08:27 3789398 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:41:08  loss: 257.2745 (271.0308)  lr: 0.0000 (0.0000)  time: 0.132677  data: 0.002109  max mem: 1750
I20240613 11:08:28 3789398 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:40:14  loss: 256.8835 (269.2375)  lr: 0.0000 (0.0000)  time: 0.122061  data: 0.002011  max mem: 1750
I20240613 11:08:30 3789398 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:39:37  loss: 249.6913 (267.6093)  lr: 0.0000 (0.0000)  time: 0.122317  data: 0.002130  max mem: 1750
I20240613 11:08:31 3789398 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:39:03  loss: 248.3826 (266.0820)  lr: 0.0000 (0.0000)  time: 0.133106  data: 0.001787  max mem: 1750
I20240613 11:08:32 3789398 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:38:31  loss: 247.6314 (264.7450)  lr: 0.0000 (0.0000)  time: 0.132878  data: 0.001616  max mem: 1750
I20240613 11:08:34 3789398 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:38:03  loss: 246.4586 (263.3234)  lr: 0.0000 (0.0000)  time: 0.132942  data: 0.001684  max mem: 1750
I20240613 11:08:35 3789398 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:37:34  loss: 245.8706 (261.9655)  lr: 0.0000 (0.0000)  time: 0.131796  data: 0.001757  max mem: 1750
I20240613 11:08:36 3789398 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:37:09  loss: 239.4108 (260.6985)  lr: 0.0000 (0.0000)  time: 0.131495  data: 0.001873  max mem: 1750
I20240613 11:08:38 3789398 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:36:45  loss: 236.4653 (259.5014)  lr: 0.0000 (0.0000)  time: 0.132108  data: 0.001912  max mem: 1750
I20240613 11:08:39 3789398 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:36:23  loss: 236.4653 (258.9126)  lr: 0.0000 (0.0000)  time: 0.131555  data: 0.001836  max mem: 1750
I20240613 11:08:40 3789398 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:35:54  loss: 234.5804 (257.6936)  lr: 0.0000 (0.0000)  time: 0.121335  data: 0.001724  max mem: 1750
I20240613 11:08:42 3789398 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:36:05  loss: 232.6558 (256.6753)  lr: 0.0000 (0.0000)  time: 0.160336  data: 0.058949  max mem: 1750
I20240613 11:08:44 3789398 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:35:49  loss: 231.7879 (255.3949)  lr: 0.0000 (0.0000)  time: 0.175116  data: 0.065452  max mem: 1750
I20240613 11:08:45 3789398 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:35:23  loss: 231.5778 (254.3616)  lr: 0.0000 (0.0000)  time: 0.125915  data: 0.008374  max mem: 1750
I20240613 11:08:46 3789398 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:35:04  loss: 230.9550 (253.4001)  lr: 0.0000 (0.0000)  time: 0.118256  data: 0.001905  max mem: 1750
I20240613 11:08:47 3789398 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:34:49  loss: 229.3464 (252.7320)  lr: 0.0000 (0.0000)  time: 0.129544  data: 0.010727  max mem: 1750
I20240613 11:08:49 3789398 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:34:34  loss: 227.7848 (251.8582)  lr: 0.0000 (0.0000)  time: 0.133095  data: 0.010874  max mem: 1750
I20240613 11:08:50 3789398 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:34:20  loss: 226.6600 (251.1781)  lr: 0.0000 (0.0000)  time: 0.132876  data: 0.001875  max mem: 1750
I20240613 11:08:51 3789398 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:34:06  loss: 226.4888 (250.3019)  lr: 0.0000 (0.0000)  time: 0.133067  data: 0.001757  max mem: 1750
I20240613 11:08:53 3789398 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:33:53  loss: 226.0141 (249.3999)  lr: 0.0000 (0.0000)  time: 0.132654  data: 0.001704  max mem: 1750
I20240613 11:08:54 3789398 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:33:41  loss: 225.9834 (248.4722)  lr: 0.0000 (0.0000)  time: 0.132833  data: 0.001891  max mem: 1750
I20240613 11:08:55 3789398 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:33:29  loss: 225.1083 (247.5073)  lr: 0.0000 (0.0000)  time: 0.133087  data: 0.001995  max mem: 1750
I20240613 11:08:57 3789398 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:33:18  loss: 221.1229 (246.7731)  lr: 0.0000 (0.0000)  time: 0.132729  data: 0.001865  max mem: 1750
I20240613 11:08:58 3789398 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:33:07  loss: 220.7091 (245.8731)  lr: 0.0000 (0.0000)  time: 0.132761  data: 0.001915  max mem: 1750
I20240613 11:08:59 3789398 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:32:57  loss: 220.4012 (244.9751)  lr: 0.0000 (0.0000)  time: 0.132696  data: 0.001892  max mem: 1750
I20240613 11:09:01 3789398 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:32:47  loss: 220.2654 (244.1875)  lr: 0.0000 (0.0000)  time: 0.132736  data: 0.001815  max mem: 1750
I20240613 11:09:02 3789398 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:32:32  loss: 217.0096 (243.4308)  lr: 0.0000 (0.0000)  time: 0.122037  data: 0.002213  max mem: 1750
I20240613 11:09:03 3789398 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:32:23  loss: 215.9395 (242.8541)  lr: 0.0000 (0.0000)  time: 0.121818  data: 0.002301  max mem: 1750
I20240613 11:09:04 3789398 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:32:14  loss: 215.7518 (242.1480)  lr: 0.0000 (0.0000)  time: 0.132366  data: 0.001877  max mem: 1750
I20240613 11:09:06 3789398 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:32:05  loss: 214.4220 (241.5598)  lr: 0.0000 (0.0000)  time: 0.132246  data: 0.001878  max mem: 1750
I20240613 11:09:07 3789398 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:31:57  loss: 214.2212 (240.8434)  lr: 0.0000 (0.0000)  time: 0.132443  data: 0.001972  max mem: 1750
I20240613 11:09:08 3789398 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:31:49  loss: 214.2212 (240.3776)  lr: 0.0000 (0.0000)  time: 0.132139  data: 0.001834  max mem: 1750
I20240613 11:09:10 3789398 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:31:41  loss: 212.7409 (239.7439)  lr: 0.0000 (0.0000)  time: 0.132203  data: 0.001905  max mem: 1750
I20240613 11:09:11 3789398 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:31:33  loss: 211.3612 (239.1224)  lr: 0.0000 (0.0000)  time: 0.132653  data: 0.002125  max mem: 1750
I20240613 11:09:12 3789398 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:31:19  loss: 208.7454 (238.4025)  lr: 0.0000 (0.0000)  time: 0.116662  data: 0.002211  max mem: 1750
I20240613 11:09:14 3789398 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:31:34  loss: 208.6199 (237.8519)  lr: 0.0000 (0.0000)  time: 0.166192  data: 0.067445  max mem: 1750
I20240613 11:09:16 3789398 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:31:27  loss: 208.6199 (237.3680)  lr: 0.0000 (0.0000)  time: 0.182240  data: 0.067396  max mem: 1750
I20240613 11:09:17 3789398 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:31:18  loss: 208.2528 (236.8102)  lr: 0.0000 (0.0000)  time: 0.129374  data: 0.001950  max mem: 1750
I20240613 11:09:18 3789398 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:31:09  loss: 207.9464 (236.1365)  lr: 0.0000 (0.0000)  time: 0.122899  data: 0.001792  max mem: 1750
I20240613 11:09:19 3789398 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:31:00  loss: 207.5694 (235.5761)  lr: 0.0000 (0.0000)  time: 0.119531  data: 0.005925  max mem: 1750
I20240613 11:09:21 3789398 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:30:54  loss: 207.1716 (235.0679)  lr: 0.0000 (0.0000)  time: 0.125883  data: 0.006118  max mem: 1750
I20240613 11:09:22 3789398 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:30:48  loss: 206.7938 (234.5389)  lr: 0.0000 (0.0000)  time: 0.132715  data: 0.002155  max mem: 1750
I20240613 11:09:23 3789398 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:30:42  loss: 206.1828 (234.0731)  lr: 0.0000 (0.0000)  time: 0.132988  data: 0.001968  max mem: 1750
I20240613 11:09:25 3789398 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:30:36  loss: 205.4651 (233.4577)  lr: 0.0000 (0.0000)  time: 0.133539  data: 0.001852  max mem: 1750
I20240613 11:09:26 3789398 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:30:31  loss: 205.1892 (232.8485)  lr: 0.0000 (0.0000)  time: 0.133448  data: 0.001988  max mem: 1750
I20240613 11:09:27 3789398 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:30:25  loss: 205.1892 (232.4624)  lr: 0.0000 (0.0000)  time: 0.133418  data: 0.002147  max mem: 1750
I20240613 11:09:29 3789398 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:30:20  loss: 205.0199 (231.8822)  lr: 0.0000 (0.0000)  time: 0.133428  data: 0.002078  max mem: 1750
I20240613 11:09:30 3789398 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:30:15  loss: 205.0127 (231.3377)  lr: 0.0000 (0.0000)  time: 0.132824  data: 0.002153  max mem: 1750
I20240613 11:09:31 3789398 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:30:10  loss: 204.5745 (230.8788)  lr: 0.0000 (0.0000)  time: 0.133058  data: 0.002279  max mem: 1750
I20240613 11:09:33 3789398 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:30:05  loss: 202.5116 (230.3935)  lr: 0.0000 (0.0000)  time: 0.133254  data: 0.002097  max mem: 1750
I20240613 11:09:34 3789398 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:30:00  loss: 202.5116 (230.0249)  lr: 0.0000 (0.0000)  time: 0.133082  data: 0.001961  max mem: 1750
I20240613 11:09:35 3789398 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:29:53  loss: 202.2725 (229.5490)  lr: 0.0000 (0.0000)  time: 0.125460  data: 0.002082  max mem: 1750
I20240613 11:09:36 3789398 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:29:47  loss: 199.6721 (228.9879)  lr: 0.0000 (0.0000)  time: 0.121703  data: 0.002035  max mem: 1750
I20240613 11:09:38 3789398 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:29:42  loss: 199.6721 (228.6020)  lr: 0.0000 (0.0000)  time: 0.129078  data: 0.001797  max mem: 1750
I20240613 11:09:39 3789398 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:29:38  loss: 200.4312 (228.3051)  lr: 0.0000 (0.0000)  time: 0.132256  data: 0.001789  max mem: 1750
I20240613 11:09:40 3789398 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:29:33  loss: 199.6721 (227.7035)  lr: 0.0000 (0.0000)  time: 0.132484  data: 0.002030  max mem: 1750
I20240613 11:09:42 3789398 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:29:29  loss: 199.6721 (227.3713)  lr: 0.0000 (0.0000)  time: 0.133133  data: 0.002064  max mem: 1750
I20240613 11:09:43 3789398 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:29:23  loss: 197.0637 (226.8303)  lr: 0.0000 (0.0000)  time: 0.128635  data: 0.001988  max mem: 1750
I20240613 11:09:45 3789398 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:29:28  loss: 196.9091 (226.3299)  lr: 0.0000 (0.0000)  time: 0.158257  data: 0.059629  max mem: 1750
I20240613 11:09:46 3789398 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:29:28  loss: 195.7620 (225.9180)  lr: 0.0000 (0.0000)  time: 0.176659  data: 0.076121  max mem: 1750
I20240613 11:09:48 3789398 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:29:24  loss: 194.8568 (225.4848)  lr: 0.0000 (0.0000)  time: 0.146724  data: 0.018518  max mem: 1750
I20240613 11:09:49 3789398 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:29:18  loss: 194.8568 (225.2179)  lr: 0.0000 (0.0000)  time: 0.125126  data: 0.002047  max mem: 1750
I20240613 11:09:50 3789398 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:29:17  loss: 194.6922 (224.7585)  lr: 0.0000 (0.0000)  time: 0.135038  data: 0.015438  max mem: 1750
I20240613 11:09:52 3789398 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:29:12  loss: 194.8568 (224.4415)  lr: 0.0000 (0.0000)  time: 0.142121  data: 0.016803  max mem: 1750
I20240613 11:09:53 3789398 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:29:07  loss: 195.2437 (224.0980)  lr: 0.0000 (0.0000)  time: 0.125338  data: 0.008911  max mem: 1750
I20240613 11:09:54 3789398 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:29:03  loss: 194.8568 (223.6485)  lr: 0.0000 (0.0000)  time: 0.125643  data: 0.007659  max mem: 1750
I20240613 11:09:56 3789398 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:28:59  loss: 194.8568 (223.1487)  lr: 0.0000 (0.0000)  time: 0.132707  data: 0.002211  max mem: 1750
I20240613 11:09:57 3789398 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:28:55  loss: 195.2437 (222.8411)  lr: 0.0000 (0.0000)  time: 0.132766  data: 0.002017  max mem: 1750
I20240613 11:09:58 3789398 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:28:52  loss: 193.3774 (222.3876)  lr: 0.0000 (0.0000)  time: 0.133129  data: 0.001853  max mem: 1750
I20240613 11:10:00 3789398 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:28:48  loss: 190.8332 (221.9972)  lr: 0.0000 (0.0000)  time: 0.133352  data: 0.001773  max mem: 1750
I20240613 11:10:01 3789398 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:28:45  loss: 190.8332 (221.6782)  lr: 0.0000 (0.0000)  time: 0.133322  data: 0.001866  max mem: 1750
I20240613 11:10:02 3789398 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:28:41  loss: 190.8332 (221.3630)  lr: 0.0000 (0.0000)  time: 0.133580  data: 0.002124  max mem: 1750
I20240613 11:10:04 3789398 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:28:38  loss: 190.8332 (220.9974)  lr: 0.0000 (0.0000)  time: 0.133629  data: 0.002232  max mem: 1750
I20240613 11:10:05 3789398 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:28:34  loss: 188.1487 (220.6480)  lr: 0.0000 (0.0000)  time: 0.132611  data: 0.002316  max mem: 1750
I20240613 11:10:06 3789398 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:28:31  loss: 187.3669 (220.2198)  lr: 0.0000 (0.0000)  time: 0.132339  data: 0.002209  max mem: 1750
I20240613 11:10:08 3789398 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:28:27  loss: 187.3669 (219.8118)  lr: 0.0000 (0.0000)  time: 0.132300  data: 0.002043  max mem: 1750
I20240613 11:10:09 3789398 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:28:23  loss: 187.3669 (219.5088)  lr: 0.0000 (0.0000)  time: 0.128925  data: 0.002070  max mem: 1750
I20240613 11:10:10 3789398 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:28:18  loss: 187.3669 (219.1536)  lr: 0.0000 (0.0000)  time: 0.119769  data: 0.002128  max mem: 1750
I20240613 11:10:11 3789398 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:28:15  loss: 187.3669 (218.7646)  lr: 0.0000 (0.0000)  time: 0.123033  data: 0.002114  max mem: 1750
I20240613 11:10:13 3789398 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:28:12  loss: 187.2536 (218.3987)  lr: 0.0000 (0.0000)  time: 0.133393  data: 0.002002  max mem: 1750
I20240613 11:10:14 3789398 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:28:08  loss: 187.2536 (218.1137)  lr: 0.0000 (0.0000)  time: 0.130734  data: 0.001976  max mem: 1750
I20240613 11:10:15 3789398 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:28:06  loss: 187.0912 (217.7956)  lr: 0.0000 (0.0000)  time: 0.134736  data: 0.025242  max mem: 1750
I20240613 11:10:17 3789398 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:28:10  loss: 185.6613 (217.4484)  lr: 0.0000 (0.0000)  time: 0.170601  data: 0.063955  max mem: 1750
I20240613 11:10:19 3789398 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:28:07  loss: 185.6613 (217.1520)  lr: 0.0000 (0.0000)  time: 0.166468  data: 0.041086  max mem: 1750
I20240613 11:10:20 3789398 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:28:04  loss: 185.4331 (216.8265)  lr: 0.0000 (0.0000)  time: 0.133259  data: 0.002450  max mem: 1750
I20240613 11:10:22 3789398 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:28:03  loss: 185.6613 (216.5967)  lr: 0.0000 (0.0000)  time: 0.142760  data: 0.016668  max mem: 1750
I20240613 11:10:23 3789398 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:28:00  loss: 185.6613 (216.3007)  lr: 0.0000 (0.0000)  time: 0.142303  data: 0.016635  max mem: 1750
I20240613 11:10:24 3789398 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:27:57  loss: 184.9204 (215.9853)  lr: 0.0000 (0.0000)  time: 0.132034  data: 0.002084  max mem: 1750
I20240613 11:10:26 3789398 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:27:54  loss: 185.6613 (215.7598)  lr: 0.0000 (0.0000)  time: 0.131817  data: 0.001976  max mem: 1750
I20240613 11:10:27 3789398 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:27:49  loss: 184.9204 (215.4616)  lr: 0.0000 (0.0000)  time: 0.121384  data: 0.002103  max mem: 1750
I20240613 11:10:28 3789398 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:27:46  loss: 184.9204 (215.2471)  lr: 0.0000 (0.0000)  time: 0.121698  data: 0.002248  max mem: 1750
I20240613 11:10:29 3789398 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:27:43  loss: 184.6914 (214.9060)  lr: 0.0000 (0.0000)  time: 0.132455  data: 0.002059  max mem: 1750
I20240613 11:10:31 3789398 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:27:40  loss: 184.6914 (214.6774)  lr: 0.0000 (0.0000)  time: 0.132829  data: 0.001962  max mem: 1750
I20240613 11:10:32 3789398 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:27:38  loss: 183.6400 (214.4051)  lr: 0.0000 (0.0000)  time: 0.132818  data: 0.001926  max mem: 1750
I20240613 11:10:33 3789398 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:27:35  loss: 183.6400 (214.0996)  lr: 0.0000 (0.0000)  time: 0.133122  data: 0.002523  max mem: 1750
I20240613 11:10:35 3789398 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:27:32  loss: 184.6914 (213.8894)  lr: 0.0000 (0.0000)  time: 0.132983  data: 0.002508  max mem: 1750
I20240613 11:10:36 3789398 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:27:30  loss: 184.5622 (213.6387)  lr: 0.0000 (0.0000)  time: 0.132612  data: 0.001906  max mem: 1750
I20240613 11:10:37 3789398 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:27:27  loss: 183.6400 (213.3812)  lr: 0.0000 (0.0000)  time: 0.132593  data: 0.001791  max mem: 1750
I20240613 11:10:39 3789398 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:27:24  loss: 183.6400 (213.0640)  lr: 0.0000 (0.0000)  time: 0.132769  data: 0.001755  max mem: 1750
I20240613 11:10:40 3789398 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:27:22  loss: 183.6400 (212.7779)  lr: 0.0000 (0.0000)  time: 0.133153  data: 0.001856  max mem: 1750
I20240613 11:10:41 3789398 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:27:19  loss: 183.2576 (212.4658)  lr: 0.0000 (0.0000)  time: 0.132586  data: 0.001817  max mem: 1750
I20240613 11:10:43 3789398 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:27:16  loss: 183.2576 (212.2329)  lr: 0.0000 (0.0000)  time: 0.130973  data: 0.001781  max mem: 1750
I20240613 11:10:44 3789398 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:27:12  loss: 183.2576 (211.8819)  lr: 0.0000 (0.0000)  time: 0.121068  data: 0.002118  max mem: 1750
I20240613 11:10:45 3789398 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:27:09  loss: 182.9827 (211.6355)  lr: 0.0000 (0.0000)  time: 0.122540  data: 0.002128  max mem: 1750
I20240613 11:10:46 3789398 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:27:04  loss: 183.2576 (211.4271)  lr: 0.0000 (0.0000)  time: 0.120945  data: 0.001887  max mem: 1750
I20240613 11:10:48 3789398 dinov2 linear.py:272] running validation !
I20240613 11:10:51 3789398 dinov2 helpers.py:102] Test:  [    0/10010]  eta: 6:43:53    time: 2.420918  data: 1.932137  max mem: 1826
I20240613 11:10:56 3789398 dinov2 helpers.py:102] Test:  [   10/10010]  eta: 1:49:30    time: 0.657079  data: 0.393283  max mem: 2021
I20240613 11:10:58 3789398 dinov2 helpers.py:102] Test:  [   20/10010]  eta: 1:18:13    time: 0.372245  data: 0.119906  max mem: 2021
I20240613 11:11:01 3789398 dinov2 helpers.py:102] Test:  [   30/10010]  eta: 1:06:36    time: 0.259253  data: 0.000383  max mem: 2021
I20240613 11:11:04 3789398 dinov2 helpers.py:102] Test:  [   40/10010]  eta: 1:00:34    time: 0.254126  data: 0.000322  max mem: 2021
I20240613 11:11:06 3789398 dinov2 helpers.py:102] Test:  [   50/10010]  eta: 0:56:56    time: 0.254153  data: 0.000297  max mem: 2021
I20240613 11:11:09 3789398 dinov2 helpers.py:102] Test:  [   60/10010]  eta: 0:54:18    time: 0.251372  data: 0.000321  max mem: 2021
I20240613 11:11:11 3789398 dinov2 helpers.py:102] Test:  [   70/10010]  eta: 0:52:01    time: 0.240103  data: 0.000324  max mem: 2021
I20240613 11:11:13 3789398 dinov2 helpers.py:102] Test:  [   80/10010]  eta: 0:50:35    time: 0.239375  data: 0.000327  max mem: 2021
I20240613 11:11:16 3789398 dinov2 helpers.py:102] Test:  [   90/10010]  eta: 0:49:30    time: 0.247556  data: 0.000342  max mem: 2021
I20240613 11:11:18 3789398 dinov2 helpers.py:102] Test:  [  100/10010]  eta: 0:47:30    time: 0.214315  data: 0.000325  max mem: 2021
I20240613 11:11:20 3789398 dinov2 helpers.py:102] Test:  [  110/10010]  eta: 0:46:39    time: 0.207180  data: 0.000326  max mem: 2021
I20240613 11:11:22 3789398 dinov2 helpers.py:102] Test:  [  120/10010]  eta: 0:46:03    time: 0.237775  data: 0.000358  max mem: 2021
I20240613 11:11:24 3789398 dinov2 helpers.py:102] Test:  [  130/10010]  eta: 0:44:45    time: 0.211059  data: 0.000318  max mem: 2021
I20240613 11:11:27 3789398 dinov2 helpers.py:102] Test:  [  140/10010]  eta: 0:44:34    time: 0.219798  data: 0.000301  max mem: 2021
I20240613 11:11:29 3789398 dinov2 helpers.py:102] Test:  [  150/10010]  eta: 0:44:19    time: 0.255827  data: 0.000319  max mem: 2021
I20240613 11:11:32 3789398 dinov2 helpers.py:102] Test:  [  160/10010]  eta: 0:44:08    time: 0.254187  data: 0.000293  max mem: 2021
I20240613 11:11:34 3789398 dinov2 helpers.py:102] Test:  [  170/10010]  eta: 0:43:57    time: 0.254901  data: 0.000294  max mem: 2021
I20240613 11:11:37 3789398 dinov2 helpers.py:102] Test:  [  180/10010]  eta: 0:43:28    time: 0.237060  data: 0.000280  max mem: 2021
I20240613 11:11:39 3789398 dinov2 helpers.py:102] Test:  [  190/10010]  eta: 0:43:19    time: 0.236970  data: 0.000272  max mem: 2021
I20240613 11:11:42 3789398 dinov2 helpers.py:102] Test:  [  200/10010]  eta: 0:43:12    time: 0.254636  data: 0.000314  max mem: 2021
I20240613 11:11:44 3789398 dinov2 helpers.py:102] Test:  [  210/10010]  eta: 0:43:05    time: 0.254838  data: 0.000327  max mem: 2021
I20240613 11:11:47 3789398 dinov2 helpers.py:102] Test:  [  220/10010]  eta: 0:43:01    time: 0.257543  data: 0.000323  max mem: 2021
I20240613 11:11:49 3789398 dinov2 helpers.py:102] Test:  [  230/10010]  eta: 0:42:31    time: 0.229866  data: 0.000312  max mem: 2021
I20240613 11:11:51 3789398 dinov2 helpers.py:102] Test:  [  240/10010]  eta: 0:42:13    time: 0.211809  data: 0.000299  max mem: 2021
I20240613 11:11:54 3789398 dinov2 helpers.py:102] Test:  [  250/10010]  eta: 0:42:09    time: 0.239540  data: 0.000316  max mem: 2021
I20240613 11:11:56 3789398 dinov2 helpers.py:102] Test:  [  260/10010]  eta: 0:41:56    time: 0.243151  data: 0.000313  max mem: 2021
I20240613 11:11:59 3789398 dinov2 helpers.py:102] Test:  [  270/10010]  eta: 0:41:52    time: 0.243320  data: 0.000295  max mem: 2021
I20240613 11:12:01 3789398 dinov2 helpers.py:102] Test:  [  280/10010]  eta: 0:41:49    time: 0.255694  data: 0.000318  max mem: 2021
I20240613 11:12:03 3789398 dinov2 helpers.py:102] Test:  [  290/10010]  eta: 0:41:35    time: 0.239174  data: 0.000322  max mem: 2021
I20240613 11:12:06 3789398 dinov2 helpers.py:102] Test:  [  300/10010]  eta: 0:41:31    time: 0.238051  data: 0.000281  max mem: 2021
I20240613 11:12:08 3789398 dinov2 helpers.py:102] Test:  [  310/10010]  eta: 0:41:28    time: 0.254252  data: 0.000330  max mem: 2021
I20240613 11:12:11 3789398 dinov2 helpers.py:102] Test:  [  320/10010]  eta: 0:41:25    time: 0.254759  data: 0.000355  max mem: 2021
I20240613 11:12:14 3789398 dinov2 helpers.py:102] Test:  [  330/10010]  eta: 0:41:22    time: 0.255494  data: 0.000326  max mem: 2021
I20240613 11:12:16 3789398 dinov2 helpers.py:102] Test:  [  340/10010]  eta: 0:41:11    time: 0.240192  data: 0.000361  max mem: 2021
I20240613 11:12:18 3789398 dinov2 helpers.py:102] Test:  [  350/10010]  eta: 0:41:08    time: 0.239149  data: 0.000365  max mem: 2021
I20240613 11:12:21 3789398 dinov2 helpers.py:102] Test:  [  360/10010]  eta: 0:40:57    time: 0.240054  data: 0.000335  max mem: 2021
I20240613 11:12:23 3789398 dinov2 helpers.py:102] Test:  [  370/10010]  eta: 0:40:54    time: 0.239856  data: 0.000324  max mem: 2021
I20240613 11:12:26 3789398 dinov2 helpers.py:102] Test:  [  380/10010]  eta: 0:40:50    time: 0.250189  data: 0.000294  max mem: 2021
I20240613 11:12:27 3789398 dinov2 helpers.py:102] Test:  [  390/10010]  eta: 0:40:29    time: 0.213755  data: 0.000286  max mem: 2021
I20240613 11:12:30 3789398 dinov2 helpers.py:102] Test:  [  400/10010]  eta: 0:40:19    time: 0.200205  data: 0.000324  max mem: 2021
I20240613 11:12:32 3789398 dinov2 helpers.py:102] Test:  [  410/10010]  eta: 0:40:17    time: 0.237152  data: 0.000300  max mem: 2021
I20240613 11:12:35 3789398 dinov2 helpers.py:102] Test:  [  420/10010]  eta: 0:40:15    time: 0.254955  data: 0.000284  max mem: 2021
I20240613 11:12:37 3789398 dinov2 helpers.py:102] Test:  [  430/10010]  eta: 0:40:13    time: 0.254635  data: 0.000280  max mem: 2021
I20240613 11:12:40 3789398 dinov2 helpers.py:102] Test:  [  440/10010]  eta: 0:40:11    time: 0.253874  data: 0.000262  max mem: 2021
I20240613 11:12:42 3789398 dinov2 helpers.py:102] Test:  [  450/10010]  eta: 0:40:03    time: 0.240172  data: 0.000287  max mem: 2021
I20240613 11:12:45 3789398 dinov2 helpers.py:102] Test:  [  460/10010]  eta: 0:40:01    time: 0.240009  data: 0.000334  max mem: 2021
I20240613 11:12:47 3789398 dinov2 helpers.py:102] Test:  [  470/10010]  eta: 0:39:59    time: 0.253982  data: 0.000333  max mem: 2021
I20240613 11:12:50 3789398 dinov2 helpers.py:102] Test:  [  480/10010]  eta: 0:39:57    time: 0.253881  data: 0.000275  max mem: 2021
I20240613 11:12:52 3789398 dinov2 helpers.py:102] Test:  [  490/10010]  eta: 0:39:49    time: 0.239552  data: 0.000284  max mem: 2021
I20240613 11:12:54 3789398 dinov2 helpers.py:102] Test:  [  500/10010]  eta: 0:39:37    time: 0.211947  data: 0.000330  max mem: 2021
I20240613 11:12:56 3789398 dinov2 helpers.py:102] Test:  [  510/10010]  eta: 0:39:30    time: 0.212379  data: 0.000320  max mem: 2021
I20240613 11:12:58 3789398 dinov2 helpers.py:102] Test:  [  520/10010]  eta: 0:39:24    time: 0.229386  data: 0.000295  max mem: 2021
I20240613 11:13:01 3789398 dinov2 helpers.py:102] Test:  [  530/10010]  eta: 0:39:23    time: 0.243190  data: 0.000335  max mem: 2021
I20240613 11:13:04 3789398 dinov2 helpers.py:102] Test:  [  540/10010]  eta: 0:39:21    time: 0.253393  data: 0.000330  max mem: 2021
I20240613 11:13:06 3789398 dinov2 helpers.py:102] Test:  [  550/10010]  eta: 0:39:19    time: 0.253718  data: 0.000326  max mem: 2021
I20240613 11:13:08 3789398 dinov2 helpers.py:102] Test:  [  560/10010]  eta: 0:39:15    time: 0.247906  data: 0.000346  max mem: 2021
I20240613 11:13:11 3789398 dinov2 helpers.py:102] Test:  [  570/10010]  eta: 0:39:11    time: 0.240484  data: 0.000327  max mem: 2021
I20240613 11:13:13 3789398 dinov2 helpers.py:102] Test:  [  580/10010]  eta: 0:39:10    time: 0.246690  data: 0.000346  max mem: 2021
I20240613 11:13:16 3789398 dinov2 helpers.py:102] Test:  [  590/10010]  eta: 0:39:08    time: 0.253713  data: 0.000338  max mem: 2021
I20240613 11:13:19 3789398 dinov2 helpers.py:102] Test:  [  600/10010]  eta: 0:39:06    time: 0.254674  data: 0.000335  max mem: 2021
I20240613 11:13:21 3789398 dinov2 helpers.py:102] Test:  [  610/10010]  eta: 0:39:05    time: 0.254981  data: 0.000346  max mem: 2021
I20240613 11:13:23 3789398 dinov2 helpers.py:102] Test:  [  620/10010]  eta: 0:38:56    time: 0.233344  data: 0.000352  max mem: 2021
I20240613 11:13:26 3789398 dinov2 helpers.py:102] Test:  [  630/10010]  eta: 0:38:55    time: 0.232810  data: 0.000387  max mem: 2021
I20240613 11:13:28 3789398 dinov2 helpers.py:102] Test:  [  640/10010]  eta: 0:38:51    time: 0.247437  data: 0.000364  max mem: 2021
I20240613 11:13:30 3789398 dinov2 helpers.py:102] Test:  [  650/10010]  eta: 0:38:38    time: 0.207774  data: 0.000341  max mem: 2021
I20240613 11:13:32 3789398 dinov2 helpers.py:102] Test:  [  660/10010]  eta: 0:38:37    time: 0.216200  data: 0.000358  max mem: 2021
I20240613 11:13:35 3789398 dinov2 helpers.py:102] Test:  [  670/10010]  eta: 0:38:35    time: 0.256832  data: 0.000324  max mem: 2021
I20240613 11:13:37 3789398 dinov2 helpers.py:102] Test:  [  680/10010]  eta: 0:38:30    time: 0.240697  data: 0.000361  max mem: 2021
I20240613 11:13:40 3789398 dinov2 helpers.py:102] Test:  [  690/10010]  eta: 0:38:29    time: 0.240853  data: 0.000391  max mem: 2021
I20240613 11:13:42 3789398 dinov2 helpers.py:102] Test:  [  700/10010]  eta: 0:38:27    time: 0.255268  data: 0.000314  max mem: 2021
I20240613 11:13:45 3789398 dinov2 helpers.py:102] Test:  [  710/10010]  eta: 0:38:25    time: 0.254507  data: 0.000311  max mem: 2021
I20240613 11:13:47 3789398 dinov2 helpers.py:102] Test:  [  720/10010]  eta: 0:38:24    time: 0.254119  data: 0.000331  max mem: 2021
I20240613 11:13:50 3789398 dinov2 helpers.py:102] Test:  [  730/10010]  eta: 0:38:18    time: 0.240388  data: 0.000304  max mem: 2021
I20240613 11:13:52 3789398 dinov2 helpers.py:102] Test:  [  740/10010]  eta: 0:38:17    time: 0.240558  data: 0.000316  max mem: 2021
I20240613 11:13:55 3789398 dinov2 helpers.py:102] Test:  [  750/10010]  eta: 0:38:13    time: 0.244840  data: 0.000303  max mem: 2021
I20240613 11:13:57 3789398 dinov2 helpers.py:102] Test:  [  760/10010]  eta: 0:38:05    time: 0.218491  data: 0.000281  max mem: 2021
I20240613 11:13:59 3789398 dinov2 helpers.py:102] Test:  [  770/10010]  eta: 0:38:03    time: 0.228113  data: 0.000297  max mem: 2021
I20240613 11:14:01 3789398 dinov2 helpers.py:102] Test:  [  780/10010]  eta: 0:37:56    time: 0.231674  data: 0.000294  max mem: 2021
I20240613 11:14:03 3789398 dinov2 helpers.py:102] Test:  [  790/10010]  eta: 0:37:49    time: 0.206039  data: 0.000322  max mem: 2021
I20240613 11:14:06 3789398 dinov2 helpers.py:102] Test:  [  800/10010]  eta: 0:37:45    time: 0.221108  data: 0.000343  max mem: 2021
I20240613 11:14:08 3789398 dinov2 helpers.py:102] Test:  [  810/10010]  eta: 0:37:44    time: 0.245670  data: 0.000348  max mem: 2021
I20240613 11:14:11 3789398 dinov2 helpers.py:102] Test:  [  820/10010]  eta: 0:37:42    time: 0.254186  data: 0.000353  max mem: 2021
I20240613 11:14:13 3789398 dinov2 helpers.py:102] Test:  [  830/10010]  eta: 0:37:41    time: 0.255687  data: 0.000341  max mem: 2021
I20240613 11:14:16 3789398 dinov2 helpers.py:102] Test:  [  840/10010]  eta: 0:37:35    time: 0.235133  data: 0.000311  max mem: 2021
I20240613 11:14:18 3789398 dinov2 helpers.py:102] Test:  [  850/10010]  eta: 0:37:33    time: 0.235052  data: 0.000300  max mem: 2021
I20240613 11:14:21 3789398 dinov2 helpers.py:102] Test:  [  860/10010]  eta: 0:37:32    time: 0.255165  data: 0.000313  max mem: 2021
I20240613 11:14:23 3789398 dinov2 helpers.py:102] Test:  [  870/10010]  eta: 0:37:30    time: 0.254790  data: 0.000321  max mem: 2021
I20240613 11:14:26 3789398 dinov2 helpers.py:102] Test:  [  880/10010]  eta: 0:37:27    time: 0.246991  data: 0.000355  max mem: 2021
I20240613 11:14:28 3789398 dinov2 helpers.py:102] Test:  [  890/10010]  eta: 0:37:23    time: 0.231936  data: 0.000372  max mem: 2021
I20240613 11:14:30 3789398 dinov2 helpers.py:102] Test:  [  900/10010]  eta: 0:37:17    time: 0.221519  data: 0.000396  max mem: 2021
I20240613 11:14:32 3789398 dinov2 helpers.py:102] Test:  [  910/10010]  eta: 0:37:13    time: 0.222006  data: 0.000362  max mem: 2021
I20240613 11:14:35 3789398 dinov2 helpers.py:102] Test:  [  920/10010]  eta: 0:37:11    time: 0.240862  data: 0.000309  max mem: 2021
I20240613 11:14:37 3789398 dinov2 helpers.py:102] Test:  [  930/10010]  eta: 0:37:10    time: 0.255379  data: 0.000337  max mem: 2021
I20240613 11:14:40 3789398 dinov2 helpers.py:102] Test:  [  940/10010]  eta: 0:37:08    time: 0.254784  data: 0.000323  max mem: 2021
I20240613 11:14:42 3789398 dinov2 helpers.py:102] Test:  [  950/10010]  eta: 0:37:04    time: 0.240688  data: 0.000301  max mem: 2021
I20240613 11:14:45 3789398 dinov2 helpers.py:102] Test:  [  960/10010]  eta: 0:37:03    time: 0.244200  data: 0.000350  max mem: 2021
I20240613 11:14:47 3789398 dinov2 helpers.py:102] Test:  [  970/10010]  eta: 0:37:02    time: 0.261244  data: 0.000394  max mem: 2021
I20240613 11:14:50 3789398 dinov2 helpers.py:102] Test:  [  980/10010]  eta: 0:37:00    time: 0.257536  data: 0.000358  max mem: 2021
I20240613 11:14:52 3789398 dinov2 helpers.py:102] Test:  [  990/10010]  eta: 0:36:59    time: 0.254922  data: 0.000324  max mem: 2021
I20240613 11:14:55 3789398 dinov2 helpers.py:102] Test:  [ 1000/10010]  eta: 0:36:54    time: 0.237522  data: 0.000325  max mem: 2021
I20240613 11:14:57 3789398 dinov2 helpers.py:102] Test:  [ 1010/10010]  eta: 0:36:51    time: 0.229382  data: 0.000337  max mem: 2021
I20240613 11:14:59 3789398 dinov2 helpers.py:102] Test:  [ 1020/10010]  eta: 0:36:44    time: 0.219963  data: 0.000349  max mem: 2021
I20240613 11:15:02 3789398 dinov2 helpers.py:102] Test:  [ 1030/10010]  eta: 0:36:43    time: 0.228361  data: 0.000346  max mem: 2021
I20240613 11:15:04 3789398 dinov2 helpers.py:102] Test:  [ 1040/10010]  eta: 0:36:41    time: 0.250984  data: 0.000366  max mem: 2021
I20240613 11:15:07 3789398 dinov2 helpers.py:102] Test:  [ 1050/10010]  eta: 0:36:39    time: 0.251134  data: 0.000348  max mem: 2021
I20240613 11:15:09 3789398 dinov2 helpers.py:102] Test:  [ 1060/10010]  eta: 0:36:35    time: 0.241375  data: 0.000343  max mem: 2021
I20240613 11:15:12 3789398 dinov2 helpers.py:102] Test:  [ 1070/10010]  eta: 0:36:33    time: 0.241392  data: 0.000371  max mem: 2021
I20240613 11:15:14 3789398 dinov2 helpers.py:102] Test:  [ 1080/10010]  eta: 0:36:32    time: 0.255711  data: 0.000332  max mem: 2021
I20240613 11:15:17 3789398 dinov2 helpers.py:102] Test:  [ 1090/10010]  eta: 0:36:30    time: 0.255370  data: 0.000313  max mem: 2021
I20240613 11:15:19 3789398 dinov2 helpers.py:102] Test:  [ 1100/10010]  eta: 0:36:28    time: 0.255036  data: 0.000348  max mem: 2021
I20240613 11:15:21 3789398 dinov2 helpers.py:102] Test:  [ 1110/10010]  eta: 0:36:24    time: 0.240519  data: 0.000384  max mem: 2021
I20240613 11:15:24 3789398 dinov2 helpers.py:102] Test:  [ 1120/10010]  eta: 0:36:23    time: 0.245046  data: 0.000360  max mem: 2021
I20240613 11:15:27 3789398 dinov2 helpers.py:102] Test:  [ 1130/10010]  eta: 0:36:22    time: 0.259676  data: 0.000337  max mem: 2021
I20240613 11:15:29 3789398 dinov2 helpers.py:102] Test:  [ 1140/10010]  eta: 0:36:16    time: 0.231489  data: 0.000343  max mem: 2021
I20240613 11:15:31 3789398 dinov2 helpers.py:102] Test:  [ 1150/10010]  eta: 0:36:13    time: 0.221908  data: 0.000335  max mem: 2021
I20240613 11:15:34 3789398 dinov2 helpers.py:102] Test:  [ 1160/10010]  eta: 0:36:11    time: 0.245062  data: 0.000350  max mem: 2021
I20240613 11:15:36 3789398 dinov2 helpers.py:102] Test:  [ 1170/10010]  eta: 0:36:05    time: 0.222692  data: 0.000361  max mem: 2021
I20240613 11:15:38 3789398 dinov2 helpers.py:102] Test:  [ 1180/10010]  eta: 0:36:03    time: 0.223463  data: 0.000339  max mem: 2021
I20240613 11:15:41 3789398 dinov2 helpers.py:102] Test:  [ 1190/10010]  eta: 0:36:01    time: 0.255495  data: 0.000338  max mem: 2021
I20240613 11:15:43 3789398 dinov2 helpers.py:102] Test:  [ 1200/10010]  eta: 0:36:00    time: 0.255586  data: 0.000348  max mem: 2021
I20240613 11:15:46 3789398 dinov2 helpers.py:102] Test:  [ 1210/10010]  eta: 0:35:58    time: 0.256127  data: 0.000344  max mem: 2021
I20240613 11:15:48 3789398 dinov2 helpers.py:102] Test:  [ 1220/10010]  eta: 0:35:54    time: 0.241879  data: 0.000347  max mem: 2021
I20240613 11:15:51 3789398 dinov2 helpers.py:102] Test:  [ 1230/10010]  eta: 0:35:53    time: 0.244145  data: 0.000358  max mem: 2021
I20240613 11:15:53 3789398 dinov2 helpers.py:102] Test:  [ 1240/10010]  eta: 0:35:51    time: 0.258429  data: 0.000358  max mem: 2021
I20240613 11:15:56 3789398 dinov2 helpers.py:102] Test:  [ 1250/10010]  eta: 0:35:50    time: 0.255382  data: 0.000362  max mem: 2021
I20240613 11:15:58 3789398 dinov2 helpers.py:102] Test:  [ 1260/10010]  eta: 0:35:48    time: 0.255600  data: 0.000352  max mem: 2021
I20240613 11:16:00 3789398 dinov2 helpers.py:102] Test:  [ 1270/10010]  eta: 0:35:43    time: 0.229977  data: 0.000315  max mem: 2021
I20240613 11:16:02 3789398 dinov2 helpers.py:102] Test:  [ 1280/10010]  eta: 0:35:37    time: 0.202344  data: 0.000319  max mem: 2021
I20240613 11:16:05 3789398 dinov2 helpers.py:102] Test:  [ 1290/10010]  eta: 0:35:35    time: 0.224527  data: 0.000341  max mem: 2021
I20240613 11:16:07 3789398 dinov2 helpers.py:102] Test:  [ 1300/10010]  eta: 0:35:32    time: 0.242531  data: 0.000328  max mem: 2021
I20240613 11:16:10 3789398 dinov2 helpers.py:102] Test:  [ 1310/10010]  eta: 0:35:30    time: 0.246425  data: 0.000326  max mem: 2021
I20240613 11:16:12 3789398 dinov2 helpers.py:102] Test:  [ 1320/10010]  eta: 0:35:29    time: 0.257099  data: 0.000350  max mem: 2021
I20240613 11:16:15 3789398 dinov2 helpers.py:102] Test:  [ 1330/10010]  eta: 0:35:24    time: 0.238842  data: 0.000373  max mem: 2021
I20240613 11:16:17 3789398 dinov2 helpers.py:102] Test:  [ 1340/10010]  eta: 0:35:23    time: 0.238746  data: 0.000367  max mem: 2021
I20240613 11:16:20 3789398 dinov2 helpers.py:102] Test:  [ 1350/10010]  eta: 0:35:21    time: 0.256382  data: 0.000343  max mem: 2021
I20240613 11:16:22 3789398 dinov2 helpers.py:102] Test:  [ 1360/10010]  eta: 0:35:19    time: 0.254150  data: 0.000316  max mem: 2021
I20240613 11:16:25 3789398 dinov2 helpers.py:102] Test:  [ 1370/10010]  eta: 0:35:17    time: 0.254082  data: 0.000318  max mem: 2021
I20240613 11:16:27 3789398 dinov2 helpers.py:102] Test:  [ 1380/10010]  eta: 0:35:14    time: 0.240639  data: 0.000321  max mem: 2021
I20240613 11:16:30 3789398 dinov2 helpers.py:102] Test:  [ 1390/10010]  eta: 0:35:12    time: 0.240276  data: 0.000288  max mem: 2021
I20240613 11:16:32 3789398 dinov2 helpers.py:102] Test:  [ 1400/10010]  eta: 0:35:06    time: 0.225462  data: 0.000296  max mem: 2021
I20240613 11:16:34 3789398 dinov2 helpers.py:102] Test:  [ 1410/10010]  eta: 0:35:04    time: 0.221881  data: 0.000351  max mem: 2021
I20240613 11:16:36 3789398 dinov2 helpers.py:102] Test:  [ 1420/10010]  eta: 0:35:01    time: 0.244101  data: 0.000346  max mem: 2021
I20240613 11:16:39 3789398 dinov2 helpers.py:102] Test:  [ 1430/10010]  eta: 0:34:59    time: 0.239903  data: 0.000328  max mem: 2021
I20240613 11:16:41 3789398 dinov2 helpers.py:102] Test:  [ 1440/10010]  eta: 0:34:55    time: 0.232463  data: 0.000360  max mem: 2021
I20240613 11:16:44 3789398 dinov2 helpers.py:102] Test:  [ 1450/10010]  eta: 0:34:53    time: 0.240564  data: 0.000378  max mem: 2021
I20240613 11:16:46 3789398 dinov2 helpers.py:102] Test:  [ 1460/10010]  eta: 0:34:51    time: 0.254686  data: 0.000364  max mem: 2021
I20240613 11:16:49 3789398 dinov2 helpers.py:102] Test:  [ 1470/10010]  eta: 0:34:49    time: 0.254319  data: 0.000325  max mem: 2021
I20240613 11:16:51 3789398 dinov2 helpers.py:102] Test:  [ 1480/10010]  eta: 0:34:48    time: 0.255007  data: 0.000339  max mem: 2021
I20240613 11:16:54 3789398 dinov2 helpers.py:102] Test:  [ 1490/10010]  eta: 0:34:44    time: 0.241158  data: 0.000341  max mem: 2021
I20240613 11:16:56 3789398 dinov2 helpers.py:102] Test:  [ 1500/10010]  eta: 0:34:42    time: 0.237661  data: 0.000352  max mem: 2021
I20240613 11:16:59 3789398 dinov2 helpers.py:102] Test:  [ 1510/10010]  eta: 0:34:40    time: 0.252774  data: 0.000387  max mem: 2021
I20240613 11:17:01 3789398 dinov2 helpers.py:102] Test:  [ 1520/10010]  eta: 0:34:38    time: 0.256134  data: 0.000384  max mem: 2021
I20240613 11:17:03 3789398 dinov2 helpers.py:102] Test:  [ 1530/10010]  eta: 0:34:32    time: 0.218473  data: 0.000336  max mem: 2021
I20240613 11:17:05 3789398 dinov2 helpers.py:102] Test:  [ 1540/10010]  eta: 0:34:30    time: 0.210256  data: 0.000295  max mem: 2021
I20240613 11:17:08 3789398 dinov2 helpers.py:102] Test:  [ 1550/10010]  eta: 0:34:26    time: 0.229543  data: 0.000329  max mem: 2021
I20240613 11:17:10 3789398 dinov2 helpers.py:102] Test:  [ 1560/10010]  eta: 0:34:23    time: 0.229709  data: 0.000329  max mem: 2021
I20240613 11:17:13 3789398 dinov2 helpers.py:102] Test:  [ 1570/10010]  eta: 0:34:22    time: 0.248992  data: 0.000280  max mem: 2021
I20240613 11:17:15 3789398 dinov2 helpers.py:102] Test:  [ 1580/10010]  eta: 0:34:20    time: 0.256297  data: 0.000294  max mem: 2021
I20240613 11:17:18 3789398 dinov2 helpers.py:102] Test:  [ 1590/10010]  eta: 0:34:18    time: 0.254585  data: 0.000333  max mem: 2021
I20240613 11:17:20 3789398 dinov2 helpers.py:102] Test:  [ 1600/10010]  eta: 0:34:15    time: 0.251595  data: 0.000345  max mem: 2021
I20240613 11:17:22 3789398 dinov2 helpers.py:102] Test:  [ 1610/10010]  eta: 0:34:12    time: 0.241334  data: 0.000347  max mem: 2021
I20240613 11:17:25 3789398 dinov2 helpers.py:102] Test:  [ 1620/10010]  eta: 0:34:11    time: 0.245434  data: 0.000358  max mem: 2021
I20240613 11:17:28 3789398 dinov2 helpers.py:102] Test:  [ 1630/10010]  eta: 0:34:09    time: 0.255486  data: 0.000356  max mem: 2021
I20240613 11:17:30 3789398 dinov2 helpers.py:102] Test:  [ 1640/10010]  eta: 0:34:07    time: 0.254064  data: 0.000340  max mem: 2021
I20240613 11:17:33 3789398 dinov2 helpers.py:102] Test:  [ 1650/10010]  eta: 0:34:05    time: 0.254088  data: 0.000342  max mem: 2021
I20240613 11:17:34 3789398 dinov2 helpers.py:102] Test:  [ 1660/10010]  eta: 0:33:59    time: 0.212944  data: 0.000346  max mem: 2021
I20240613 11:17:37 3789398 dinov2 helpers.py:102] Test:  [ 1670/10010]  eta: 0:33:56    time: 0.208353  data: 0.000351  max mem: 2021
I20240613 11:17:39 3789398 dinov2 helpers.py:102] Test:  [ 1680/10010]  eta: 0:33:54    time: 0.244815  data: 0.000341  max mem: 2021
I20240613 11:17:42 3789398 dinov2 helpers.py:102] Test:  [ 1690/10010]  eta: 0:33:51    time: 0.235126  data: 0.000328  max mem: 2021
I20240613 11:17:44 3789398 dinov2 helpers.py:102] Test:  [ 1700/10010]  eta: 0:33:49    time: 0.240023  data: 0.000343  max mem: 2021
I20240613 11:17:47 3789398 dinov2 helpers.py:102] Test:  [ 1710/10010]  eta: 0:33:47    time: 0.254908  data: 0.000351  max mem: 2021
I20240613 11:17:49 3789398 dinov2 helpers.py:102] Test:  [ 1720/10010]  eta: 0:33:43    time: 0.238187  data: 0.000336  max mem: 2021
I20240613 11:17:51 3789398 dinov2 helpers.py:102] Test:  [ 1730/10010]  eta: 0:33:41    time: 0.240013  data: 0.000358  max mem: 2021
I20240613 11:17:54 3789398 dinov2 helpers.py:102] Test:  [ 1740/10010]  eta: 0:33:40    time: 0.258882  data: 0.000352  max mem: 2021
I20240613 11:17:57 3789398 dinov2 helpers.py:102] Test:  [ 1750/10010]  eta: 0:33:38    time: 0.256583  data: 0.000353  max mem: 2021
I20240613 11:17:59 3789398 dinov2 helpers.py:102] Test:  [ 1760/10010]  eta: 0:33:36    time: 0.255011  data: 0.000386  max mem: 2021
I20240613 11:18:01 3789398 dinov2 helpers.py:102] Test:  [ 1770/10010]  eta: 0:33:33    time: 0.242716  data: 0.000378  max mem: 2021
I20240613 11:18:04 3789398 dinov2 helpers.py:102] Test:  [ 1780/10010]  eta: 0:33:31    time: 0.243180  data: 0.000372  max mem: 2021
I20240613 11:18:06 3789398 dinov2 helpers.py:102] Test:  [ 1790/10010]  eta: 0:33:25    time: 0.219002  data: 0.000343  max mem: 2021
I20240613 11:18:08 3789398 dinov2 helpers.py:102] Test:  [ 1800/10010]  eta: 0:33:23    time: 0.217525  data: 0.000349  max mem: 2021
I20240613 11:18:11 3789398 dinov2 helpers.py:102] Test:  [ 1810/10010]  eta: 0:33:21    time: 0.246540  data: 0.000347  max mem: 2021
I20240613 11:18:13 3789398 dinov2 helpers.py:102] Test:  [ 1820/10010]  eta: 0:33:19    time: 0.246815  data: 0.000325  max mem: 2021
I20240613 11:18:15 3789398 dinov2 helpers.py:102] Test:  [ 1830/10010]  eta: 0:33:15    time: 0.235677  data: 0.000339  max mem: 2021
I20240613 11:18:18 3789398 dinov2 helpers.py:102] Test:  [ 1840/10010]  eta: 0:33:13    time: 0.236803  data: 0.000379  max mem: 2021
I20240613 11:18:21 3789398 dinov2 helpers.py:102] Test:  [ 1850/10010]  eta: 0:33:12    time: 0.258081  data: 0.000366  max mem: 2021
I20240613 11:18:23 3789398 dinov2 helpers.py:102] Test:  [ 1860/10010]  eta: 0:33:10    time: 0.257627  data: 0.000308  max mem: 2021
I20240613 11:18:26 3789398 dinov2 helpers.py:102] Test:  [ 1870/10010]  eta: 0:33:08    time: 0.254768  data: 0.000335  max mem: 2021
I20240613 11:18:28 3789398 dinov2 helpers.py:102] Test:  [ 1880/10010]  eta: 0:33:04    time: 0.238634  data: 0.000362  max mem: 2021
I20240613 11:18:31 3789398 dinov2 helpers.py:102] Test:  [ 1890/10010]  eta: 0:33:02    time: 0.238301  data: 0.000349  max mem: 2021
I20240613 11:18:33 3789398 dinov2 helpers.py:102] Test:  [ 1900/10010]  eta: 0:33:00    time: 0.256480  data: 0.000373  max mem: 2021
I20240613 11:18:36 3789398 dinov2 helpers.py:102] Test:  [ 1910/10010]  eta: 0:32:58    time: 0.257371  data: 0.000371  max mem: 2021
I20240613 11:18:38 3789398 dinov2 helpers.py:102] Test:  [ 1920/10010]  eta: 0:32:54    time: 0.230608  data: 0.000359  max mem: 2021
I20240613 11:18:40 3789398 dinov2 helpers.py:102] Test:  [ 1930/10010]  eta: 0:32:51    time: 0.216055  data: 0.000375  max mem: 2021
I20240613 11:18:42 3789398 dinov2 helpers.py:102] Test:  [ 1940/10010]  eta: 0:32:49    time: 0.237189  data: 0.000386  max mem: 2021
I20240613 11:18:45 3789398 dinov2 helpers.py:102] Test:  [ 1950/10010]  eta: 0:32:47    time: 0.251451  data: 0.000408  max mem: 2021
I20240613 11:18:48 3789398 dinov2 helpers.py:102] Test:  [ 1960/10010]  eta: 0:32:45    time: 0.254549  data: 0.000356  max mem: 2021
I20240613 11:18:50 3789398 dinov2 helpers.py:102] Test:  [ 1970/10010]  eta: 0:32:43    time: 0.255562  data: 0.000306  max mem: 2021
I20240613 11:18:53 3789398 dinov2 helpers.py:102] Test:  [ 1980/10010]  eta: 0:32:41    time: 0.250931  data: 0.000360  max mem: 2021
I20240613 11:18:55 3789398 dinov2 helpers.py:102] Test:  [ 1990/10010]  eta: 0:32:37    time: 0.234106  data: 0.000366  max mem: 2021
I20240613 11:18:57 3789398 dinov2 helpers.py:102] Test:  [ 2000/10010]  eta: 0:32:35    time: 0.239315  data: 0.000329  max mem: 2021
I20240613 11:19:00 3789398 dinov2 helpers.py:102] Test:  [ 2010/10010]  eta: 0:32:33    time: 0.255114  data: 0.000346  max mem: 2021
I20240613 11:19:02 3789398 dinov2 helpers.py:102] Test:  [ 2020/10010]  eta: 0:32:31    time: 0.254784  data: 0.000345  max mem: 2021
I20240613 11:19:05 3789398 dinov2 helpers.py:102] Test:  [ 2030/10010]  eta: 0:32:29    time: 0.254748  data: 0.000346  max mem: 2021
I20240613 11:19:07 3789398 dinov2 helpers.py:102] Test:  [ 2040/10010]  eta: 0:32:25    time: 0.233460  data: 0.000329  max mem: 2021
I20240613 11:19:09 3789398 dinov2 helpers.py:102] Test:  [ 2050/10010]  eta: 0:32:21    time: 0.201997  data: 0.000307  max mem: 2021
I20240613 11:19:12 3789398 dinov2 helpers.py:102] Test:  [ 2060/10010]  eta: 0:32:19    time: 0.224225  data: 0.000326  max mem: 2021
I20240613 11:19:14 3789398 dinov2 helpers.py:102] Test:  [ 2070/10010]  eta: 0:32:16    time: 0.243744  data: 0.000305  max mem: 2021
I20240613 11:19:16 3789398 dinov2 helpers.py:102] Test:  [ 2080/10010]  eta: 0:32:14    time: 0.242513  data: 0.000301  max mem: 2021
I20240613 11:19:19 3789398 dinov2 helpers.py:102] Test:  [ 2090/10010]  eta: 0:32:12    time: 0.254340  data: 0.000326  max mem: 2021
I20240613 11:19:21 3789398 dinov2 helpers.py:102] Test:  [ 2100/10010]  eta: 0:32:09    time: 0.235423  data: 0.000336  max mem: 2021
I20240613 11:19:24 3789398 dinov2 helpers.py:102] Test:  [ 2110/10010]  eta: 0:32:07    time: 0.235797  data: 0.000332  max mem: 2021
I20240613 11:19:26 3789398 dinov2 helpers.py:102] Test:  [ 2120/10010]  eta: 0:32:04    time: 0.254766  data: 0.000327  max mem: 2021
I20240613 11:19:29 3789398 dinov2 helpers.py:102] Test:  [ 2130/10010]  eta: 0:32:02    time: 0.254901  data: 0.000333  max mem: 2021
I20240613 11:19:31 3789398 dinov2 helpers.py:102] Test:  [ 2140/10010]  eta: 0:32:00    time: 0.255158  data: 0.000324  max mem: 2021
I20240613 11:19:34 3789398 dinov2 helpers.py:102] Test:  [ 2150/10010]  eta: 0:31:57    time: 0.241448  data: 0.000337  max mem: 2021
I20240613 11:19:36 3789398 dinov2 helpers.py:102] Test:  [ 2160/10010]  eta: 0:31:55    time: 0.240655  data: 0.000333  max mem: 2021
I20240613 11:19:39 3789398 dinov2 helpers.py:102] Test:  [ 2170/10010]  eta: 0:31:53    time: 0.247332  data: 0.000333  max mem: 2021
I20240613 11:19:41 3789398 dinov2 helpers.py:102] Test:  [ 2180/10010]  eta: 0:31:49    time: 0.219359  data: 0.000328  max mem: 2021
I20240613 11:19:43 3789398 dinov2 helpers.py:102] Test:  [ 2190/10010]  eta: 0:31:47    time: 0.227094  data: 0.000336  max mem: 2021
I20240613 11:19:46 3789398 dinov2 helpers.py:102] Test:  [ 2200/10010]  eta: 0:31:44    time: 0.252613  data: 0.000377  max mem: 2021
I20240613 11:19:48 3789398 dinov2 helpers.py:102] Test:  [ 2210/10010]  eta: 0:31:41    time: 0.236768  data: 0.000345  max mem: 2021
I20240613 11:19:51 3789398 dinov2 helpers.py:102] Test:  [ 2220/10010]  eta: 0:31:39    time: 0.242995  data: 0.000331  max mem: 2021
I20240613 11:19:53 3789398 dinov2 helpers.py:102] Test:  [ 2230/10010]  eta: 0:31:37    time: 0.258122  data: 0.000327  max mem: 2021
I20240613 11:19:56 3789398 dinov2 helpers.py:102] Test:  [ 2240/10010]  eta: 0:31:35    time: 0.254893  data: 0.000309  max mem: 2021
I20240613 11:19:58 3789398 dinov2 helpers.py:102] Test:  [ 2250/10010]  eta: 0:31:33    time: 0.253975  data: 0.000309  max mem: 2021
I20240613 11:20:00 3789398 dinov2 helpers.py:102] Test:  [ 2260/10010]  eta: 0:31:30    time: 0.235551  data: 0.000349  max mem: 2021
I20240613 11:20:03 3789398 dinov2 helpers.py:102] Test:  [ 2270/10010]  eta: 0:31:28    time: 0.235970  data: 0.000385  max mem: 2021
I20240613 11:20:05 3789398 dinov2 helpers.py:102] Test:  [ 2280/10010]  eta: 0:31:26    time: 0.254794  data: 0.000407  max mem: 2021
I20240613 11:20:08 3789398 dinov2 helpers.py:102] Test:  [ 2290/10010]  eta: 0:31:24    time: 0.254872  data: 0.000391  max mem: 2021
I20240613 11:20:10 3789398 dinov2 helpers.py:102] Test:  [ 2300/10010]  eta: 0:31:21    time: 0.251032  data: 0.000325  max mem: 2021
I20240613 11:20:12 3789398 dinov2 helpers.py:102] Test:  [ 2310/10010]  eta: 0:31:16    time: 0.202798  data: 0.000305  max mem: 2021
I20240613 11:20:14 3789398 dinov2 helpers.py:102] Test:  [ 2320/10010]  eta: 0:31:13    time: 0.190812  data: 0.000318  max mem: 2021
I20240613 11:20:16 3789398 dinov2 helpers.py:102] Test:  [ 2330/10010]  eta: 0:31:09    time: 0.216239  data: 0.000313  max mem: 2021
I20240613 11:20:19 3789398 dinov2 helpers.py:102] Test:  [ 2340/10010]  eta: 0:31:06    time: 0.212611  data: 0.000320  max mem: 2021
I20240613 11:20:21 3789398 dinov2 helpers.py:102] Test:  [ 2350/10010]  eta: 0:31:04    time: 0.238684  data: 0.000339  max mem: 2021
I20240613 11:20:24 3789398 dinov2 helpers.py:102] Test:  [ 2360/10010]  eta: 0:31:02    time: 0.257786  data: 0.000313  max mem: 2021
I20240613 11:20:26 3789398 dinov2 helpers.py:102] Test:  [ 2370/10010]  eta: 0:30:59    time: 0.241031  data: 0.000336  max mem: 2021
I20240613 11:20:29 3789398 dinov2 helpers.py:102] Test:  [ 2380/10010]  eta: 0:30:57    time: 0.241584  data: 0.000362  max mem: 2021
I20240613 11:20:31 3789398 dinov2 helpers.py:102] Test:  [ 2390/10010]  eta: 0:30:55    time: 0.255655  data: 0.000331  max mem: 2021
I20240613 11:20:34 3789398 dinov2 helpers.py:102] Test:  [ 2400/10010]  eta: 0:30:53    time: 0.255084  data: 0.000342  max mem: 2021
I20240613 11:20:36 3789398 dinov2 helpers.py:102] Test:  [ 2410/10010]  eta: 0:30:51    time: 0.255003  data: 0.000383  max mem: 2021
I20240613 11:20:39 3789398 dinov2 helpers.py:102] Test:  [ 2420/10010]  eta: 0:30:49    time: 0.255128  data: 0.000416  max mem: 2021
I20240613 11:20:41 3789398 dinov2 helpers.py:102] Test:  [ 2430/10010]  eta: 0:30:46    time: 0.240032  data: 0.000390  max mem: 2021
I20240613 11:20:43 3789398 dinov2 helpers.py:102] Test:  [ 2440/10010]  eta: 0:30:42    time: 0.209826  data: 0.000370  max mem: 2021
I20240613 11:20:45 3789398 dinov2 helpers.py:102] Test:  [ 2450/10010]  eta: 0:30:40    time: 0.224306  data: 0.000389  max mem: 2021
I20240613 11:20:48 3789398 dinov2 helpers.py:102] Test:  [ 2460/10010]  eta: 0:30:36    time: 0.234056  data: 0.000329  max mem: 2021
I20240613 11:20:50 3789398 dinov2 helpers.py:102] Test:  [ 2470/10010]  eta: 0:30:34    time: 0.236581  data: 0.000353  max mem: 2021
I20240613 11:20:53 3789398 dinov2 helpers.py:102] Test:  [ 2480/10010]  eta: 0:30:32    time: 0.247455  data: 0.000392  max mem: 2021
I20240613 11:20:55 3789398 dinov2 helpers.py:102] Test:  [ 2490/10010]  eta: 0:30:29    time: 0.241219  data: 0.000408  max mem: 2021
I20240613 11:20:58 3789398 dinov2 helpers.py:102] Test:  [ 2500/10010]  eta: 0:30:27    time: 0.251161  data: 0.000415  max mem: 2021
I20240613 11:21:00 3789398 dinov2 helpers.py:102] Test:  [ 2510/10010]  eta: 0:30:25    time: 0.254855  data: 0.000334  max mem: 2021
I20240613 11:21:03 3789398 dinov2 helpers.py:102] Test:  [ 2520/10010]  eta: 0:30:23    time: 0.254330  data: 0.000375  max mem: 2021
I20240613 11:21:05 3789398 dinov2 helpers.py:102] Test:  [ 2530/10010]  eta: 0:30:21    time: 0.255390  data: 0.000405  max mem: 2021
I20240613 11:21:07 3789398 dinov2 helpers.py:102] Test:  [ 2540/10010]  eta: 0:30:18    time: 0.241284  data: 0.000367  max mem: 2021
I20240613 11:21:10 3789398 dinov2 helpers.py:102] Test:  [ 2550/10010]  eta: 0:30:16    time: 0.240160  data: 0.000380  max mem: 2021
I20240613 11:21:13 3789398 dinov2 helpers.py:102] Test:  [ 2560/10010]  eta: 0:30:14    time: 0.251131  data: 0.000389  max mem: 2021
I20240613 11:21:15 3789398 dinov2 helpers.py:102] Test:  [ 2570/10010]  eta: 0:30:11    time: 0.233842  data: 0.000357  max mem: 2021
I20240613 11:21:17 3789398 dinov2 helpers.py:102] Test:  [ 2580/10010]  eta: 0:30:09    time: 0.237301  data: 0.000333  max mem: 2021
I20240613 11:21:19 3789398 dinov2 helpers.py:102] Test:  [ 2590/10010]  eta: 0:30:05    time: 0.230315  data: 0.000310  max mem: 2021
I20240613 11:21:22 3789398 dinov2 helpers.py:102] Test:  [ 2600/10010]  eta: 0:30:03    time: 0.231197  data: 0.000338  max mem: 2021
I20240613 11:21:24 3789398 dinov2 helpers.py:102] Test:  [ 2610/10010]  eta: 0:30:01    time: 0.255953  data: 0.000357  max mem: 2021
I20240613 11:21:27 3789398 dinov2 helpers.py:102] Test:  [ 2620/10010]  eta: 0:29:59    time: 0.255592  data: 0.000342  max mem: 2021
I20240613 11:21:30 3789398 dinov2 helpers.py:102] Test:  [ 2630/10010]  eta: 0:29:57    time: 0.255646  data: 0.000379  max mem: 2021
I20240613 11:21:32 3789398 dinov2 helpers.py:102] Test:  [ 2640/10010]  eta: 0:29:54    time: 0.244803  data: 0.000360  max mem: 2021
I20240613 11:21:34 3789398 dinov2 helpers.py:102] Test:  [ 2650/10010]  eta: 0:29:52    time: 0.239167  data: 0.000335  max mem: 2021
I20240613 11:21:37 3789398 dinov2 helpers.py:102] Test:  [ 2660/10010]  eta: 0:29:49    time: 0.248739  data: 0.000339  max mem: 2021
I20240613 11:21:39 3789398 dinov2 helpers.py:102] Test:  [ 2670/10010]  eta: 0:29:47    time: 0.253556  data: 0.000308  max mem: 2021
I20240613 11:21:42 3789398 dinov2 helpers.py:102] Test:  [ 2680/10010]  eta: 0:29:45    time: 0.254002  data: 0.000308  max mem: 2021
I20240613 11:21:44 3789398 dinov2 helpers.py:102] Test:  [ 2690/10010]  eta: 0:29:42    time: 0.242103  data: 0.000336  max mem: 2021
I20240613 11:21:46 3789398 dinov2 helpers.py:102] Test:  [ 2700/10010]  eta: 0:29:38    time: 0.208969  data: 0.000348  max mem: 2021
I20240613 11:21:49 3789398 dinov2 helpers.py:102] Test:  [ 2710/10010]  eta: 0:29:36    time: 0.221236  data: 0.000372  max mem: 2021
I20240613 11:21:51 3789398 dinov2 helpers.py:102] Test:  [ 2720/10010]  eta: 0:29:34    time: 0.245744  data: 0.000386  max mem: 2021
I20240613 11:21:54 3789398 dinov2 helpers.py:102] Test:  [ 2730/10010]  eta: 0:29:31    time: 0.245666  data: 0.000375  max mem: 2021
I20240613 11:21:56 3789398 dinov2 helpers.py:102] Test:  [ 2740/10010]  eta: 0:29:29    time: 0.254896  data: 0.000348  max mem: 2021
I20240613 11:21:58 3789398 dinov2 helpers.py:102] Test:  [ 2750/10010]  eta: 0:29:27    time: 0.242416  data: 0.000318  max mem: 2021
I20240613 11:22:01 3789398 dinov2 helpers.py:102] Test:  [ 2760/10010]  eta: 0:29:24    time: 0.241870  data: 0.000344  max mem: 2021
I20240613 11:22:04 3789398 dinov2 helpers.py:102] Test:  [ 2770/10010]  eta: 0:29:22    time: 0.256741  data: 0.000331  max mem: 2021
I20240613 11:22:06 3789398 dinov2 helpers.py:102] Test:  [ 2780/10010]  eta: 0:29:20    time: 0.256863  data: 0.000300  max mem: 2021
I20240613 11:22:09 3789398 dinov2 helpers.py:102] Test:  [ 2790/10010]  eta: 0:29:18    time: 0.254074  data: 0.000369  max mem: 2021
I20240613 11:22:11 3789398 dinov2 helpers.py:102] Test:  [ 2800/10010]  eta: 0:29:15    time: 0.244554  data: 0.000416  max mem: 2021
I20240613 11:22:13 3789398 dinov2 helpers.py:102] Test:  [ 2810/10010]  eta: 0:29:13    time: 0.238374  data: 0.000383  max mem: 2021
I20240613 11:22:16 3789398 dinov2 helpers.py:102] Test:  [ 2820/10010]  eta: 0:29:10    time: 0.236780  data: 0.000334  max mem: 2021
I20240613 11:22:18 3789398 dinov2 helpers.py:102] Test:  [ 2830/10010]  eta: 0:29:08    time: 0.235097  data: 0.000300  max mem: 2021
I20240613 11:22:21 3789398 dinov2 helpers.py:102] Test:  [ 2840/10010]  eta: 0:29:05    time: 0.243140  data: 0.000322  max mem: 2021
I20240613 11:22:23 3789398 dinov2 helpers.py:102] Test:  [ 2850/10010]  eta: 0:29:03    time: 0.243136  data: 0.000339  max mem: 2021
I20240613 11:22:25 3789398 dinov2 helpers.py:102] Test:  [ 2860/10010]  eta: 0:29:00    time: 0.232073  data: 0.000345  max mem: 2021
I20240613 11:22:28 3789398 dinov2 helpers.py:102] Test:  [ 2870/10010]  eta: 0:28:58    time: 0.240361  data: 0.000382  max mem: 2021
I20240613 11:22:30 3789398 dinov2 helpers.py:102] Test:  [ 2880/10010]  eta: 0:28:56    time: 0.255109  data: 0.000385  max mem: 2021
I20240613 11:22:33 3789398 dinov2 helpers.py:102] Test:  [ 2890/10010]  eta: 0:28:53    time: 0.255588  data: 0.000358  max mem: 2021
I20240613 11:22:35 3789398 dinov2 helpers.py:102] Test:  [ 2900/10010]  eta: 0:28:51    time: 0.254822  data: 0.000318  max mem: 2021
I20240613 11:22:38 3789398 dinov2 helpers.py:102] Test:  [ 2910/10010]  eta: 0:28:48    time: 0.238774  data: 0.000305  max mem: 2021
I20240613 11:22:40 3789398 dinov2 helpers.py:102] Test:  [ 2920/10010]  eta: 0:28:46    time: 0.239583  data: 0.000338  max mem: 2021
I20240613 11:22:43 3789398 dinov2 helpers.py:102] Test:  [ 2930/10010]  eta: 0:28:44    time: 0.255778  data: 0.000358  max mem: 2021
I20240613 11:22:45 3789398 dinov2 helpers.py:102] Test:  [ 2940/10010]  eta: 0:28:42    time: 0.254809  data: 0.000320  max mem: 2021
I20240613 11:22:48 3789398 dinov2 helpers.py:102] Test:  [ 2950/10010]  eta: 0:28:39    time: 0.235191  data: 0.000318  max mem: 2021
I20240613 11:22:50 3789398 dinov2 helpers.py:102] Test:  [ 2960/10010]  eta: 0:28:36    time: 0.223222  data: 0.000327  max mem: 2021
I20240613 11:22:52 3789398 dinov2 helpers.py:102] Test:  [ 2970/10010]  eta: 0:28:33    time: 0.226604  data: 0.000339  max mem: 2021
I20240613 11:22:54 3789398 dinov2 helpers.py:102] Test:  [ 2980/10010]  eta: 0:28:30    time: 0.229003  data: 0.000372  max mem: 2021
I20240613 11:22:57 3789398 dinov2 helpers.py:102] Test:  [ 2990/10010]  eta: 0:28:28    time: 0.245023  data: 0.000371  max mem: 2021
I20240613 11:23:00 3789398 dinov2 helpers.py:102] Test:  [ 3000/10010]  eta: 0:28:26    time: 0.255446  data: 0.000335  max mem: 2021
I20240613 11:26:57 3800962 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 11:26:57 3800962 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 11:26:57 3800962 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 11:26:57 3800962 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 11:26:57 3800962 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 11:26:58 3800962 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 11:26:58 3800962 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:26:58 3800962 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 11:27:01 3800962 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 11:27:01 3800962 dinov2 loaders.py:122] sampler: sharded infinite
I20240613 11:27:01 3800962 dinov2 loaders.py:206] using PyTorch data loader
I20240613 11:27:01 3800962 dinov2 loaders.py:221] infinite data loader
I20240613 11:27:01 3800962 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:27:01 3800962 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 11:27:01 3800962 dinov2 loaders.py:147] sampler: distributed
I20240613 11:27:01 3800962 dinov2 loaders.py:206] using PyTorch data loader
I20240613 11:27:01 3800962 dinov2 loaders.py:219] # of batches: 10,010
I20240613 11:27:01 3800962 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 11:27:01 3800962 dinov2 linear.py:338] Starting training from iteration 0
I20240613 11:38:27 3806103 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 11:38:27 3806103 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 11:38:27 3806103 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 11:38:27 3806103 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 11:38:27 3806103 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 11:38:28 3806103 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 11:38:29 3806103 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 11:38:29 3806103 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 13:32:59 3841414 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 13:32:59 3841414 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 13:32:59 3841414 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 13:32:59 3841414 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 13:32:59 3841414 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 13:32:59 3841414 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 13:32:59 3841414 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 13:32:59 3841414 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 13:33:52 3841914 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 13:33:52 3841914 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 13:33:52 3841914 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 13:33:53 3841914 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 13:33:53 3841914 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 13:33:53 3841914 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 13:33:53 3841914 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 13:33:53 3841914 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 14:24:27 3865232 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 14:24:27 3865232 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 14:24:27 3865232 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0028284271247461905
I20240613 14:24:27 3865232 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0028284271247461905
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 14:24:27 3865232 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 14:24:27 3865232 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 14:33:53 3867784 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 14:33:53 3867784 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 14:33:53 3867784 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0028284271247461905
I20240613 14:33:53 3867784 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0028284271247461905
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 14:33:53 3867784 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 14:33:54 3867784 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 14:33:54 3867784 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 14:33:54 3867784 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:50:14 3905062 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 15:50:14 3905062 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 15:50:14 3905062 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 15:50:14 3905062 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 15:50:14 3905062 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 15:50:14 3905062 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 15:50:14 3905062 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 15:50:14 3905062 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:50:18 3905062 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 15:50:18 3905062 dinov2 loaders.py:122] sampler: sharded infinite
I20240613 15:50:18 3905062 dinov2 loaders.py:206] using PyTorch data loader
I20240613 15:50:18 3905062 dinov2 loaders.py:221] infinite data loader
I20240613 15:50:18 3905062 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 15:50:18 3905062 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:50:18 3905062 dinov2 loaders.py:147] sampler: distributed
I20240613 15:50:18 3905062 dinov2 loaders.py:206] using PyTorch data loader
I20240613 15:50:18 3905062 dinov2 loaders.py:219] # of batches: 10,010
I20240613 15:50:18 3905062 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 15:50:18 3905062 dinov2 linear.py:340] Starting training from iteration 0
I20240613 15:50:29 3905062 dinov2 helpers.py:102] Training  [    0/12500]  eta: 1 day, 17:31:17  loss: 341.1960 (341.1960)  lr: 0.0000 (0.0000)  time: 11.958235  data: 11.278572  max mem: 1537
I20240613 15:50:30 3905062 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20240613 15:50:31 3905062 dinov2 helpers.py:102] Training  [   10/12500]  eta: 4:12:47  loss: 330.6245 (335.9103)  lr: 0.0000 (0.0000)  time: 1.214359  data: 1.027759  max mem: 2091
I20240613 15:50:43 3906662 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 15:50:43 3906662 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 15:50:43 3906662 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 15:50:43 3906662 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 15:50:43 3906662 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 15:50:44 3906662 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 15:50:44 3906662 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 15:50:44 3906662 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:59:04 3909845 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 15:59:04 3909845 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 15:59:04 3909845 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 15:59:04 3909845 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 15:59:04 3909845 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 15:59:04 3909845 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 15:59:04 3909845 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 15:59:04 3909845 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:59:07 3909845 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 15:59:07 3909845 dinov2 loaders.py:122] sampler: sharded infinite
I20240613 15:59:07 3909845 dinov2 loaders.py:206] using PyTorch data loader
I20240613 15:59:07 3909845 dinov2 loaders.py:221] infinite data loader
I20240613 15:59:07 3909845 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 15:59:07 3909845 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 15:59:07 3909845 dinov2 loaders.py:147] sampler: distributed
I20240613 15:59:07 3909845 dinov2 loaders.py:206] using PyTorch data loader
I20240613 15:59:07 3909845 dinov2 loaders.py:219] # of batches: 10,010
I20240613 15:59:07 3909845 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240613 15:59:07 3909845 dinov2 linear.py:340] Starting training from iteration 0
I20240613 16:09:09 3914468 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 16:09:09 3914468 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 16:09:09 3914468 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 16:09:09 3914468 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 16:09:09 3914468 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 16:09:10 3914468 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 16:09:10 3914468 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 16:09:10 3914468 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 16:22:07 3919620 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 16:22:07 3919620 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 16:22:07 3919620 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 16:22:07 3919620 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 16:22:07 3919620 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 16:22:08 3919620 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 16:22:08 3919620 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 16:22:08 3919620 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 16:22:25 3919939 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 16:22:25 3919939 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 16:22:25 3919939 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 16:22:25 3919939 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 16:22:25 3919939 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 16:22:25 3919939 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 16:22:25 3919939 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 16:22:25 3919939 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 16:54:33 3931586 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 16:54:33 3931586 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 16:54:33 3931586 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 16:54:33 3931586 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 16:54:33 3931586 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 16:54:33 3931586 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 16:54:33 3931586 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 16:54:33 3931586 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240613 17:15:17 3939241 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 17:15:17 3939241 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 0
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 17:15:17 3939241 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240613 17:15:17 3939241 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240613 17:15:17 3939241 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240613 17:15:18 3939241 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240613 17:15:18 3939241 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240613 17:15:18 3939241 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:03:32 39624 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240614 10:03:32 39624 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240614 10:03:32 39624 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240614 10:03:32 39624 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240614 10:03:32 39624 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240614 10:03:33 39624 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240614 10:07:29 39624 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:07:29 39624 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:07:33 39624 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:07:33 39624 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:07:47 39624 dinov2 knn.py:262] Extracting features for train set...
I20240614 10:07:47 39624 dinov2 loaders.py:147] sampler: distributed
I20240614 10:07:47 39624 dinov2 loaders.py:206] using PyTorch data loader
I20240614 10:07:47 39624 dinov2 loaders.py:219] # of batches: 5,005
I20240614 10:07:52 39624 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240614 10:07:52 39624 dinov2 helpers.py:102]   [   0/5005]  eta: 6:20:25    time: 4.560518  data: 2.763693  max mem: 2173
I20240614 10:07:55 39624 dinov2 helpers.py:102]   [  10/5005]  eta: 0:57:09    time: 0.686679  data: 0.494854  max mem: 2847
I20240614 10:07:58 39624 dinov2 helpers.py:102]   [  20/5005]  eta: 0:42:53    time: 0.314059  data: 0.280096  max mem: 2847
I20240614 10:08:02 39624 dinov2 helpers.py:102]   [  30/5005]  eta: 0:38:35    time: 0.343646  data: 0.308750  max mem: 2847
I20240614 10:08:05 39624 dinov2 helpers.py:102]   [  40/5005]  eta: 0:36:26    time: 0.360761  data: 0.326260  max mem: 2847
I20240614 10:09:37 42144 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240614 10:09:37 42144 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240614 10:09:37 42144 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240614 10:09:37 42144 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240614 10:09:37 42144 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240614 10:09:38 42144 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240614 10:09:38 42144 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:09:38 42144 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:09:38 42144 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:09:38 42144 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:09:38 42144 dinov2 knn.py:262] Extracting features for train set...
I20240614 10:09:38 42144 dinov2 loaders.py:147] sampler: distributed
I20240614 10:09:38 42144 dinov2 loaders.py:206] using PyTorch data loader
I20240614 10:09:38 42144 dinov2 loaders.py:219] # of batches: 5,005
I20240614 10:09:42 42144 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240614 10:09:42 42144 dinov2 helpers.py:102]   [   0/5005]  eta: 6:01:56    time: 4.339005  data: 2.689677  max mem: 2173
I20240614 10:09:46 42144 dinov2 helpers.py:102]   [  10/5005]  eta: 1:01:10    time: 0.734916  data: 0.553628  max mem: 2847
I20240614 10:09:49 42144 dinov2 helpers.py:102]   [  20/5005]  eta: 0:45:55    time: 0.363406  data: 0.335580  max mem: 2847
I20240614 10:09:53 42144 dinov2 helpers.py:102]   [  30/5005]  eta: 0:40:50    time: 0.359259  data: 0.338790  max mem: 2847
I20240614 10:09:57 42144 dinov2 helpers.py:102]   [  40/5005]  eta: 0:38:42    time: 0.378401  data: 0.358848  max mem: 2847
I20240614 10:10:01 42144 dinov2 helpers.py:102]   [  50/5005]  eta: 0:37:37    time: 0.398413  data: 0.373768  max mem: 2847
I20240614 10:10:05 42144 dinov2 helpers.py:102]   [  60/5005]  eta: 0:36:32    time: 0.393474  data: 0.369847  max mem: 2847
I20240614 10:10:08 42144 dinov2 helpers.py:102]   [  70/5005]  eta: 0:35:38    time: 0.376325  data: 0.359016  max mem: 2847
I20240614 10:10:12 42144 dinov2 helpers.py:102]   [  80/5005]  eta: 0:35:03    time: 0.377413  data: 0.360192  max mem: 2847
I20240614 10:10:16 42144 dinov2 helpers.py:102]   [  90/5005]  eta: 0:34:30    time: 0.378413  data: 0.360740  max mem: 2847
I20240614 10:10:20 42144 dinov2 helpers.py:102]   [ 100/5005]  eta: 0:33:59    time: 0.369646  data: 0.352092  max mem: 2847
I20240614 10:10:23 42144 dinov2 helpers.py:102]   [ 110/5005]  eta: 0:33:36    time: 0.370164  data: 0.353480  max mem: 2847
I20240614 10:10:27 42144 dinov2 helpers.py:102]   [ 120/5005]  eta: 0:33:15    time: 0.372635  data: 0.355699  max mem: 2847
I20240614 10:11:53 43736 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240614 10:11:53 43736 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240614 10:11:53 43736 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0028284271247461905
I20240614 10:11:53 43736 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0028284271247461905
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240614 10:11:53 43736 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240614 10:11:54 43736 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240614 10:11:54 43736 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:11:54 43736 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:11:54 43736 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:11:54 43736 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:11:54 43736 dinov2 knn.py:262] Extracting features for train set...
I20240614 10:11:54 43736 dinov2 loaders.py:147] sampler: distributed
I20240614 10:11:54 43736 dinov2 loaders.py:206] using PyTorch data loader
I20240614 10:11:54 43736 dinov2 loaders.py:219] # of batches: 626
I20240614 10:11:59 43736 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240614 10:11:59 43736 dinov2 helpers.py:102]   [  0/626]  eta: 0:54:50    time: 5.257155  data: 3.568179  max mem: 2178
I20240614 10:12:23 43736 dinov2 helpers.py:102]   [ 10/626]  eta: 0:27:05    time: 2.638043  data: 1.831637  max mem: 2850
I20240614 10:12:28 43736 dinov2 helpers.py:102]   [ 20/626]  eta: 0:16:24    time: 1.442309  data: 0.829374  max mem: 2850
I20240614 10:12:33 43736 dinov2 helpers.py:102]   [ 30/626]  eta: 0:12:42    time: 0.531743  data: 0.000766  max mem: 2850
I20240614 10:12:40 43736 dinov2 helpers.py:102]   [ 40/626]  eta: 0:10:56    time: 0.592139  data: 0.000744  max mem: 2850
I20240614 10:12:45 43736 dinov2 helpers.py:102]   [ 50/626]  eta: 0:09:41    time: 0.590886  data: 0.000680  max mem: 2850
I20240614 10:12:50 43736 dinov2 helpers.py:102]   [ 60/626]  eta: 0:08:47    time: 0.543898  data: 0.000623  max mem: 2850
I20240614 10:12:56 43736 dinov2 helpers.py:102]   [ 70/626]  eta: 0:08:10    time: 0.557632  data: 0.000641  max mem: 2850
I20240614 10:13:02 43736 dinov2 helpers.py:102]   [ 80/626]  eta: 0:07:40    time: 0.571225  data: 0.000670  max mem: 2850
I20240614 10:13:08 43736 dinov2 helpers.py:102]   [ 90/626]  eta: 0:07:17    time: 0.578596  data: 0.047004  max mem: 2850
I20240614 10:13:13 43736 dinov2 helpers.py:102]   [100/626]  eta: 0:06:53    time: 0.559976  data: 0.047168  max mem: 2850
I20240614 10:13:18 43736 dinov2 helpers.py:102]   [110/626]  eta: 0:06:33    time: 0.517440  data: 0.000829  max mem: 2850
I20240614 10:13:23 43736 dinov2 helpers.py:102]   [120/626]  eta: 0:06:15    time: 0.511719  data: 0.000644  max mem: 2850
I20240614 10:13:28 43736 dinov2 helpers.py:102]   [130/626]  eta: 0:05:58    time: 0.509583  data: 0.010409  max mem: 2850
I20240614 10:13:34 43736 dinov2 helpers.py:102]   [140/626]  eta: 0:05:45    time: 0.529068  data: 0.052915  max mem: 2850
I20240614 10:13:39 43736 dinov2 helpers.py:102]   [150/626]  eta: 0:05:33    time: 0.550808  data: 0.043140  max mem: 2850
I20240614 10:13:45 43736 dinov2 helpers.py:102]   [160/626]  eta: 0:05:21    time: 0.540062  data: 0.014952  max mem: 2850
I20240614 10:13:50 43736 dinov2 helpers.py:102]   [170/626]  eta: 0:05:10    time: 0.528606  data: 0.073491  max mem: 2850
I20240614 10:13:55 43736 dinov2 helpers.py:102]   [180/626]  eta: 0:05:00    time: 0.535558  data: 0.157294  max mem: 2850
I20240614 10:14:01 43736 dinov2 helpers.py:102]   [190/626]  eta: 0:04:50    time: 0.556332  data: 0.203052  max mem: 2850
I20240614 10:14:07 43736 dinov2 helpers.py:102]   [200/626]  eta: 0:04:42    time: 0.571337  data: 0.229493  max mem: 2850
I20240614 10:14:13 43736 dinov2 helpers.py:102]   [210/626]  eta: 0:04:35    time: 0.612336  data: 0.196674  max mem: 2850
I20240614 10:14:18 43736 dinov2 helpers.py:102]   [220/626]  eta: 0:04:25    time: 0.575174  data: 0.168267  max mem: 2850
I20240614 10:14:23 43736 dinov2 helpers.py:102]   [230/626]  eta: 0:04:16    time: 0.503713  data: 0.276803  max mem: 2850
I20240614 10:14:29 43736 dinov2 helpers.py:102]   [240/626]  eta: 0:04:09    time: 0.541089  data: 0.407618  max mem: 2850
I20240614 10:14:35 43736 dinov2 helpers.py:102]   [250/626]  eta: 0:04:02    time: 0.591228  data: 0.466475  max mem: 2850
I20240614 10:14:41 43736 dinov2 helpers.py:102]   [260/626]  eta: 0:03:55    time: 0.603865  data: 0.443106  max mem: 2850
I20240614 10:14:47 43736 dinov2 helpers.py:102]   [270/626]  eta: 0:03:47    time: 0.579324  data: 0.375926  max mem: 2850
I20240614 10:14:53 43736 dinov2 helpers.py:102]   [280/626]  eta: 0:03:40    time: 0.576311  data: 0.353648  max mem: 2850
I20240614 10:14:58 43736 dinov2 helpers.py:102]   [290/626]  eta: 0:03:33    time: 0.567097  data: 0.369387  max mem: 2850
I20240614 10:15:04 43736 dinov2 helpers.py:102]   [300/626]  eta: 0:03:25    time: 0.545479  data: 0.418260  max mem: 2850
I20240614 10:15:10 43736 dinov2 helpers.py:102]   [310/626]  eta: 0:03:19    time: 0.576034  data: 0.495315  max mem: 2850
I20240614 10:15:15 43736 dinov2 helpers.py:102]   [320/626]  eta: 0:03:12    time: 0.581346  data: 0.520834  max mem: 2850
I20240614 10:15:21 43736 dinov2 helpers.py:102]   [330/626]  eta: 0:03:05    time: 0.584054  data: 0.480815  max mem: 2850
I20240614 10:15:28 43736 dinov2 helpers.py:102]   [340/626]  eta: 0:02:59    time: 0.619908  data: 0.388614  max mem: 2850
I20240614 10:15:33 43736 dinov2 helpers.py:102]   [350/626]  eta: 0:02:52    time: 0.597568  data: 0.338157  max mem: 2850
I20240614 10:15:39 43736 dinov2 helpers.py:102]   [360/626]  eta: 0:02:46    time: 0.579399  data: 0.380235  max mem: 2850
I20240614 10:15:46 43736 dinov2 helpers.py:102]   [370/626]  eta: 0:02:40    time: 0.630183  data: 0.428066  max mem: 2850
I20240614 10:15:52 43736 dinov2 helpers.py:102]   [380/626]  eta: 0:02:33    time: 0.637546  data: 0.389045  max mem: 2850
I20240614 10:15:57 43736 dinov2 helpers.py:102]   [390/626]  eta: 0:02:27    time: 0.573603  data: 0.314876  max mem: 2850
I20240614 10:16:03 43736 dinov2 helpers.py:102]   [400/626]  eta: 0:02:20    time: 0.539300  data: 0.344476  max mem: 2850
I20240614 10:16:09 43736 dinov2 helpers.py:102]   [410/626]  eta: 0:02:14    time: 0.584208  data: 0.396536  max mem: 2850
I20240614 10:16:15 43736 dinov2 helpers.py:102]   [420/626]  eta: 0:02:07    time: 0.611292  data: 0.409061  max mem: 2850
I20240614 10:16:21 43736 dinov2 helpers.py:102]   [430/626]  eta: 0:02:01    time: 0.610312  data: 0.354826  max mem: 2850
I20240614 10:16:28 43736 dinov2 helpers.py:102]   [440/626]  eta: 0:01:55    time: 0.637133  data: 0.234274  max mem: 2850
I20240614 10:16:34 43736 dinov2 helpers.py:102]   [450/626]  eta: 0:01:49    time: 0.615159  data: 0.131134  max mem: 2850
I20240614 10:16:39 43736 dinov2 helpers.py:102]   [460/626]  eta: 0:01:42    time: 0.571539  data: 0.043003  max mem: 2850
I20240614 10:16:46 43736 dinov2 helpers.py:102]   [470/626]  eta: 0:01:36    time: 0.604766  data: 0.013414  max mem: 2850
I20240614 10:16:52 43736 dinov2 helpers.py:102]   [480/626]  eta: 0:01:30    time: 0.638845  data: 0.013424  max mem: 2850
I20240614 10:16:58 43736 dinov2 helpers.py:102]   [490/626]  eta: 0:01:24    time: 0.592562  data: 0.000731  max mem: 2850
I20240614 10:17:03 43736 dinov2 helpers.py:102]   [500/626]  eta: 0:01:17    time: 0.546854  data: 0.009033  max mem: 2850
I20240614 10:17:09 43736 dinov2 helpers.py:102]   [510/626]  eta: 0:01:11    time: 0.589133  data: 0.037561  max mem: 2850
I20240614 10:17:15 43736 dinov2 helpers.py:102]   [520/626]  eta: 0:01:05    time: 0.604220  data: 0.029269  max mem: 2850
I20240709 20:48:21 2286201 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240709 20:48:21 2286201 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240709 20:48:21 2286201 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240709 20:48:21 2286201 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240709 20:48:21 2286201 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240709 20:48:22 2286201 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240709 20:48:52 2286201 dinov2 loaders.py:88] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240709 20:48:52 2286201 dinov2 loaders.py:93] # of dataset samples: 1,281,167
I20240709 20:48:56 2286201 dinov2 loaders.py:88] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240709 20:48:56 2286201 dinov2 loaders.py:93] # of dataset samples: 1,281,167
I20240709 20:50:19 2286201 dinov2 knn.py:262] Extracting features for train set...
I20240709 20:50:29 2286201 dinov2 loaders.py:151] sampler: distributed
I20240709 20:50:29 2286201 dinov2 loaders.py:210] using PyTorch data loader
I20240709 20:50:29 2286201 dinov2 loaders.py:223] # of batches: 5,005
I20240709 20:51:20 2286201 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240709 20:51:20 2286201 dinov2 helpers.py:102]   [   0/5005]  eta: 2 days, 22:38:37    time: 50.812744  data: 20.185688  max mem: 2173
I20240709 20:51:28 2286201 dinov2 helpers.py:102]   [  10/5005]  eta: 7:29:02    time: 5.393799  data: 2.514015  max mem: 2847
I20240709 20:52:11 2286201 dinov2 helpers.py:102]   [  20/5005]  eta: 6:43:59    time: 2.565042  data: 2.495895  max mem: 2847
I20240709 20:52:59 2286201 dinov2 helpers.py:102]   [  30/5005]  eta: 6:42:20    time: 4.554566  data: 4.520814  max mem: 2847
I20240709 20:53:51 2286201 dinov2 helpers.py:102]   [  40/5005]  eta: 6:47:04    time: 4.978873  data: 4.949651  max mem: 2847
I20240709 20:56:13 2289612 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240709 20:56:13 2289612 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240709 20:56:13 2289612 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240709 20:56:13 2289612 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240709 20:56:13 2289612 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240709 20:56:14 2289612 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240709 20:56:14 2289612 dinov2 loaders.py:88] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240709 20:56:14 2289612 dinov2 loaders.py:93] # of dataset samples: 1,281,167
I20240709 20:56:14 2289612 dinov2 loaders.py:88] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240709 20:56:14 2289612 dinov2 loaders.py:93] # of dataset samples: 1,281,167
I20240709 20:56:14 2289612 dinov2 knn.py:262] Extracting features for train set...
I20240709 20:56:14 2289612 dinov2 loaders.py:151] sampler: distributed
I20240709 20:56:14 2289612 dinov2 loaders.py:210] using PyTorch data loader
I20240709 20:56:14 2289612 dinov2 loaders.py:223] # of batches: 5,005
I20240709 21:03:31 2289612 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240710 17:24:18 2831842 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240710 17:24:18 2831842 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240710 17:24:18 2831842 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240710 17:24:18 2831842 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240710 17:24:18 2831842 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240710 17:24:19 2831842 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240710 17:24:19 2831842 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:24:19 2831842 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:24:19 2831842 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:24:19 2831842 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:24:19 2831842 dinov2 knn.py:262] Extracting features for train set...
I20240710 17:24:23 2831842 dinov2 loaders.py:151] sampler: distributed
I20240710 17:24:23 2831842 dinov2 loaders.py:210] using PyTorch data loader
I20240710 17:24:23 2831842 dinov2 loaders.py:223] # of batches: 196
I20240710 17:24:46 2831842 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([50000, 384])
I20240710 17:25:05 2832800 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240710 17:25:05 2832800 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240710 17:25:05 2832800 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240710 17:25:05 2832800 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240710 17:25:05 2832800 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240710 17:25:05 2832800 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240710 17:25:05 2832800 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:25:05 2832800 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:25:05 2832800 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:25:05 2832800 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:25:05 2832800 dinov2 knn.py:262] Extracting features for train set...
I20240710 17:25:09 2832800 dinov2 loaders.py:151] sampler: distributed
I20240710 17:25:09 2832800 dinov2 loaders.py:210] using PyTorch data loader
I20240710 17:25:09 2832800 dinov2 loaders.py:223] # of batches: 196
I20240710 17:25:17 2832800 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([50000, 384])
I20240710 17:25:17 2832800 dinov2 helpers.py:102]   [  0/196]  eta: 0:27:14    time: 8.337935  data: 3.537779  max mem: 959
I20240710 17:25:18 2832800 dinov2 helpers.py:102]   [ 10/196]  eta: 0:02:41    time: 0.869901  data: 0.321980  max mem: 1035
I20240710 17:25:23 2832800 dinov2 helpers.py:102]   [ 20/196]  eta: 0:01:55    time: 0.270959  data: 0.191773  max mem: 1035
I20240710 17:25:28 2832800 dinov2 helpers.py:102]   [ 30/196]  eta: 0:01:40    time: 0.458037  data: 0.423315  max mem: 1035
I20240710 17:25:32 2832800 dinov2 helpers.py:102]   [ 40/196]  eta: 0:01:28    time: 0.478357  data: 0.443639  max mem: 1035
I20240710 17:25:37 2832800 dinov2 helpers.py:102]   [ 50/196]  eta: 0:01:19    time: 0.455959  data: 0.423319  max mem: 1035
I20240710 17:25:42 2832800 dinov2 helpers.py:102]   [ 60/196]  eta: 0:01:14    time: 0.499217  data: 0.467959  max mem: 1035
I20240710 17:25:47 2832800 dinov2 helpers.py:102]   [ 70/196]  eta: 0:01:07    time: 0.507967  data: 0.474134  max mem: 1035
I20240710 17:25:52 2832800 dinov2 helpers.py:102]   [ 80/196]  eta: 0:01:01    time: 0.475116  data: 0.442062  max mem: 1035
I20240710 17:25:56 2832800 dinov2 helpers.py:102]   [ 90/196]  eta: 0:00:55    time: 0.479748  data: 0.446849  max mem: 1035
I20240710 17:26:01 2832800 dinov2 helpers.py:102]   [100/196]  eta: 0:00:49    time: 0.469003  data: 0.434711  max mem: 1035
I20240710 17:26:06 2832800 dinov2 helpers.py:102]   [110/196]  eta: 0:00:44    time: 0.472405  data: 0.439553  max mem: 1035
I20240710 17:26:11 2832800 dinov2 helpers.py:102]   [120/196]  eta: 0:00:38    time: 0.485289  data: 0.454669  max mem: 1035
I20240710 17:26:15 2832800 dinov2 helpers.py:102]   [130/196]  eta: 0:00:33    time: 0.476306  data: 0.446920  max mem: 1035
I20240710 17:26:20 2832800 dinov2 helpers.py:102]   [140/196]  eta: 0:00:28    time: 0.474321  data: 0.444541  max mem: 1035
I20240710 17:26:25 2832800 dinov2 helpers.py:102]   [150/196]  eta: 0:00:23    time: 0.460767  data: 0.431600  max mem: 1035
I20240710 17:26:29 2832800 dinov2 helpers.py:102]   [160/196]  eta: 0:00:17    time: 0.449901  data: 0.423377  max mem: 1035
I20240710 17:26:34 2832800 dinov2 helpers.py:102]   [170/196]  eta: 0:00:12    time: 0.453517  data: 0.428822  max mem: 1035
I20240710 17:26:39 2832800 dinov2 helpers.py:102]   [180/196]  eta: 0:00:07    time: 0.465291  data: 0.440434  max mem: 1035
I20240710 17:26:43 2832800 dinov2 helpers.py:102]   [190/196]  eta: 0:00:02    time: 0.468980  data: 0.444530  max mem: 1035
I20240710 17:26:46 2832800 dinov2 helpers.py:102]   [195/196]  eta: 0:00:00    time: 0.518442  data: 0.446753  max mem: 1035
I20240710 17:26:47 2832800 dinov2 helpers.py:130]  Total time: 0:01:38 (0.502229 s / it)
I20240710 17:26:47 2832800 dinov2 utils.py:141] Features shape: (50000, 384)
I20240710 17:26:47 2832800 dinov2 utils.py:142] Labels shape: (50000,)
I20240710 17:26:54 2832800 dinov2 knn.py:266] Train features created, shape torch.Size([50000, 384]).
I20240710 17:27:05 2832800 dinov2 loaders.py:151] sampler: distributed
I20240710 17:27:05 2832800 dinov2 loaders.py:210] using PyTorch data loader
I20240710 17:27:05 2832800 dinov2 loaders.py:223] # of batches: 196
I20240710 17:29:19 2832800 dinov2 knn.py:301] Start the k-NN classification.
I20240710 17:29:23 2832800 dinov2 helpers.py:102] Test:  [  0/196]  eta: 0:10:59    time: 3.362667  data: 3.079344  max mem: 1035
I20240710 17:29:28 2832800 dinov2 helpers.py:102] Test:  [ 10/196]  eta: 0:02:23    time: 0.770187  data: 0.515283  max mem: 1037
I20240710 17:29:33 2832800 dinov2 helpers.py:102] Test:  [ 20/196]  eta: 0:01:47    time: 0.475372  data: 0.222441  max mem: 1037
I20240710 17:29:37 2832800 dinov2 helpers.py:102] Test:  [ 30/196]  eta: 0:01:29    time: 0.412498  data: 0.159403  max mem: 1037
I20240710 17:29:40 2832800 dinov2 helpers.py:102] Test:  [ 40/196]  eta: 0:01:18    time: 0.382931  data: 0.131379  max mem: 1037
I20240710 17:29:44 2832800 dinov2 helpers.py:102] Test:  [ 50/196]  eta: 0:01:09    time: 0.375986  data: 0.126127  max mem: 1037
I20240710 17:29:48 2832800 dinov2 helpers.py:102] Test:  [ 60/196]  eta: 0:01:02    time: 0.385562  data: 0.136950  max mem: 1037
I20240710 17:29:52 2832800 dinov2 helpers.py:102] Test:  [ 70/196]  eta: 0:00:57    time: 0.403484  data: 0.156401  max mem: 1037
I20240710 17:29:57 2832800 dinov2 helpers.py:102] Test:  [ 80/196]  eta: 0:00:52    time: 0.431750  data: 0.183401  max mem: 1037
I20240710 17:30:01 2832800 dinov2 helpers.py:102] Test:  [ 90/196]  eta: 0:00:47    time: 0.421990  data: 0.170846  max mem: 1037
I20240710 17:30:04 2832800 dinov2 helpers.py:102] Test:  [100/196]  eta: 0:00:42    time: 0.389446  data: 0.138656  max mem: 1037
I20240710 17:30:08 2832800 dinov2 helpers.py:102] Test:  [110/196]  eta: 0:00:37    time: 0.390089  data: 0.139111  max mem: 1037
I20240710 17:30:13 2832800 dinov2 helpers.py:102] Test:  [120/196]  eta: 0:00:33    time: 0.414131  data: 0.162140  max mem: 1037
I20240710 17:30:17 2832800 dinov2 helpers.py:102] Test:  [130/196]  eta: 0:00:28    time: 0.409369  data: 0.157374  max mem: 1037
I20240710 17:30:21 2832800 dinov2 helpers.py:102] Test:  [140/196]  eta: 0:00:24    time: 0.407397  data: 0.167380  max mem: 1037
I20240710 17:30:25 2832800 dinov2 helpers.py:102] Test:  [150/196]  eta: 0:00:19    time: 0.405614  data: 0.169036  max mem: 1037
I20240710 17:30:28 2832800 dinov2 helpers.py:102] Test:  [160/196]  eta: 0:00:15    time: 0.369820  data: 0.120947  max mem: 1037
I20240710 17:30:32 2832800 dinov2 helpers.py:102] Test:  [170/196]  eta: 0:00:11    time: 0.375385  data: 0.124121  max mem: 1037
I20240710 17:30:36 2832800 dinov2 helpers.py:102] Test:  [180/196]  eta: 0:00:06    time: 0.381066  data: 0.130762  max mem: 1037
I20240710 17:30:40 2832800 dinov2 helpers.py:102] Test:  [190/196]  eta: 0:00:02    time: 0.370305  data: 0.119030  max mem: 1037
I20240710 17:30:42 2832800 dinov2 helpers.py:102] Test:  [195/196]  eta: 0:00:00    time: 0.376312  data: 0.133173  max mem: 1037
I20240710 17:30:42 2832800 dinov2 helpers.py:130] Test: Total time: 0:01:21 (0.417578 s / it)
I20240710 17:30:42 2832800 dinov2 utils.py:79] Averaged stats: 
I20240710 17:33:19 2837781 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240710 17:33:19 2837781 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240710 17:33:19 2837781 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240710 17:33:19 2837781 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240710 17:33:19 2837781 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240710 17:33:20 2837781 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240710 17:33:20 2837781 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:33:20 2837781 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:33:20 2837781 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:33:20 2837781 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:33:20 2837781 dinov2 knn.py:262] Extracting features for train set...
I20240710 17:33:38 2838034 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240710 17:33:38 2838034 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240710 17:33:38 2838034 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240710 17:33:38 2838034 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240710 17:33:38 2838034 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240710 17:33:38 2838034 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240710 17:33:38 2838034 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:33:38 2838034 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:33:38 2838034 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240710 17:33:38 2838034 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240710 17:33:38 2838034 dinov2 knn.py:262] Extracting features for train set...
I20240710 17:33:38 2838034 dinov2 loaders.py:151] sampler: distributed
I20240710 17:33:38 2838034 dinov2 loaders.py:210] using PyTorch data loader
I20240710 17:33:38 2838034 dinov2 loaders.py:223] # of batches: 196
I20240710 17:33:47 2838034 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([50000, 384])
I20240710 17:33:47 2838034 dinov2 helpers.py:102]   [  0/196]  eta: 0:27:44    time: 8.493887  data: 3.375392  max mem: 959
I20240710 17:33:48 2838034 dinov2 helpers.py:102]   [ 10/196]  eta: 0:02:44    time: 0.885451  data: 0.307145  max mem: 1035
I20240710 17:33:51 2838034 dinov2 helpers.py:102]   [ 20/196]  eta: 0:01:48    time: 0.223631  data: 0.151494  max mem: 1035
I20240710 17:33:56 2838034 dinov2 helpers.py:102]   [ 30/196]  eta: 0:01:31    time: 0.364942  data: 0.345815  max mem: 1035
I20240710 17:33:59 2838034 dinov2 helpers.py:102]   [ 40/196]  eta: 0:01:19    time: 0.398593  data: 0.377054  max mem: 1035
I20240710 17:34:03 2838034 dinov2 helpers.py:102]   [ 50/196]  eta: 0:01:10    time: 0.377713  data: 0.355147  max mem: 1035
I20240710 17:34:08 2838034 dinov2 helpers.py:102]   [ 60/196]  eta: 0:01:04    time: 0.410460  data: 0.389871  max mem: 1035
I20240710 17:34:12 2838034 dinov2 helpers.py:102]   [ 70/196]  eta: 0:00:58    time: 0.431273  data: 0.412075  max mem: 1035
I20240710 17:34:16 2838034 dinov2 helpers.py:102]   [ 80/196]  eta: 0:00:53    time: 0.408451  data: 0.387975  max mem: 1035
I20240710 17:34:20 2838034 dinov2 helpers.py:102]   [ 90/196]  eta: 0:00:48    time: 0.401483  data: 0.380038  max mem: 1035
I20240710 17:34:24 2838034 dinov2 helpers.py:102]   [100/196]  eta: 0:00:43    time: 0.400341  data: 0.380525  max mem: 1035
I20240710 17:34:28 2838034 dinov2 helpers.py:102]   [110/196]  eta: 0:00:38    time: 0.409092  data: 0.390782  max mem: 1035
I20240710 17:34:32 2838034 dinov2 helpers.py:102]   [120/196]  eta: 0:00:33    time: 0.414617  data: 0.396067  max mem: 1035
I20240710 17:34:36 2838034 dinov2 helpers.py:102]   [130/196]  eta: 0:00:28    time: 0.398596  data: 0.379139  max mem: 1035
I20240710 17:34:40 2838034 dinov2 helpers.py:102]   [140/196]  eta: 0:00:24    time: 0.408589  data: 0.389898  max mem: 1035
I20240710 17:34:44 2838034 dinov2 helpers.py:102]   [150/196]  eta: 0:00:19    time: 0.409788  data: 0.391622  max mem: 1035
I20240710 17:34:48 2838034 dinov2 helpers.py:102]   [160/196]  eta: 0:00:15    time: 0.381134  data: 0.363056  max mem: 1035
I20240710 17:34:52 2838034 dinov2 helpers.py:102]   [170/196]  eta: 0:00:11    time: 0.388044  data: 0.368760  max mem: 1035
I20240710 17:34:56 2838034 dinov2 helpers.py:102]   [180/196]  eta: 0:00:06    time: 0.393634  data: 0.373840  max mem: 1035
I20240710 17:35:00 2838034 dinov2 helpers.py:102]   [190/196]  eta: 0:00:02    time: 0.385922  data: 0.366498  max mem: 1035
I20240710 17:35:02 2838034 dinov2 helpers.py:102]   [195/196]  eta: 0:00:00    time: 0.419799  data: 0.378558  max mem: 1035
I20240710 17:35:03 2838034 dinov2 helpers.py:130]  Total time: 0:01:24 (0.431976 s / it)
I20240710 17:35:03 2838034 dinov2 utils.py:141] Features shape: (50000, 384)
I20240710 17:35:03 2838034 dinov2 utils.py:142] Labels shape: (50000,)
I20240710 17:35:03 2838034 dinov2 knn.py:266] Train features created, shape torch.Size([50000, 384]).
I20240710 17:35:03 2838034 dinov2 loaders.py:151] sampler: distributed
I20240710 17:35:03 2838034 dinov2 loaders.py:210] using PyTorch data loader
I20240710 17:35:03 2838034 dinov2 loaders.py:223] # of batches: 196
I20240710 17:35:04 2838034 dinov2 knn.py:301] Start the k-NN classification.
I20240721 21:34:39 2696102 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 21:34:39 2696102 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 21:34:39 2696102 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 21:34:39 2696102 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 21:34:39 2696102 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 21:34:40 2696102 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 21:34:40 2696102 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 21:34:40 2696102 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240721 21:34:40 2696102 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 21:34:40 2696102 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240721 21:34:40 2696102 dinov2 knn.py:262] Extracting features for train set...
I20240721 21:34:53 2696102 dinov2 loaders.py:151] sampler: distributed
I20240721 21:34:53 2696102 dinov2 loaders.py:210] using PyTorch data loader
I20240721 21:34:53 2696102 dinov2 loaders.py:223] # of batches: 196
I20240721 21:35:00 2696102 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([50000, 384])
I20240721 21:35:00 2696102 dinov2 helpers.py:103]   [  0/196]  eta: 0:22:25    time: 6.863086  data: 3.793258  max mem: 959
I20240721 21:35:02 2696102 dinov2 helpers.py:103]   [ 10/196]  eta: 0:02:31    time: 0.815186  data: 0.509604  max mem: 1035
I20240721 21:35:07 2696102 dinov2 helpers.py:103]   [ 20/196]  eta: 0:01:54    time: 0.339667  data: 0.308104  max mem: 1035
I20240721 21:35:11 2696102 dinov2 helpers.py:103]   [ 30/196]  eta: 0:01:37    time: 0.464366  data: 0.430331  max mem: 1035
I20240721 21:35:16 2696102 dinov2 helpers.py:103]   [ 40/196]  eta: 0:01:27    time: 0.463301  data: 0.429914  max mem: 1035
I20240721 21:35:21 2696102 dinov2 helpers.py:103]   [ 50/196]  eta: 0:01:19    time: 0.478851  data: 0.446167  max mem: 1035
I20240721 21:35:27 2696102 dinov2 helpers.py:103]   [ 60/196]  eta: 0:01:15    time: 0.546222  data: 0.514534  max mem: 1035
I20240721 21:35:33 2696102 dinov2 helpers.py:103]   [ 70/196]  eta: 0:01:10    time: 0.590053  data: 0.561236  max mem: 1035
I20240721 21:35:39 2696102 dinov2 helpers.py:103]   [ 80/196]  eta: 0:01:06    time: 0.622862  data: 0.597006  max mem: 1035
I20240721 21:35:45 2696102 dinov2 helpers.py:103]   [ 90/196]  eta: 0:01:00    time: 0.608407  data: 0.584235  max mem: 1035
I20240721 21:35:50 2696102 dinov2 helpers.py:103]   [100/196]  eta: 0:00:54    time: 0.533925  data: 0.510057  max mem: 1035
I20240721 21:35:56 2696102 dinov2 helpers.py:103]   [110/196]  eta: 0:00:48    time: 0.536521  data: 0.512221  max mem: 1035
I20240721 21:36:01 2696102 dinov2 helpers.py:103]   [120/196]  eta: 0:00:42    time: 0.566545  data: 0.542121  max mem: 1035
I20240721 21:36:07 2696102 dinov2 helpers.py:103]   [130/196]  eta: 0:00:37    time: 0.566023  data: 0.540051  max mem: 1035
I20240721 21:36:12 2696102 dinov2 helpers.py:103]   [140/196]  eta: 0:00:31    time: 0.549440  data: 0.520772  max mem: 1035
I20240721 21:36:18 2696102 dinov2 helpers.py:103]   [150/196]  eta: 0:00:25    time: 0.530062  data: 0.491981  max mem: 1035
I20240721 21:36:23 2696102 dinov2 helpers.py:103]   [160/196]  eta: 0:00:20    time: 0.523168  data: 0.487117  max mem: 1035
I20240721 21:36:29 2696102 dinov2 helpers.py:103]   [170/196]  eta: 0:00:14    time: 0.551303  data: 0.526364  max mem: 1035
I20240721 21:36:34 2696102 dinov2 helpers.py:103]   [180/196]  eta: 0:00:08    time: 0.563912  data: 0.537447  max mem: 1035
I20240721 21:36:41 2696102 dinov2 helpers.py:103]   [190/196]  eta: 0:00:03    time: 0.602176  data: 0.575502  max mem: 1035
I20240721 21:36:42 2696102 dinov2 helpers.py:103]   [195/196]  eta: 0:00:00    time: 0.522937  data: 0.495290  max mem: 1035
I20240721 21:36:43 2696102 dinov2 helpers.py:132]  Total time: 0:01:49 (0.558445 s / it)
I20240721 21:36:43 2696102 dinov2 utils.py:141] Features shape: (50000, 384)
I20240721 21:36:43 2696102 dinov2 utils.py:142] Labels shape: (50000,)
I20240721 21:36:56 2696102 dinov2 knn.py:266] Train features created, shape torch.Size([50000, 384]).
I20240721 21:37:20 2696102 dinov2 loaders.py:151] sampler: distributed
I20240721 21:37:20 2696102 dinov2 loaders.py:210] using PyTorch data loader
I20240721 21:37:20 2696102 dinov2 loaders.py:223] # of batches: 196
I20240721 21:40:17 2699102 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 21:40:17 2699102 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 21:40:17 2699102 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 21:40:17 2699102 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 21:40:17 2699102 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 21:40:18 2699102 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 21:40:18 2699102 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 21:40:18 2699102 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240721 21:40:18 2699102 dinov2 loaders.py:88] using dataset: "ImageNet:split=VAL:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 21:40:18 2699102 dinov2 loaders.py:93] # of dataset samples: 50,000
I20240721 21:40:18 2699102 dinov2 knn.py:262] Extracting features for train set...
I20240721 21:40:18 2699102 dinov2 loaders.py:151] sampler: distributed
I20240721 21:40:18 2699102 dinov2 loaders.py:210] using PyTorch data loader
I20240721 21:40:18 2699102 dinov2 loaders.py:223] # of batches: 196
I20240721 22:21:49 2711544 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:21:49 2711544 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters
val_dataset_str: Sentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters
I20240721 22:21:49 2711544 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:21:49 2711544 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:21:49 2711544 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:21:49 2711544 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:21:49 2711544 dinov2 loaders.py:88] using dataset: "Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters"
I20240721 22:23:33 2712424 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:23:33 2712424 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: Sentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:23:33 2712424 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:23:33 2712424 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:23:33 2712424 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:23:33 2712424 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:23:33 2712424 dinov2 loaders.py:88] using dataset: "Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:23:34 2712424 dinov2 loaders.py:93] # of dataset samples: 164,544
I20240721 22:23:34 2712424 dinov2 loaders.py:88] using dataset: "Sentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:28:04 2714083 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:28:04 2714083 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: Sentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:28:04 2714083 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:28:04 2714083 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:28:04 2714083 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:28:04 2714083 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:28:04 2714083 dinov2 loaders.py:92] using dataset: "Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:28:05 2714083 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:28:05 2714083 dinov2 loaders.py:92] using dataset: "Sentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:28:43 2714671 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:28:43 2714671 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:28:43 2714671 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:28:43 2714671 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:28:43 2714671 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:28:43 2714671 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:28:43 2714671 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:28:44 2714671 dinov2 loaders.py:97] # of dataset samples: 164,622
I20240721 22:28:44 2714671 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:31:22 2715829 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:31:22 2715829 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:31:22 2715829 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:31:22 2715829 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:31:23 2715829 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:31:23 2715829 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:31:23 2715829 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:31:24 2715829 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:31:24 2715829 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=VAL:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:32:23 2716403 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:32:23 2716403 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:32:23 2716403 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:32:23 2716403 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:32:23 2716403 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:32:24 2716403 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:32:24 2716403 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:32:25 2716403 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:32:25 2716403 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:32:25 2716403 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:32:25 2716403 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:34:19 2716403 dinov2 loaders.py:155] sampler: distributed
I20240721 22:34:19 2716403 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:34:19 2716403 dinov2 loaders.py:227] # of batches: 643
I20240721 22:35:22 2718251 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:35:22 2718251 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:35:22 2718251 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:35:22 2718251 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:35:22 2718251 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:35:23 2718251 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:35:23 2718251 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:35:24 2718251 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:35:24 2718251 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:35:24 2718251 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:35:24 2718251 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:35:24 2718251 dinov2 loaders.py:155] sampler: distributed
I20240721 22:35:24 2718251 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:35:24 2718251 dinov2 loaders.py:227] # of batches: 643
W20240721 22:36:02 2718762 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:36:02 2718762 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:36:02 2718767 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:36:02 2718767 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:36:03 2718770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:36:03 2718770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:36:04 2718773 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:36:04 2718773 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:36:05 2718776 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:36:05 2718776 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

I20240721 22:39:40 2720767 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:39:40 2720767 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:39:40 2720767 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:39:40 2720767 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:39:40 2720767 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:39:41 2720767 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:39:41 2720767 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:39:42 2720767 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:39:42 2720767 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:39:42 2720767 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:39:42 2720767 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:39:42 2720767 dinov2 loaders.py:155] sampler: distributed
I20240721 22:39:42 2720767 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:39:42 2720767 dinov2 loaders.py:227] # of batches: 643
W20240721 22:39:43 2720987 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:39:44 2720992 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:39:44 2720995 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:39:45 2720998 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:39:46 2721001 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:42:21 2720987 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:42:21 2720987 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:42:22 2720992 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:42:22 2720992 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240721 22:42:48 2722631 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:42:48 2722631 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:42:48 2722631 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:42:48 2722631 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:42:48 2722631 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:42:49 2722631 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:42:49 2722631 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:50:36 2725547 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:50:36 2725547 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:50:36 2725547 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:50:36 2725547 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:50:36 2725547 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:50:37 2725547 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:50:37 2725547 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:50:38 2725547 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:50:38 2725547 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:50:38 2725547 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:50:38 2725547 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:50:38 2725547 dinov2 loaders.py:155] sampler: distributed
I20240721 22:50:38 2725547 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:50:38 2725547 dinov2 loaders.py:227] # of batches: 643
W20240721 22:50:39 2725770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:50:40 2725775 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:50:40 2725778 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:50:41 2725781 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:50:42 2725784 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:51:49 2725770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:51:49 2725770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:51:50 2725775 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:51:50 2725775 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240721 22:52:50 2727049 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:52:50 2727049 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:52:50 2727049 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:52:51 2727049 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:52:51 2727049 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:52:51 2727049 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:52:51 2727049 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:52:52 2727049 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:52:52 2727049 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:52:52 2727049 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:52:52 2727049 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:52:52 2727049 dinov2 loaders.py:155] sampler: distributed
I20240721 22:52:52 2727049 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:52:52 2727049 dinov2 loaders.py:227] # of batches: 643
W20240721 22:52:53 2727260 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:52:54 2727265 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:52:54 2727268 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:52:55 2727271 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:52:56 2727274 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:54:00 2727260 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:54:14 2727260 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:54:14 2727260 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:54:17 2727265 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:54:17 2727265 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:54:18 2727268 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:54:18 2727268 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:54:18 2727271 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

W20240721 22:54:18 2727274 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(

I20240721 22:56:38 2729187 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 22:56:38 2729187 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 22:56:38 2729187 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240721 22:56:38 2729187 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  in_chans: 3
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240721 22:56:38 2729187 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 22:56:40 2729187 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240721 22:56:40 2729187 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:56:41 2729187 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 22:56:41 2729187 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 22:56:41 2729187 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 22:56:41 2729187 dinov2 knn.py:262] Extracting features for train set...
I20240721 22:56:41 2729187 dinov2 loaders.py:155] sampler: distributed
I20240721 22:56:41 2729187 dinov2 loaders.py:214] using PyTorch data loader
I20240721 22:56:41 2729187 dinov2 loaders.py:227] # of batches: 643
W20240721 22:57:49 2729770 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:57:50 2729775 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:57:51 2729778 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:57:51 2729781 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 22:57:52 2729784 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240721 23:01:40 2731700 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 23:01:40 2731700 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 23:01:40 2731700 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240721 23:01:40 2731700 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240721 23:01:40 2731700 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 23:01:42 2731700 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240721 23:01:42 2731700 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240721 23:01:42 2731700 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 23:01:43 2731700 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 23:01:43 2731700 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 23:01:43 2731700 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 23:01:43 2731700 dinov2 knn.py:262] Extracting features for train set...
I20240721 23:01:43 2731700 dinov2 loaders.py:155] sampler: distributed
I20240721 23:01:43 2731700 dinov2 loaders.py:214] using PyTorch data loader
I20240721 23:01:43 2731700 dinov2 loaders.py:227] # of batches: 643
I20240721 23:02:29 2732252 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240721 23:02:29 2732252 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240721 23:02:29 2732252 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240721 23:02:29 2732252 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240721 23:02:29 2732252 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240721 23:02:31 2732252 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240721 23:02:31 2732252 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240721 23:02:31 2732252 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 23:02:32 2732252 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240721 23:02:32 2732252 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240721 23:02:32 2732252 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240721 23:02:32 2732252 dinov2 knn.py:262] Extracting features for train set...
I20240721 23:02:32 2732252 dinov2 loaders.py:155] sampler: distributed
I20240721 23:02:32 2732252 dinov2 loaders.py:214] using PyTorch data loader
I20240721 23:02:32 2732252 dinov2 loaders.py:227] # of batches: 643
W20240721 23:02:33 2732474 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:02:33 2732479 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:02:34 2732482 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:02:35 2732485 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:02:35 2732488 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240721 23:03:06 2732252 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([164544, 768])
I20240721 23:03:06 2732252 dinov2 helpers.py:103]   [  0/643]  eta: 6:04:30    time: 34.013859  data: 20.846491  max mem: 8979
I20240721 23:03:17 2732252 dinov2 helpers.py:103]   [ 10/643]  eta: 0:43:05    time: 4.084423  data: 2.839566  max mem: 9469
I20240721 23:03:48 2732252 dinov2 helpers.py:103]   [ 20/643]  eta: 0:37:38    time: 2.106533  data: 2.069978  max mem: 9469
I20240721 23:04:19 2732252 dinov2 helpers.py:103]   [ 30/643]  eta: 0:35:10    time: 3.089193  data: 3.068915  max mem: 9469
I20240721 23:04:49 2732252 dinov2 helpers.py:103]   [ 40/643]  eta: 0:33:33    time: 3.038969  data: 3.016749  max mem: 9469
I20240721 23:05:19 2732252 dinov2 helpers.py:103]   [ 50/643]  eta: 0:32:23    time: 3.021246  data: 2.997004  max mem: 9469
I20240721 23:05:49 2732252 dinov2 helpers.py:103]   [ 60/643]  eta: 0:31:24    time: 3.012172  data: 2.984228  max mem: 9469
I20240721 23:06:19 2732252 dinov2 helpers.py:103]   [ 70/643]  eta: 0:30:32    time: 2.994035  data: 2.954770  max mem: 9469
I20240721 23:06:48 2732252 dinov2 helpers.py:103]   [ 80/643]  eta: 0:29:42    time: 2.965819  data: 2.925828  max mem: 9469
I20240721 23:07:18 2732252 dinov2 helpers.py:103]   [ 90/643]  eta: 0:28:57    time: 2.942434  data: 2.902605  max mem: 9469
I20240721 23:07:48 2732252 dinov2 helpers.py:103]   [100/643]  eta: 0:28:17    time: 2.964450  data: 2.912051  max mem: 9469
I20240721 23:08:17 2732252 dinov2 helpers.py:103]   [110/643]  eta: 0:27:37    time: 2.970742  data: 2.924230  max mem: 9469
I20240721 23:08:47 2732252 dinov2 helpers.py:103]   [120/643]  eta: 0:26:59    time: 2.951233  data: 2.901923  max mem: 9469
I20240721 23:09:16 2732252 dinov2 helpers.py:103]   [130/643]  eta: 0:26:22    time: 2.936337  data: 2.888652  max mem: 9469
I20240721 23:09:45 2732252 dinov2 helpers.py:103]   [140/643]  eta: 0:25:46    time: 2.941254  data: 2.906750  max mem: 9469
I20240721 23:10:15 2732252 dinov2 helpers.py:103]   [150/643]  eta: 0:25:13    time: 2.979177  data: 2.943765  max mem: 9469
I20240721 23:10:43 2732252 dinov2 helpers.py:103]   [160/643]  eta: 0:24:34    time: 2.887789  data: 2.851984  max mem: 9469
I20240721 23:11:13 2732252 dinov2 helpers.py:103]   [170/643]  eta: 0:24:02    time: 2.886889  data: 2.847684  max mem: 9469
I20240721 23:11:42 2732252 dinov2 helpers.py:103]   [180/643]  eta: 0:23:28    time: 2.953837  data: 2.916087  max mem: 9469
I20240721 23:12:13 2732252 dinov2 helpers.py:103]   [190/643]  eta: 0:22:59    time: 3.006410  data: 2.966420  max mem: 9469
I20240721 23:12:41 2732252 dinov2 helpers.py:103]   [200/643]  eta: 0:22:22    time: 2.923199  data: 2.886009  max mem: 9469
I20240721 23:13:09 2732252 dinov2 helpers.py:103]   [210/643]  eta: 0:21:47    time: 2.788269  data: 2.756580  max mem: 9469
I20240721 23:13:38 2732252 dinov2 helpers.py:103]   [220/643]  eta: 0:21:15    time: 2.864654  data: 2.831752  max mem: 9469
I20240721 23:14:08 2732252 dinov2 helpers.py:103]   [230/643]  eta: 0:20:45    time: 2.958641  data: 2.926130  max mem: 9469
I20240721 23:14:37 2732252 dinov2 helpers.py:103]   [240/643]  eta: 0:20:12    time: 2.940100  data: 2.906972  max mem: 9469
I20240721 23:15:07 2732252 dinov2 helpers.py:103]   [250/643]  eta: 0:19:42    time: 2.933017  data: 2.901083  max mem: 9469
I20240721 23:15:37 2732252 dinov2 helpers.py:103]   [260/643]  eta: 0:19:11    time: 2.981684  data: 2.953026  max mem: 9469
I20240721 23:16:07 2732252 dinov2 helpers.py:103]   [270/643]  eta: 0:18:41    time: 3.001818  data: 2.974905  max mem: 9469
I20240721 23:16:37 2732252 dinov2 helpers.py:103]   [280/643]  eta: 0:18:12    time: 3.037154  data: 3.010652  max mem: 9469
I20240721 23:17:08 2732252 dinov2 helpers.py:103]   [290/643]  eta: 0:17:42    time: 3.026809  data: 2.999297  max mem: 9469
I20240721 23:17:37 2732252 dinov2 helpers.py:103]   [300/643]  eta: 0:17:11    time: 2.989851  data: 2.960436  max mem: 9469
I20240721 23:18:06 2732252 dinov2 helpers.py:103]   [310/643]  eta: 0:16:40    time: 2.938118  data: 2.909069  max mem: 9469
I20240721 23:18:36 2732252 dinov2 helpers.py:103]   [320/643]  eta: 0:16:09    time: 2.929865  data: 2.900082  max mem: 9469
I20240721 23:19:07 2732252 dinov2 helpers.py:103]   [330/643]  eta: 0:15:40    time: 3.030206  data: 2.994570  max mem: 9469
I20240721 23:19:38 2732252 dinov2 helpers.py:103]   [340/643]  eta: 0:15:11    time: 3.127347  data: 3.089855  max mem: 9469
I20240721 23:20:08 2732252 dinov2 helpers.py:103]   [350/643]  eta: 0:14:41    time: 3.051364  data: 3.017745  max mem: 9469
I20240721 23:20:39 2732252 dinov2 helpers.py:103]   [360/643]  eta: 0:14:12    time: 3.037174  data: 3.006145  max mem: 9469
I20240721 23:21:10 2732252 dinov2 helpers.py:103]   [370/643]  eta: 0:13:42    time: 3.112567  data: 3.084284  max mem: 9469
I20240721 23:21:41 2732252 dinov2 helpers.py:103]   [380/643]  eta: 0:13:12    time: 3.082285  data: 3.055131  max mem: 9469
I20240721 23:22:11 2732252 dinov2 helpers.py:103]   [390/643]  eta: 0:12:43    time: 3.065785  data: 3.038728  max mem: 9469
I20240721 23:22:43 2732252 dinov2 helpers.py:103]   [400/643]  eta: 0:12:13    time: 3.094872  data: 3.066133  max mem: 9469
I20240721 23:23:14 2732252 dinov2 helpers.py:103]   [410/643]  eta: 0:11:43    time: 3.109453  data: 3.080106  max mem: 9469
I20240721 23:23:45 2732252 dinov2 helpers.py:103]   [420/643]  eta: 0:11:14    time: 3.104366  data: 3.076550  max mem: 9469
I20240721 23:24:16 2732252 dinov2 helpers.py:103]   [430/643]  eta: 0:10:44    time: 3.098926  data: 3.071616  max mem: 9469
I20240721 23:24:47 2732252 dinov2 helpers.py:103]   [440/643]  eta: 0:10:14    time: 3.103154  data: 3.075007  max mem: 9469
I20240721 23:25:17 2732252 dinov2 helpers.py:103]   [450/643]  eta: 0:09:44    time: 3.067611  data: 3.039682  max mem: 9469
I20240721 23:25:48 2732252 dinov2 helpers.py:103]   [460/643]  eta: 0:09:14    time: 3.070558  data: 3.043344  max mem: 9469
I20240721 23:26:18 2732252 dinov2 helpers.py:103]   [470/643]  eta: 0:08:43    time: 3.046787  data: 3.018420  max mem: 9469
I20240721 23:26:48 2732252 dinov2 helpers.py:103]   [480/643]  eta: 0:08:13    time: 3.012746  data: 2.981364  max mem: 9469
I20240721 23:27:19 2732252 dinov2 helpers.py:103]   [490/643]  eta: 0:07:43    time: 3.035656  data: 2.995636  max mem: 9469
I20240721 23:27:50 2732252 dinov2 helpers.py:103]   [500/643]  eta: 0:07:13    time: 3.092734  data: 3.052765  max mem: 9469
I20240721 23:28:20 2732252 dinov2 helpers.py:103]   [510/643]  eta: 0:06:42    time: 3.063605  data: 3.028615  max mem: 9469
I20240721 23:28:50 2732252 dinov2 helpers.py:103]   [520/643]  eta: 0:06:12    time: 3.002864  data: 2.967287  max mem: 9469
I20240721 23:29:21 2732252 dinov2 helpers.py:103]   [530/643]  eta: 0:05:42    time: 3.034453  data: 3.002100  max mem: 9469
I20240721 23:29:52 2732252 dinov2 helpers.py:103]   [540/643]  eta: 0:05:12    time: 3.102623  data: 3.058948  max mem: 9469
I20240721 23:30:22 2732252 dinov2 helpers.py:103]   [550/643]  eta: 0:04:41    time: 3.070383  data: 3.028278  max mem: 9469
I20240721 23:30:54 2732252 dinov2 helpers.py:103]   [560/643]  eta: 0:04:11    time: 3.074869  data: 3.037076  max mem: 9469
I20240721 23:31:25 2732252 dinov2 helpers.py:103]   [570/643]  eta: 0:03:41    time: 3.160530  data: 3.118857  max mem: 9469
I20240721 23:31:54 2732252 dinov2 helpers.py:103]   [580/643]  eta: 0:03:11    time: 3.019489  data: 2.989872  max mem: 9469
I20240721 23:32:21 2732252 dinov2 helpers.py:103]   [590/643]  eta: 0:02:40    time: 2.779857  data: 2.756255  max mem: 9469
I20240721 23:32:45 2732252 dinov2 helpers.py:103]   [600/643]  eta: 0:02:09    time: 2.562110  data: 2.540811  max mem: 9469
I20240721 23:33:13 2732252 dinov2 helpers.py:103]   [610/643]  eta: 0:01:39    time: 2.582562  data: 2.561786  max mem: 9469
I20240721 23:33:39 2732252 dinov2 helpers.py:103]   [620/643]  eta: 0:01:09    time: 2.696417  data: 2.675472  max mem: 9469
I20240721 23:34:09 2732252 dinov2 helpers.py:103]   [630/643]  eta: 0:00:39    time: 2.830649  data: 2.790788  max mem: 9469
I20240721 23:34:40 2732252 dinov2 helpers.py:103]   [640/643]  eta: 0:00:09    time: 3.009845  data: 2.966897  max mem: 9469
I20240721 23:34:46 2732252 dinov2 helpers.py:103]   [642/643]  eta: 0:00:03    time: 3.170359  data: 2.805902  max mem: 9469
I20240721 23:34:47 2732252 dinov2 helpers.py:132]  Total time: 0:32:15 (3.009917 s / it)
I20240721 23:34:47 2732252 dinov2 utils.py:141] Features shape: (164544, 768)
I20240721 23:34:47 2732252 dinov2 utils.py:142] Labels shape: (164544,)
I20240721 23:34:47 2732252 dinov2 knn.py:266] Train features created, shape torch.Size([164544, 768]).
I20240721 23:34:47 2732252 dinov2 loaders.py:155] sampler: distributed
I20240721 23:34:47 2732252 dinov2 loaders.py:214] using PyTorch data loader
I20240721 23:34:47 2732252 dinov2 loaders.py:227] # of batches: 69
I20240721 23:34:47 2732252 dinov2 knn.py:301] Start the k-NN classification.
W20240721 23:34:48 2746753 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:34:49 2746758 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:34:50 2746761 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:34:50 2746765 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240721 23:34:51 2746768 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240721 23:35:05 2732252 dinov2 helpers.py:103] Test:  [ 0/69]  eta: 0:20:34    time: 17.895279  data: 16.339233  max mem: 9469
I20240721 23:35:38 2732252 dinov2 helpers.py:103] Test:  [10/69]  eta: 0:04:31    time: 4.593299  data: 3.072995  max mem: 9469
I20240721 23:36:08 2732252 dinov2 helpers.py:103] Test:  [20/69]  eta: 0:03:08    time: 3.146807  data: 1.630281  max mem: 9469
I20240721 23:36:39 2732252 dinov2 helpers.py:103] Test:  [30/69]  eta: 0:02:20    time: 3.060691  data: 1.542340  max mem: 9469
I20240721 23:37:11 2732252 dinov2 helpers.py:103] Test:  [40/69]  eta: 0:01:41    time: 3.139517  data: 1.620722  max mem: 9469
I20240721 23:37:44 2732252 dinov2 helpers.py:103] Test:  [50/69]  eta: 0:01:05    time: 3.262354  data: 1.741904  max mem: 9469
I20240721 23:38:17 2732252 dinov2 helpers.py:103] Test:  [60/69]  eta: 0:00:31    time: 3.328314  data: 1.806630  max mem: 9469
I20240721 23:38:42 2732252 dinov2 helpers.py:103] Test:  [68/69]  eta: 0:00:03    time: 3.370964  data: 1.804586  max mem: 9469
I20240721 23:38:42 2732252 dinov2 helpers.py:132] Test: Total time: 0:03:55 (3.405981 s / it)
I20240721 23:38:42 2732252 dinov2 utils.py:79] Averaged stats: 
I20240721 23:38:43 2732252 dinov2 knn.py:369] ('full', 10) classifier result: Top1: 91.45 Top5: 99.07
I20240721 23:38:43 2732252 dinov2 knn.py:369] ('full', 20) classifier result: Top1: 91.33 Top5: 99.44
I20240721 23:38:43 2732252 dinov2 knn.py:369] ('full', 100) classifier result: Top1: 90.10 Top5: 99.84
I20240721 23:38:43 2732252 dinov2 knn.py:369] ('full', 200) classifier result: Top1: 89.59 Top5: 99.87
I20240723 23:31:35 3558492 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240723 23:31:35 3558492 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240723 23:31:35 3558492 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.002
I20240723 23:31:35 3558492 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.002
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240723 23:31:35 3558492 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240723 23:31:37 3558492 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240723 23:31:37 3558492 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240723 23:31:37 3558492 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:31:38 3558492 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240723 23:31:38 3558492 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:31:39 3558492 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240723 23:31:39 3558492 dinov2 knn.py:262] Extracting features for train set...
I20240723 23:31:39 3558492 dinov2 loaders.py:155] sampler: distributed
I20240723 23:31:39 3558492 dinov2 loaders.py:214] using PyTorch data loader
I20240723 23:31:39 3558492 dinov2 loaders.py:227] # of batches: 81
W20240723 23:31:43 3559013 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:31:48 3559029 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:31:54 3559048 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:00 3559146 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:03 3559263 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240723 23:32:15 3558492 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([164544, 768])
I20240723 23:32:15 3558492 dinov2 helpers.py:103]   [ 0/81]  eta: 0:48:35    time: 35.993217  data: 28.212734  max mem: 8979
I20240723 23:35:23 3566301 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240723 23:35:23 3566301 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240723 23:35:23 3566301 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240723 23:35:23 3566301 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240723 23:35:23 3566301 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240723 23:35:26 3566301 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240723 23:35:26 3566301 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240723 23:35:26 3566301 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:35:27 3566301 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240723 23:35:27 3566301 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:35:28 3566301 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240723 23:35:28 3566301 dinov2 knn.py:262] Extracting features for train set...
I20240723 23:35:28 3566301 dinov2 loaders.py:155] sampler: distributed
I20240723 23:35:28 3566301 dinov2 loaders.py:214] using PyTorch data loader
I20240723 23:35:28 3566301 dinov2 loaders.py:227] # of batches: 161
W20240723 23:35:30 3566735 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:35:33 3566749 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:35:36 3566761 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:35:40 3566773 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:35:43 3566792 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240723 23:36:05 3566301 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([164544, 768])
I20240723 23:36:05 3566301 dinov2 helpers.py:103]   [  0/161]  eta: 1:41:21    time: 37.775028  data: 24.451992  max mem: 8979
I20240723 23:36:27 3566301 dinov2 helpers.py:103]   [ 10/161]  eta: 0:13:41    time: 5.437632  data: 4.201676  max mem: 9471
I20240723 23:37:02 3566301 dinov2 helpers.py:103]   [ 20/161]  eta: 0:10:31    time: 2.814551  data: 2.785861  max mem: 9471
I20240723 23:37:34 3566301 dinov2 helpers.py:103]   [ 30/161]  eta: 0:08:55    time: 3.350494  data: 3.322087  max mem: 9471
I20240723 23:38:10 3566301 dinov2 helpers.py:103]   [ 40/161]  eta: 0:07:58    time: 3.409106  data: 3.382359  max mem: 9471
I20240723 23:38:45 3566301 dinov2 helpers.py:103]   [ 50/161]  eta: 0:07:10    time: 3.548390  data: 3.522017  max mem: 9471
I20240723 23:39:21 3566301 dinov2 helpers.py:103]   [ 60/161]  eta: 0:06:26    time: 3.562071  data: 3.535403  max mem: 9471
I20240723 23:39:58 3566301 dinov2 helpers.py:103]   [ 70/161]  eta: 0:05:46    time: 3.642498  data: 3.614238  max mem: 9471
I20240723 23:40:34 3566301 dinov2 helpers.py:103]   [ 80/161]  eta: 0:05:06    time: 3.644810  data: 3.616994  max mem: 9471
I20240723 23:41:12 3566301 dinov2 helpers.py:103]   [ 90/161]  eta: 0:04:29    time: 3.707437  data: 3.681927  max mem: 9471
I20240723 23:41:50 3566301 dinov2 helpers.py:103]   [100/161]  eta: 0:03:51    time: 3.813962  data: 3.788966  max mem: 9471
I20240723 23:42:28 3566301 dinov2 helpers.py:103]   [110/161]  eta: 0:03:13    time: 3.771679  data: 3.746573  max mem: 9471
I20240723 23:43:04 3566301 dinov2 helpers.py:103]   [120/161]  eta: 0:02:34    time: 3.702756  data: 3.678567  max mem: 9471
I20240723 23:43:43 3566301 dinov2 helpers.py:103]   [130/161]  eta: 0:01:57    time: 3.740094  data: 3.715919  max mem: 9471
I20240723 23:44:21 3566301 dinov2 helpers.py:103]   [140/161]  eta: 0:01:19    time: 3.832663  data: 3.808170  max mem: 9471
I20240723 23:44:53 3566301 dinov2 helpers.py:103]   [150/161]  eta: 0:00:41    time: 3.542960  data: 3.518509  max mem: 9471
I20240723 23:45:32 3566301 dinov2 helpers.py:103]   [160/161]  eta: 0:00:03    time: 3.555419  data: 3.001391  max mem: 9471
I20240723 23:45:33 3566301 dinov2 helpers.py:132]  Total time: 0:10:05 (3.761863 s / it)
I20240723 23:45:33 3566301 dinov2 utils.py:141] Features shape: (164544, 768)
I20240723 23:45:33 3566301 dinov2 utils.py:142] Labels shape: (164544,)
I20240723 23:45:33 3566301 dinov2 knn.py:266] Train features created, shape torch.Size([164544, 768]).
I20240723 23:45:33 3566301 dinov2 loaders.py:155] sampler: distributed
I20240723 23:45:33 3566301 dinov2 loaders.py:214] using PyTorch data loader
I20240723 23:45:33 3566301 dinov2 loaders.py:227] # of batches: 18
I20240723 23:45:33 3566301 dinov2 knn.py:301] Start the k-NN classification.
W20240723 23:45:34 3575656 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:45:39 3575668 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:45:42 3575680 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:45:45 3575692 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:45:48 3575702 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240723 23:50:37 3566301 dinov2 helpers.py:103] Test:  [ 0/18]  eta: 1:31:09    time: 303.879883  data: 16.984791  max mem: 9471
I20240724 11:08:50 3968959 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240724 11:08:50 3968959 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240724 11:08:50 3968959 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240724 11:08:50 3968959 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240724 11:08:50 3968959 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240724 11:08:52 3968959 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240724 11:08:52 3968959 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240724 11:08:52 3968959 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 11:08:53 3968959 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240724 11:08:53 3968959 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 11:08:54 3968959 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240724 11:08:54 3968959 dinov2 knn.py:262] Extracting features for train set...
I20240724 11:08:54 3968959 dinov2 loaders.py:155] sampler: distributed
I20240724 11:08:54 3968959 dinov2 loaders.py:214] using PyTorch data loader
I20240724 11:08:54 3968959 dinov2 loaders.py:227] # of batches: 161
W20240724 11:08:56 3969483 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:08:57 3969486 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:09:01 3969504 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:09:06 3969512 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:09:08 3969605 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240724 11:09:30 3968959 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([164544, 768])
I20240724 11:09:30 3968959 dinov2 helpers.py:103]   [  0/161]  eta: 1:37:45    time: 36.434155  data: 24.144936  max mem: 8979
I20240724 11:09:57 3968959 dinov2 helpers.py:103]   [ 10/161]  eta: 0:14:30    time: 5.763867  data: 2.845119  max mem: 9471
I20240724 11:10:29 3968959 dinov2 helpers.py:103]   [ 20/161]  eta: 0:10:40    time: 2.950441  data: 1.701518  max mem: 9471
I20240724 11:11:04 3968959 dinov2 helpers.py:103]   [ 30/161]  eta: 0:09:13    time: 3.373788  data: 3.096896  max mem: 9471
I20240724 11:11:41 3968959 dinov2 helpers.py:103]   [ 40/161]  eta: 0:08:13    time: 3.592055  data: 3.557529  max mem: 9471
I20240724 11:12:16 3968959 dinov2 helpers.py:103]   [ 50/161]  eta: 0:07:20    time: 3.568170  data: 3.536824  max mem: 9471
I20240724 11:12:53 3968959 dinov2 helpers.py:103]   [ 60/161]  eta: 0:06:35    time: 3.591802  data: 3.561438  max mem: 9471
I20240724 11:13:29 3968959 dinov2 helpers.py:103]   [ 70/161]  eta: 0:05:52    time: 3.657189  data: 3.628321  max mem: 9471
I20240724 11:14:04 3968959 dinov2 helpers.py:103]   [ 80/161]  eta: 0:05:10    time: 3.573409  data: 3.545043  max mem: 9471
I20240724 11:14:43 3968959 dinov2 helpers.py:103]   [ 90/161]  eta: 0:04:32    time: 3.705828  data: 3.674134  max mem: 9471
I20240724 11:15:19 3968959 dinov2 helpers.py:103]   [100/161]  eta: 0:03:52    time: 3.752327  data: 3.718894  max mem: 9471
I20240724 11:15:57 3968959 dinov2 helpers.py:103]   [110/161]  eta: 0:03:14    time: 3.684403  data: 3.655636  max mem: 9471
I20240724 11:16:35 3968959 dinov2 helpers.py:103]   [120/161]  eta: 0:02:36    time: 3.779707  data: 3.752745  max mem: 9471
I20240724 11:17:12 3968959 dinov2 helpers.py:103]   [130/161]  eta: 0:01:58    time: 3.782603  data: 3.752326  max mem: 9471
I20240724 11:17:51 3968959 dinov2 helpers.py:103]   [140/161]  eta: 0:01:20    time: 3.797852  data: 3.767783  max mem: 9471
I20240724 11:18:23 3968959 dinov2 helpers.py:103]   [150/161]  eta: 0:00:41    time: 3.526013  data: 3.496088  max mem: 9471
I20240724 11:19:09 3968959 dinov2 helpers.py:103]   [160/161]  eta: 0:00:03    time: 3.932458  data: 3.123131  max mem: 9471
I20240724 11:19:11 3968959 dinov2 helpers.py:132]  Total time: 0:10:17 (3.832437 s / it)
I20240724 11:19:11 3968959 dinov2 utils.py:141] Features shape: (164544, 768)
I20240724 11:19:11 3968959 dinov2 utils.py:142] Labels shape: (164544,)
I20240724 11:19:11 3968959 dinov2 knn.py:266] Train features created, shape torch.Size([164544, 768]).
I20240724 11:19:11 3968959 dinov2 loaders.py:155] sampler: distributed
I20240724 11:19:11 3968959 dinov2 loaders.py:214] using PyTorch data loader
I20240724 11:19:11 3968959 dinov2 loaders.py:227] # of batches: 18
I20240724 11:56:55 3968959 dinov2 knn.py:301] Start the k-NN classification.
W20240724 11:56:55 3992382 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:56:56 3992387 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 11:56:56 3992390 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240724 15:05:33 4109425 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240724 15:05:33 4109425 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240724 15:05:33 4109425 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240724 15:05:33 4109425 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240724 15:05:33 4109425 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240724 15:05:35 4109425 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240724 15:05:36 4109425 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240724 15:05:36 4109425 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 15:05:36 4109425 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240724 15:05:36 4109425 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 15:05:36 4109425 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240724 15:05:36 4109425 dinov2 knn.py:262] Extracting features for train set...
I20240724 15:05:36 4109425 dinov2 loaders.py:155] sampler: distributed
I20240724 15:05:36 4109425 dinov2 loaders.py:214] using PyTorch data loader
I20240724 15:05:36 4109425 dinov2 loaders.py:227] # of batches: 18
W20240724 15:05:37 4109618 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:05:40 4109630 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:05:43 4109643 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:05:46 4109655 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:05:49 4109669 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240724 15:06:09 4109425 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240724 15:06:09 4109425 dinov2 helpers.py:103]   [ 0/18]  eta: 0:09:44    time: 32.473648  data: 21.318747  max mem: 8979
I20240724 15:06:37 4109425 dinov2 helpers.py:103]   [10/18]  eta: 0:00:44    time: 5.583329  data: 4.045193  max mem: 9039
I20240724 15:07:04 4109425 dinov2 helpers.py:103]   [17/18]  eta: 0:00:04    time: 4.881991  data: 3.800749  max mem: 9039
I20240724 15:07:05 4109425 dinov2 helpers.py:132]  Total time: 0:01:29 (4.949141 s / it)
I20240724 15:07:05 4109425 dinov2 utils.py:141] Features shape: (17563, 768)
I20240724 15:07:05 4109425 dinov2 utils.py:142] Labels shape: (17563,)
I20240724 15:07:05 4109425 dinov2 knn.py:266] Train features created, shape torch.Size([17563, 768]).
I20240724 15:07:05 4109425 dinov2 loaders.py:155] sampler: distributed
I20240724 15:07:05 4109425 dinov2 loaders.py:214] using PyTorch data loader
I20240724 15:07:05 4109425 dinov2 loaders.py:227] # of batches: 18
I20240724 15:25:11 4109425 dinov2 knn.py:301] Start the k-NN classification.
W20240724 15:25:45 4127546 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:25:45 4127551 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 15:25:45 4127554 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240724 17:55:59 8948 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240724 17:55:59 8948 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240724 17:55:59 8948 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240724 17:55:59 8948 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240724 17:55:59 8948 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240724 17:56:00 8948 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240724 17:56:00 8948 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240724 17:56:00 8948 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 17:56:00 8948 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240724 17:56:00 8948 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240724 17:56:01 8948 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240724 17:56:01 8948 dinov2 knn.py:268] Extracting features for train set...
I20240724 17:56:01 8948 dinov2 loaders.py:155] sampler: distributed
I20240724 17:56:01 8948 dinov2 loaders.py:214] using PyTorch data loader
I20240724 17:56:01 8948 dinov2 loaders.py:227] # of batches: 18
W20240724 17:56:04 9139 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 17:56:07 9149 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 17:56:11 9162 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 17:56:14 9195 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240724 17:56:15 9318 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240724 17:56:42 8948 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240724 17:56:42 8948 dinov2 helpers.py:103]   [ 0/18]  eta: 0:12:32    time: 41.799381  data: 24.390026  max mem: 8979
I20240724 17:57:02 8948 dinov2 helpers.py:103]   [10/18]  eta: 0:00:44    time: 5.553077  data: 3.704722  max mem: 9039
I20240724 17:57:26 8948 dinov2 helpers.py:103]   [17/18]  eta: 0:00:04    time: 4.758743  data: 3.323998  max mem: 9039
I20240724 17:57:28 8948 dinov2 helpers.py:132]  Total time: 0:01:27 (4.834885 s / it)
I20240724 17:57:28 8948 dinov2 utils.py:141] Features shape: (17563, 768)
I20240724 17:57:28 8948 dinov2 utils.py:142] Labels shape: (17563,)
I20240724 17:57:28 8948 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240724 17:57:28 8948 dinov2 loaders.py:155] sampler: distributed
I20240724 17:57:28 8948 dinov2 loaders.py:214] using PyTorch data loader
I20240724 17:57:28 8948 dinov2 loaders.py:227] # of batches: 18
I20240724 23:39:41 8948 dinov2 knn.py:307] Start the k-NN classification.
I20240727 15:57:58 1718981 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 15:57:58 1718981 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 15:57:58 1718981 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 15:57:58 1718981 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 15:57:58 1718981 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 15:58:01 1718981 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 15:58:01 1718981 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 15:58:01 1718981 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 15:58:01 1718981 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 15:58:01 1718981 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 15:58:01 1718981 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 15:58:01 1718981 dinov2 knn.py:268] Extracting features for train set...
I20240727 15:58:01 1718981 dinov2 loaders.py:155] sampler: distributed
I20240727 15:58:01 1718981 dinov2 loaders.py:214] using PyTorch data loader
I20240727 15:58:01 1718981 dinov2 loaders.py:227] # of batches: 18
W20240727 15:58:03 1719200 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 15:58:05 1719211 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 15:58:08 1719220 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 15:58:10 1719230 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 15:58:12 1719307 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 15:58:48 1718981 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240727 15:58:48 1718981 dinov2 helpers.py:103]   [ 0/18]  eta: 0:13:56    time: 46.490997  data: 21.321390  max mem: 8979
I20240727 15:59:11 1718981 dinov2 helpers.py:103]   [10/18]  eta: 0:00:50    time: 6.317897  data: 1.938845  max mem: 9039
I20240727 15:59:50 1718981 dinov2 helpers.py:103]   [17/18]  eta: 0:00:06    time: 6.055823  data: 1.184982  max mem: 9039
I20240727 15:59:51 1718981 dinov2 helpers.py:132]  Total time: 0:01:50 (6.114486 s / it)
I20240727 15:59:51 1718981 dinov2 utils.py:141] Features shape: (17563, 768)
I20240727 15:59:51 1718981 dinov2 utils.py:142] Labels shape: (17563,)
I20240727 15:59:51 1718981 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240727 15:59:51 1718981 dinov2 loaders.py:155] sampler: distributed
I20240727 15:59:51 1718981 dinov2 loaders.py:214] using PyTorch data loader
I20240727 15:59:51 1718981 dinov2 loaders.py:227] # of batches: 18
I20240727 16:02:25 1718981 dinov2 knn.py:307] Start the k-NN classification.
I20240727 16:17:41 1728541 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 16:17:41 1728541 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 16:17:41 1728541 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 16:17:41 1728541 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 16:17:41 1728541 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 16:17:42 1728541 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 16:17:42 1728541 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 16:17:43 1728541 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 16:19:10 1728541 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 16:19:10 1728541 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 16:19:10 1728541 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 16:19:10 1728541 dinov2 knn.py:268] Extracting features for train set...
I20240727 16:19:10 1728541 dinov2 loaders.py:155] sampler: distributed
I20240727 16:19:10 1728541 dinov2 loaders.py:214] using PyTorch data loader
I20240727 16:19:10 1728541 dinov2 loaders.py:227] # of batches: 18
I20240727 22:36:33 1809780 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 22:36:33 1809780 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 22:36:33 1809780 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 22:36:33 1809780 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 22:36:33 1809780 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 22:36:35 1809780 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 22:36:35 1809780 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 22:36:35 1809780 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 22:44:56 1809780 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 22:44:56 1809780 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 22:44:56 1809780 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 22:44:56 1809780 dinov2 knn.py:268] Extracting features for train set...
I20240727 22:44:56 1809780 dinov2 loaders.py:155] sampler: distributed
I20240727 22:44:56 1809780 dinov2 loaders.py:214] using PyTorch data loader
I20240727 22:44:56 1809780 dinov2 loaders.py:227] # of batches: 18
W20240727 22:44:57 1812355 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:44:57 1812360 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:44:57 1812363 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:44:57 1812366 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:44:58 1812441 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 22:47:47 1814320 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 22:47:47 1814320 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 22:47:47 1814320 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 22:47:47 1814320 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 22:47:47 1814320 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 22:47:48 1814320 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 22:47:48 1814320 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 22:47:49 1814320 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 22:47:49 1814320 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 22:47:49 1814320 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 22:47:49 1814320 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 22:47:49 1814320 dinov2 knn.py:268] Extracting features for train set...
I20240727 22:47:49 1814320 dinov2 loaders.py:155] sampler: distributed
I20240727 22:47:49 1814320 dinov2 loaders.py:214] using PyTorch data loader
I20240727 22:47:49 1814320 dinov2 loaders.py:227] # of batches: 18
W20240727 22:50:04 1815560 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:50:05 1815563 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:50:06 1815568 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:50:06 1815569 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 22:50:07 1815572 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 23:39:10 1830942 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 23:39:10 1830942 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 23:39:10 1830942 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 23:39:10 1830942 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 23:39:10 1830942 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 23:39:12 1830942 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 23:39:12 1830942 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 23:39:12 1830942 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:39:12 1830942 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:39:12 1830942 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:39:12 1830942 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:39:12 1830942 dinov2 knn.py:268] Extracting features for train set...
I20240727 23:39:12 1830942 dinov2 loaders.py:155] sampler: distributed
I20240727 23:39:12 1830942 dinov2 loaders.py:214] using PyTorch data loader
I20240727 23:39:12 1830942 dinov2 loaders.py:227] # of batches: 18
I20240727 23:39:52 1832489 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 23:39:52 1832489 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 23:39:52 1832489 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 23:39:52 1832489 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 23:39:52 1832489 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 23:39:54 1832489 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 23:39:54 1832489 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 23:39:54 1832489 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:39:54 1832489 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:39:54 1832489 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:39:54 1832489 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:39:54 1832489 dinov2 knn.py:268] Extracting features for train set...
I20240727 23:39:54 1832489 dinov2 loaders.py:155] sampler: distributed
I20240727 23:39:54 1832489 dinov2 loaders.py:214] using PyTorch data loader
I20240727 23:39:54 1832489 dinov2 loaders.py:227] # of batches: 18
W20240727 23:40:03 1832846 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:40:04 1832869 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:40:05 1832873 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:40:07 1832879 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:40:08 1832885 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 23:40:48 1832489 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240727 23:40:48 1832489 dinov2 helpers.py:103]   [ 0/18]  eta: 0:15:55    time: 53.093658  data: 25.027613  max mem: 8979
I20240727 23:41:09 1832489 dinov2 helpers.py:103]   [10/18]  eta: 0:00:54    time: 6.772982  data: 2.275997  max mem: 9039
I20240727 23:41:48 1832489 dinov2 helpers.py:103]   [17/18]  eta: 0:00:06    time: 6.320858  data: 1.508301  max mem: 9039
I20240727 23:41:49 1832489 dinov2 helpers.py:132]  Total time: 0:01:54 (6.379551 s / it)
I20240727 23:41:49 1832489 dinov2 utils.py:141] Features shape: (17563, 768)
I20240727 23:41:49 1832489 dinov2 utils.py:142] Labels shape: (17563,)
I20240727 23:41:49 1832489 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240727 23:41:49 1832489 dinov2 loaders.py:155] sampler: distributed
I20240727 23:41:49 1832489 dinov2 loaders.py:214] using PyTorch data loader
I20240727 23:41:49 1832489 dinov2 loaders.py:227] # of batches: 18
I20240727 23:45:16 1832489 dinov2 knn.py:307] Start the k-NN classification.
W20240727 23:45:16 1836987 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 23:47:10 1837501 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240727 23:47:10 1837501 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240727 23:47:10 1837501 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240727 23:47:10 1837501 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240727 23:47:10 1837501 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240727 23:47:12 1837501 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240727 23:47:12 1837501 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240727 23:47:12 1837501 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:47:12 1837501 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:47:12 1837501 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240727 23:47:12 1837501 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240727 23:47:12 1837501 dinov2 knn.py:268] Extracting features for train set...
I20240727 23:47:12 1837501 dinov2 loaders.py:155] sampler: distributed
I20240727 23:47:12 1837501 dinov2 loaders.py:214] using PyTorch data loader
I20240727 23:47:12 1837501 dinov2 loaders.py:227] # of batches: 18
W20240727 23:47:20 1837933 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:47:24 1838015 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:47:25 1838127 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:47:27 1838131 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240727 23:47:29 1838209 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240727 23:47:59 1837501 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240727 23:47:59 1837501 dinov2 helpers.py:103]   [ 0/18]  eta: 0:13:58    time: 46.570618  data: 26.247000  max mem: 8979
I20240727 23:48:18 1837501 dinov2 helpers.py:103]   [10/18]  eta: 0:00:47    time: 5.993251  data: 2.386632  max mem: 9039
I20240727 23:48:58 1837501 dinov2 helpers.py:103]   [17/18]  eta: 0:00:05    time: 5.869122  data: 1.458620  max mem: 9039
I20240727 23:48:59 1837501 dinov2 helpers.py:132]  Total time: 0:01:46 (5.927251 s / it)
I20240727 23:48:59 1837501 dinov2 utils.py:141] Features shape: (17563, 768)
I20240727 23:48:59 1837501 dinov2 utils.py:142] Labels shape: (17563,)
I20240727 23:49:39 1837501 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240727 23:49:39 1837501 dinov2 loaders.py:155] sampler: distributed
I20240727 23:49:39 1837501 dinov2 loaders.py:214] using PyTorch data loader
I20240727 23:49:39 1837501 dinov2 loaders.py:227] # of batches: 18
I20240727 23:49:39 1837501 dinov2 knn.py:307] Start the k-NN classification.
I20240728 10:30:42 1991034 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 10:30:42 1991034 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 10:30:42 1991034 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 10:30:42 1991034 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 10:30:42 1991034 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 10:30:43 1991034 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 10:30:44 1991034 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 10:30:44 1991034 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:30:44 1991034 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:30:44 1991034 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:30:44 1991034 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:30:44 1991034 dinov2 knn.py:268] Extracting features for train set...
I20240728 10:30:44 1991034 dinov2 loaders.py:155] sampler: distributed
I20240728 10:30:44 1991034 dinov2 loaders.py:214] using PyTorch data loader
I20240728 10:30:44 1991034 dinov2 loaders.py:227] # of batches: 18
W20240728 10:30:57 1991440 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:30:59 1991447 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:31:00 1991516 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:31:01 1991520 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:31:02 1991542 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240728 10:35:20 1991034 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 10:38:10 1995885 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 10:38:10 1995885 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 10:38:10 1995885 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 10:38:10 1995885 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 10:38:10 1995885 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 10:38:12 1995885 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 10:38:12 1995885 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 10:38:12 1995885 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:38:12 1995885 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:38:12 1995885 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:38:12 1995885 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:38:12 1995885 dinov2 knn.py:268] Extracting features for train set...
I20240728 10:38:12 1995885 dinov2 loaders.py:155] sampler: distributed
I20240728 10:38:12 1995885 dinov2 loaders.py:214] using PyTorch data loader
I20240728 10:38:12 1995885 dinov2 loaders.py:227] # of batches: 18
W20240728 10:38:22 1996273 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:38:24 1996280 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:38:26 1996286 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:38:28 1996292 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:38:29 1996301 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240728 10:38:40 1995885 dinov2 utils.py:118] now at local rank 0
I20240728 10:38:59 1995885 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 10:40:39 1995885 dinov2 helpers.py:103]   [ 0/18]  eta: 0:44:08    time: 147.112549  data: 27.428478  max mem: 8979
I20240728 10:40:45 1995885 dinov2 utils.py:118] now at local rank 0
I20240728 10:45:22 1995885 dinov2 utils.py:118] now at local rank 0
I20240728 10:53:10 2002588 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 10:53:10 2002588 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 10:53:10 2002588 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 10:53:10 2002588 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 10:53:10 2002588 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 10:53:12 2002588 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 10:53:12 2002588 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 10:53:12 2002588 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:53:12 2002588 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:53:12 2002588 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 10:53:13 2002588 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 10:53:13 2002588 dinov2 knn.py:268] Extracting features for train set...
I20240728 10:53:13 2002588 dinov2 loaders.py:155] sampler: distributed
I20240728 10:53:13 2002588 dinov2 loaders.py:214] using PyTorch data loader
I20240728 10:53:13 2002588 dinov2 loaders.py:227] # of batches: 18
W20240728 10:53:22 2002892 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:53:24 2002983 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:53:25 2002990 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:53:27 2002996 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240728 10:53:29 2003003 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

I20240728 10:54:06 2002588 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 10:54:06 2002588 dinov2 helpers.py:103]   [ 0/18]  eta: 0:16:04    time: 53.606396  data: 27.540644  max mem: 8979
I20240728 10:54:25 2002588 dinov2 helpers.py:103]   [10/18]  eta: 0:00:52    time: 6.615165  data: 2.504492  max mem: 9039
I20240728 11:20:39 2014276 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 11:20:39 2014276 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 11:20:39 2014276 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 11:20:39 2014276 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 11:20:39 2014276 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 11:20:41 2014276 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 11:20:41 2014276 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 11:20:41 2014276 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:20:41 2014276 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:20:41 2014276 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:20:41 2014276 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:20:41 2014276 dinov2 knn.py:268] Extracting features for train set...
I20240728 11:20:41 2014276 dinov2 loaders.py:155] sampler: distributed
I20240728 11:20:41 2014276 dinov2 loaders.py:214] using PyTorch data loader
I20240728 11:20:41 2014276 dinov2 loaders.py:227] # of batches: 18
I20240728 11:21:20 2016990 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 11:21:20 2016990 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 11:21:20 2016990 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 11:21:20 2016990 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 11:21:20 2016990 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 11:21:22 2016990 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 11:21:22 2016990 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 11:21:22 2016990 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:21:22 2016990 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:21:22 2016990 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:21:22 2016990 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:21:22 2016990 dinov2 knn.py:268] Extracting features for train set...
I20240728 11:21:22 2016990 dinov2 loaders.py:155] sampler: distributed
I20240728 11:21:22 2016990 dinov2 loaders.py:214] using PyTorch data loader
I20240728 11:21:22 2016990 dinov2 loaders.py:227] # of batches: 18
I20240728 11:22:14 2016990 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 11:22:14 2016990 dinov2 helpers.py:103]   [ 0/18]  eta: 0:15:39    time: 52.220634  data: 28.428411  max mem: 8979
I20240728 11:22:34 2016990 dinov2 helpers.py:103]   [10/18]  eta: 0:00:51    time: 6.491612  data: 2.585011  max mem: 9039
I20240728 11:23:13 2016990 dinov2 helpers.py:103]   [17/18]  eta: 0:00:06    time: 6.154471  data: 1.610054  max mem: 9039
I20240728 11:23:14 2016990 dinov2 helpers.py:132]  Total time: 0:01:51 (6.203233 s / it)
I20240728 11:23:14 2016990 dinov2 utils.py:142] Features shape: (17563, 768)
I20240728 11:23:14 2016990 dinov2 utils.py:143] Labels shape: (17563,)
I20240728 11:23:14 2016990 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240728 11:23:14 2016990 dinov2 loaders.py:155] sampler: distributed
I20240728 11:23:14 2016990 dinov2 loaders.py:214] using PyTorch data loader
I20240728 11:23:14 2016990 dinov2 loaders.py:227] # of batches: 18
I20240728 11:23:38 2016990 dinov2 knn.py:307] Start the k-NN classification.
I20240728 11:27:42 2022982 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 11:27:42 2022982 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 11:27:42 2022982 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 11:27:42 2022982 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 11:27:42 2022982 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 11:27:44 2022982 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 11:27:44 2022982 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 11:27:44 2022982 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:27:44 2022982 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:27:44 2022982 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:27:44 2022982 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:27:44 2022982 dinov2 knn.py:268] Extracting features for train set...
I20240728 11:27:44 2022982 dinov2 loaders.py:155] sampler: distributed
I20240728 11:27:44 2022982 dinov2 loaders.py:214] using PyTorch data loader
I20240728 11:27:44 2022982 dinov2 loaders.py:227] # of batches: 18
I20240728 11:36:40 2022982 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 11:41:15 2029371 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 11:41:15 2029371 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 11:41:15 2029371 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 11:41:15 2029371 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 11:41:15 2029371 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 11:41:16 2029371 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 11:41:17 2029371 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 11:41:17 2029371 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:41:17 2029371 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:41:17 2029371 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 11:41:17 2029371 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 11:41:17 2029371 dinov2 knn.py:268] Extracting features for train set...
I20240728 11:41:17 2029371 dinov2 loaders.py:155] sampler: distributed
I20240728 11:41:17 2029371 dinov2 loaders.py:214] using PyTorch data loader
I20240728 11:41:17 2029371 dinov2 loaders.py:227] # of batches: 18
I20240728 11:41:48 2029371 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 11:41:48 2029371 dinov2 helpers.py:103]   [ 0/18]  eta: 0:09:24    time: 31.358234  data: 17.727587  max mem: 8979
I20240728 12:06:48 2038125 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 12:06:48 2038125 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 12:06:48 2038125 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 12:06:48 2038125 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 12:06:48 2038125 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 12:06:50 2038125 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 12:06:50 2038125 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 12:06:50 2038125 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 12:06:50 2038125 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 12:06:50 2038125 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 12:06:50 2038125 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 12:06:50 2038125 dinov2 knn.py:268] Extracting features for train set...
I20240728 12:06:50 2038125 dinov2 loaders.py:155] sampler: distributed
I20240728 12:06:50 2038125 dinov2 loaders.py:214] using PyTorch data loader
I20240728 12:06:50 2038125 dinov2 loaders.py:227] # of batches: 18
I20240728 12:07:22 2038125 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 12:07:22 2038125 dinov2 helpers.py:103]   [ 0/18]  eta: 0:09:32    time: 31.793404  data: 18.393066  max mem: 8979
I20240728 12:07:37 2038125 dinov2 helpers.py:103]   [10/18]  eta: 0:00:34    time: 4.281025  data: 2.513149  max mem: 9039
I20240728 12:31:44 2044810 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 12:31:44 2044810 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 12:31:44 2044810 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 12:31:44 2044810 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 12:31:44 2044810 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 13:10:54 2057966 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 13:10:54 2057966 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 13:10:54 2057966 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 13:10:54 2057966 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 13:10:54 2057966 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 13:10:56 2057966 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 13:10:56 2057966 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 13:10:56 2057966 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 13:10:56 2057966 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 13:10:56 2057966 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 13:10:56 2057966 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 13:10:56 2057966 dinov2 knn.py:268] Extracting features for train set...
I20240728 13:10:56 2057966 dinov2 loaders.py:155] sampler: distributed
I20240728 13:10:56 2057966 dinov2 loaders.py:214] using PyTorch data loader
I20240728 13:10:56 2057966 dinov2 loaders.py:227] # of batches: 18
I20240728 13:11:26 2057966 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 13:11:26 2057966 dinov2 helpers.py:103]   [ 0/18]  eta: 0:08:56    time: 29.809917  data: 17.478083  max mem: 8979
I20240728 13:11:45 2057966 dinov2 helpers.py:103]   [10/18]  eta: 0:00:35    time: 4.409830  data: 2.616331  max mem: 9039
I20240728 13:12:07 2057966 dinov2 helpers.py:103]   [17/18]  eta: 0:00:03    time: 3.948090  data: 2.069963  max mem: 9039
I20240728 13:12:08 2057966 dinov2 helpers.py:132]  Total time: 0:01:11 (3.984990 s / it)
I20240728 13:12:08 2057966 dinov2 utils.py:142] Features shape: (17563, 768)
I20240728 13:12:08 2057966 dinov2 utils.py:143] Labels shape: (17563,)
I20240728 13:12:08 2057966 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240728 13:12:08 2057966 dinov2 loaders.py:155] sampler: distributed
I20240728 13:12:08 2057966 dinov2 loaders.py:214] using PyTorch data loader
I20240728 13:12:08 2057966 dinov2 loaders.py:227] # of batches: 18
I20240728 13:12:08 2057966 dinov2 knn.py:307] Start the k-NN classification.
I20240728 13:12:25 2057966 dinov2 helpers.py:103] Test:  [ 0/18]  eta: 0:05:15    time: 17.548397  data: 15.750576  max mem: 9039
I20240728 13:12:57 2057966 dinov2 helpers.py:103] Test:  [10/18]  eta: 0:00:35    time: 4.469988  data: 1.584072  max mem: 9039
I20240728 13:13:14 2057966 dinov2 helpers.py:103] Test:  [17/18]  eta: 0:00:03    time: 3.689889  data: 0.968126  max mem: 9039
I20240728 13:13:14 2057966 dinov2 helpers.py:132] Test: Total time: 0:01:06 (3.690195 s / it)
I20240728 13:13:14 2057966 dinov2 utils.py:79] Averaged stats: 
I20240728 13:13:15 2057966 dinov2 knn.py:375] ('full', 10) classifier result: Top1: 99.80 Top5: 100.00
I20240728 13:13:15 2057966 dinov2 knn.py:375] ('full', 20) classifier result: Top1: 99.67 Top5: 100.00
I20240728 13:13:15 2057966 dinov2 knn.py:375] ('full', 100) classifier result: Top1: 99.53 Top5: 100.00
I20240728 13:13:15 2057966 dinov2 knn.py:375] ('full', 200) classifier result: Top1: 99.52 Top5: 100.00
I20240728 22:19:35 2188039 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 22:19:35 2188039 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 22:19:35 2188039 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 22:19:35 2188039 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 22:19:35 2188039 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 22:19:37 2188039 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 22:19:37 2188039 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 22:19:37 2188039 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 22:19:37 2188039 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 22:19:37 2188039 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 22:19:37 2188039 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 22:19:37 2188039 dinov2 knn.py:268] Extracting features for train set...
I20240728 22:19:37 2188039 dinov2 loaders.py:155] sampler: distributed
I20240728 22:19:37 2188039 dinov2 loaders.py:214] using PyTorch data loader
I20240728 22:19:37 2188039 dinov2 loaders.py:227] # of batches: 18
I20240728 22:20:30 2188039 dinov2 utils.py:130] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 23:18:21 2203436 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 23:18:22 2203436 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 23:18:22 2203436 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 23:18:22 2203436 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 23:18:22 2203436 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 23:18:23 2203436 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 23:18:23 2203436 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 23:18:23 2203436 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:18:24 2203436 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:18:24 2203436 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:18:24 2203436 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:18:24 2203436 dinov2 knn.py:268] Extracting features for train set...
I20240728 23:18:24 2203436 dinov2 loaders.py:155] sampler: distributed
I20240728 23:18:24 2203436 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:18:24 2203436 dinov2 loaders.py:227] # of batches: 18
I20240728 23:19:15 2203436 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 23:19:15 2203436 dinov2 helpers.py:103]   [ 0/18]  eta: 0:15:16    time: 50.940449  data: 24.936399  max mem: 8979
I20240728 23:19:39 2203436 dinov2 helpers.py:103]   [10/18]  eta: 0:00:54    time: 6.810758  data: 2.267642  max mem: 9039
I20240728 23:20:19 2203436 dinov2 helpers.py:103]   [17/18]  eta: 0:00:06    time: 6.393741  data: 1.385910  max mem: 9039
I20240728 23:20:20 2203436 dinov2 helpers.py:132]  Total time: 0:01:56 (6.455232 s / it)
I20240728 23:20:20 2203436 dinov2 utils.py:140] Features shape: (17563, 768)
I20240728 23:20:20 2203436 dinov2 utils.py:141] Labels shape: (17563,)
I20240728 23:20:20 2203436 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240728 23:20:20 2203436 dinov2 loaders.py:155] sampler: distributed
I20240728 23:20:20 2203436 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:20:20 2203436 dinov2 loaders.py:227] # of batches: 18
I20240728 23:20:20 2203436 dinov2 knn.py:307] Start the k-NN classification.
I20240728 23:20:50 2203436 dinov2 helpers.py:103] Test:  [ 0/18]  eta: 0:09:00    time: 30.012690  data: 27.054211  max mem: 9039
I20240728 23:25:51 2209154 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 23:25:51 2209154 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 23:25:51 2209154 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 23:25:51 2209154 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 23:25:51 2209154 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 23:25:53 2209154 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 23:25:53 2209154 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 23:25:53 2209154 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:25:53 2209154 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:25:53 2209154 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:25:53 2209154 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:25:53 2209154 dinov2 knn.py:268] Extracting features for train set...
I20240728 23:25:53 2209154 dinov2 loaders.py:155] sampler: distributed
I20240728 23:25:53 2209154 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:25:53 2209154 dinov2 loaders.py:227] # of batches: 18
I20240728 23:26:41 2209154 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 23:26:41 2209154 dinov2 helpers.py:103]   [ 0/18]  eta: 0:14:08    time: 47.159637  data: 24.199928  max mem: 8979
I20240728 23:27:07 2209154 dinov2 helpers.py:103]   [10/18]  eta: 0:00:53    time: 6.656370  data: 2.200602  max mem: 9039
I20240728 23:27:44 2209154 dinov2 helpers.py:103]   [17/18]  eta: 0:00:06    time: 6.151324  data: 1.344960  max mem: 9039
I20240728 23:27:45 2209154 dinov2 helpers.py:132]  Total time: 0:01:51 (6.210678 s / it)
I20240728 23:27:45 2209154 dinov2 utils.py:140] Features shape: (17563, 768)
I20240728 23:27:45 2209154 dinov2 utils.py:141] Labels shape: (17563,)
I20240728 23:27:45 2209154 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240728 23:27:45 2209154 dinov2 loaders.py:155] sampler: distributed
I20240728 23:27:45 2209154 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:27:45 2209154 dinov2 loaders.py:227] # of batches: 18
I20240728 23:35:56 2209154 dinov2 knn.py:307] Start the k-NN classification.
I20240728 23:36:22 2215099 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240728 23:36:22 2215099 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240728 23:36:22 2215099 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240728 23:36:22 2215099 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240728 23:36:22 2215099 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240728 23:36:23 2215099 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240728 23:36:23 2215099 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240728 23:36:23 2215099 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:36:24 2215099 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:36:24 2215099 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240728 23:36:24 2215099 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240728 23:36:24 2215099 dinov2 knn.py:268] Extracting features for train set...
I20240728 23:36:24 2215099 dinov2 loaders.py:155] sampler: distributed
I20240728 23:36:24 2215099 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:36:24 2215099 dinov2 loaders.py:227] # of batches: 18
I20240728 23:37:04 2215099 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240728 23:37:04 2215099 dinov2 helpers.py:103]   [ 0/18]  eta: 0:12:07    time: 40.395138  data: 20.525536  max mem: 8979
I20240728 23:37:28 2215099 dinov2 helpers.py:103]   [10/18]  eta: 0:00:46    time: 5.856916  data: 1.866449  max mem: 9039
I20240728 23:38:08 2215099 dinov2 helpers.py:103]   [17/18]  eta: 0:00:05    time: 5.776144  data: 1.140700  max mem: 9039
I20240728 23:38:09 2215099 dinov2 helpers.py:132]  Total time: 0:01:45 (5.833465 s / it)
I20240728 23:38:09 2215099 dinov2 utils.py:140] Features shape: (17563, 768)
I20240728 23:38:09 2215099 dinov2 utils.py:141] Labels shape: (17563,)
I20240728 23:38:09 2215099 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240728 23:38:09 2215099 dinov2 loaders.py:155] sampler: distributed
I20240728 23:38:09 2215099 dinov2 loaders.py:214] using PyTorch data loader
I20240728 23:38:09 2215099 dinov2 loaders.py:227] # of batches: 18
I20240728 23:39:54 2215099 dinov2 knn.py:309] Start the k-NN classification.
I20240728 23:45:21 2215099 dinov2 helpers.py:103] Test:  [ 0/18]  eta: 1:37:14    time: 324.160339  data: 13.754548  max mem: 9039
I20240729 09:37:16 2360107 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 09:37:16 2360107 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 09:37:16 2360107 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0014142135623730952
I20240729 09:37:16 2360107 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0014142135623730952
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 09:43:22 2360107 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 09:50:48 2360107 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 09:50:48 2360107 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 09:50:48 2360107 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:50:48 2360107 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:50:48 2360107 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:50:48 2360107 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:50:48 2360107 dinov2 knn.py:268] Extracting features for train set...
I20240729 09:50:48 2360107 dinov2 loaders.py:155] sampler: distributed
I20240729 09:50:48 2360107 dinov2 loaders.py:214] using PyTorch data loader
I20240729 09:50:48 2360107 dinov2 loaders.py:227] # of batches: 18
I20240729 09:52:44 2367479 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 09:52:44 2367479 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 09:52:44 2367479 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 09:52:44 2367479 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 09:54:12 2367479 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 09:54:14 2367479 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 09:54:14 2367479 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 09:54:14 2367479 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:54:14 2367479 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:54:14 2367479 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:54:14 2367479 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:54:14 2367479 dinov2 knn.py:268] Extracting features for train set...
I20240729 09:54:14 2367479 dinov2 loaders.py:155] sampler: distributed
I20240729 09:54:14 2367479 dinov2 loaders.py:214] using PyTorch data loader
I20240729 09:54:14 2367479 dinov2 loaders.py:227] # of batches: 69
I20240729 09:54:32 2368519 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 09:54:32 2368519 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 09:54:32 2368519 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 09:54:32 2368519 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 09:54:33 2368519 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 09:54:34 2368519 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 09:54:34 2368519 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 09:54:34 2368519 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:54:34 2368519 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:54:34 2368519 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 09:54:34 2368519 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 09:54:34 2368519 dinov2 knn.py:268] Extracting features for train set...
I20240729 09:54:34 2368519 dinov2 loaders.py:155] sampler: distributed
I20240729 09:54:34 2368519 dinov2 loaders.py:214] using PyTorch data loader
I20240729 09:54:34 2368519 dinov2 loaders.py:227] # of batches: 69
I20240729 10:45:48 2368519 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240729 10:45:48 2368519 dinov2 helpers.py:103]   [ 0/69]  eta: 2 days, 10:54:49    time: 3073.762451  data: 15.496438  max mem: 10133
I20240729 10:46:14 2381052 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 10:46:14 2381052 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 10:46:14 2381052 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 10:46:14 2381052 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 10:49:10 2381052 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 10:49:11 2381052 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 10:49:11 2381052 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 10:49:33 2382321 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 10:49:33 2382321 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 10:49:33 2382321 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 10:49:33 2382321 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 11:05:00 2382321 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 11:05:02 2382321 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 11:10:03 2387984 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 11:10:03 2387984 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 11:10:03 2387984 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 11:10:03 2387984 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 11:10:03 2387984 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 11:10:05 2387984 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 11:10:05 2387984 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 11:10:05 2387984 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:10:05 2387984 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:10:05 2387984 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:10:05 2387984 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:10:05 2387984 dinov2 knn.py:268] Extracting features for train set...
I20240729 11:10:05 2387984 dinov2 loaders.py:155] sampler: distributed
I20240729 11:10:05 2387984 dinov2 loaders.py:214] using PyTorch data loader
I20240729 11:10:05 2387984 dinov2 loaders.py:227] # of batches: 69
I20240729 11:33:36 2387984 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240729 11:33:36 2387984 dinov2 helpers.py:103]   [ 0/69]  eta: 1 day, 3:02:11    time: 1410.603149  data: 15.905423  max mem: 9749
I20240729 11:33:52 2387984 dinov2 helpers.py:103]   [10/69]  eta: 2:07:30    time: 129.675522  data: 1.446362  max mem: 9749
I20240729 11:34:37 2394749 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 11:34:37 2394749 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 11:34:37 2394749 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 11:34:37 2394749 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 11:34:37 2394749 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 11:34:38 2394749 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 11:34:38 2394749 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 11:34:39 2394749 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:34:39 2394749 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:34:39 2394749 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:34:39 2394749 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:34:39 2394749 dinov2 knn.py:268] Extracting features for train set...
I20240729 11:34:39 2394749 dinov2 loaders.py:155] sampler: distributed
I20240729 11:34:39 2394749 dinov2 loaders.py:214] using PyTorch data loader
I20240729 11:34:39 2394749 dinov2 loaders.py:227] # of batches: 69
I20240729 11:38:53 2396477 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 11:38:53 2396477 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 11:38:53 2396477 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 11:38:53 2396477 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 11:38:53 2396477 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 11:38:55 2396477 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 11:38:55 2396477 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 11:38:55 2396477 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:38:55 2396477 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:38:55 2396477 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 11:38:56 2396477 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 11:38:56 2396477 dinov2 knn.py:268] Extracting features for train set...
I20240729 11:38:56 2396477 dinov2 loaders.py:155] sampler: distributed
I20240729 11:38:56 2396477 dinov2 loaders.py:214] using PyTorch data loader
I20240729 11:38:56 2396477 dinov2 loaders.py:227] # of batches: 69
I20240729 11:39:34 2396477 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240729 11:39:34 2396477 dinov2 helpers.py:103]   [ 0/69]  eta: 0:44:42    time: 38.881519  data: 15.815016  max mem: 8979
I20240729 11:39:51 2396477 dinov2 helpers.py:103]   [10/69]  eta: 0:04:55    time: 5.010353  data: 1.438202  max mem: 9036
I20240729 11:40:19 2396477 dinov2 helpers.py:103]   [20/69]  eta: 0:03:14    time: 2.220355  data: 0.002644  max mem: 9036
I20240729 11:40:47 2396477 dinov2 helpers.py:103]   [30/69]  eta: 0:02:20    time: 2.812311  data: 0.002689  max mem: 9036
I20240729 11:41:15 2396477 dinov2 helpers.py:103]   [40/69]  eta: 0:01:38    time: 2.810098  data: 0.000571  max mem: 9036
I20240729 11:41:43 2396477 dinov2 helpers.py:103]   [50/69]  eta: 0:01:02    time: 2.819443  data: 0.000546  max mem: 9036
I20240729 11:42:12 2396477 dinov2 helpers.py:103]   [60/69]  eta: 0:00:28    time: 2.839478  data: 0.000545  max mem: 9036
I20240729 11:42:49 2396477 dinov2 helpers.py:103]   [68/69]  eta: 0:00:03    time: 3.571013  data: 0.000406  max mem: 9036
I20240729 11:42:50 2396477 dinov2 helpers.py:132]  Total time: 0:03:54 (3.398258 s / it)
I20240729 11:42:50 2396477 dinov2 utils.py:140] Features shape: (17563, 768)
I20240729 11:42:50 2396477 dinov2 utils.py:141] Labels shape: (17563,)
I20240729 11:42:51 2396477 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240729 11:42:51 2396477 dinov2 loaders.py:155] sampler: distributed
I20240729 11:42:51 2396477 dinov2 loaders.py:214] using PyTorch data loader
I20240729 11:42:51 2396477 dinov2 loaders.py:227] # of batches: 69
I20240729 12:17:28 2396477 dinov2 knn.py:309] Start the k-NN classification.
I20240729 12:18:14 2407885 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240729 12:18:14 2407885 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240729 12:18:14 2407885 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240729 12:18:14 2407885 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240729 12:18:14 2407885 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240729 12:18:15 2407885 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240729 12:18:15 2407885 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240729 12:18:15 2407885 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 12:18:16 2407885 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 12:18:16 2407885 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240729 12:18:16 2407885 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240729 12:18:16 2407885 dinov2 knn.py:268] Extracting features for train set...
I20240729 12:18:16 2407885 dinov2 loaders.py:155] sampler: distributed
I20240729 12:18:16 2407885 dinov2 loaders.py:214] using PyTorch data loader
I20240729 12:18:16 2407885 dinov2 loaders.py:227] # of batches: 69
I20240729 12:18:53 2407885 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240729 12:18:53 2407885 dinov2 helpers.py:103]   [ 0/69]  eta: 0:42:35    time: 37.039349  data: 15.475526  max mem: 8979
I20240729 12:19:09 2407885 dinov2 helpers.py:103]   [10/69]  eta: 0:04:45    time: 4.845757  data: 1.407269  max mem: 9036
I20240729 12:19:37 2407885 dinov2 helpers.py:103]   [20/69]  eta: 0:03:09    time: 2.218267  data: 0.000520  max mem: 9036
I20240729 12:20:05 2407885 dinov2 helpers.py:103]   [30/69]  eta: 0:02:17    time: 2.800420  data: 0.000541  max mem: 9036
I20240729 12:20:33 2407885 dinov2 helpers.py:103]   [40/69]  eta: 0:01:36    time: 2.780753  data: 0.000513  max mem: 9036
I20240729 12:21:00 2407885 dinov2 helpers.py:103]   [50/69]  eta: 0:01:01    time: 2.773145  data: 0.000559  max mem: 9036
I20240729 12:21:28 2407885 dinov2 helpers.py:103]   [60/69]  eta: 0:00:28    time: 2.779914  data: 0.000515  max mem: 9036
I20240729 12:22:05 2407885 dinov2 helpers.py:103]   [68/69]  eta: 0:00:03    time: 3.518933  data: 0.000375  max mem: 9036
I20240729 12:22:06 2407885 dinov2 helpers.py:132]  Total time: 0:03:50 (3.342226 s / it)
I20240729 12:22:06 2407885 dinov2 utils.py:140] Features shape: (17563, 768)
I20240729 12:22:06 2407885 dinov2 utils.py:141] Labels shape: (17563,)
I20240729 12:22:07 2407885 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240729 12:22:07 2407885 dinov2 loaders.py:155] sampler: distributed
I20240729 12:22:07 2407885 dinov2 loaders.py:214] using PyTorch data loader
I20240729 12:22:07 2407885 dinov2 loaders.py:227] # of batches: 69
I20240729 12:22:07 2407885 dinov2 knn.py:309] Start the k-NN classification.
I20240729 12:22:23 2407885 dinov2 helpers.py:103] Test:  [ 0/69]  eta: 0:18:44    time: 16.297354  data: 13.492923  max mem: 9036
I20240729 12:22:52 2407885 dinov2 helpers.py:103] Test:  [10/69]  eta: 0:04:00    time: 4.072662  data: 1.254089  max mem: 9036
I20240729 12:23:20 2407885 dinov2 helpers.py:103] Test:  [20/69]  eta: 0:02:50    time: 2.832685  data: 0.015300  max mem: 9036
I20240729 12:23:48 2407885 dinov2 helpers.py:103] Test:  [30/69]  eta: 0:02:07    time: 2.814165  data: 0.000429  max mem: 9036
I20240729 12:24:16 2407885 dinov2 helpers.py:103] Test:  [40/69]  eta: 0:01:31    time: 2.817919  data: 0.000508  max mem: 9036
I20240729 12:24:44 2407885 dinov2 helpers.py:103] Test:  [50/69]  eta: 0:00:58    time: 2.820085  data: 0.000568  max mem: 9036
I20240729 12:25:13 2407885 dinov2 helpers.py:103] Test:  [60/69]  eta: 0:00:27    time: 2.820485  data: 0.000546  max mem: 9036
I20240729 12:25:34 2407885 dinov2 helpers.py:103] Test:  [68/69]  eta: 0:00:03    time: 2.763660  data: 0.000394  max mem: 9036
I20240729 12:25:34 2407885 dinov2 helpers.py:132] Test: Total time: 0:03:27 (3.001827 s / it)
I20240729 12:25:34 2407885 dinov2 utils.py:79] Averaged stats: 
I20240729 12:25:35 2407885 dinov2 knn.py:377] ('full', 10) classifier result: Top1: 99.80 Top5: 100.00
I20240729 12:25:35 2407885 dinov2 knn.py:377] ('full', 20) classifier result: Top1: 99.68 Top5: 100.00
I20240729 12:25:35 2407885 dinov2 knn.py:377] ('full', 100) classifier result: Top1: 99.53 Top5: 100.00
I20240729 12:25:35 2407885 dinov2 knn.py:377] ('full', 200) classifier result: Top1: 99.52 Top5: 100.00
I20240730 15:41:14 2789766 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240730 15:41:14 2789766 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240730 15:41:14 2789766 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240730 15:41:14 2789766 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240730 15:41:14 2789766 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240730 15:41:15 2789766 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240730 15:41:15 2789766 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240730 15:41:15 2789766 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 15:41:16 2789766 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 15:41:16 2789766 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 15:41:16 2789766 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 15:41:16 2789766 dinov2 knn.py:268] Extracting features for train set...
I20240730 15:41:16 2789766 dinov2 loaders.py:155] sampler: distributed
I20240730 15:41:16 2789766 dinov2 loaders.py:214] using PyTorch data loader
I20240730 15:41:16 2789766 dinov2 loaders.py:227] # of batches: 69
I20240730 15:41:42 2789766 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240730 15:41:42 2789766 dinov2 helpers.py:103]   [ 0/69]  eta: 0:30:05    time: 26.159977  data: 15.380095  max mem: 8979
I20240730 15:41:57 2789766 dinov2 helpers.py:103]   [10/69]  eta: 0:03:40    time: 3.744872  data: 2.558244  max mem: 9036
I20240730 15:42:23 2789766 dinov2 helpers.py:103]   [20/69]  eta: 0:02:36    time: 2.051785  data: 1.923340  max mem: 9036
I20240730 15:42:48 2789766 dinov2 helpers.py:103]   [30/69]  eta: 0:01:56    time: 2.569160  data: 2.540613  max mem: 9036
I20240730 15:43:17 2789766 dinov2 helpers.py:103]   [40/69]  eta: 0:01:25    time: 2.692398  data: 2.660908  max mem: 9036
I20240730 15:43:43 2789766 dinov2 helpers.py:103]   [50/69]  eta: 0:00:54    time: 2.722512  data: 2.695165  max mem: 9036
I20240730 15:44:10 2789766 dinov2 helpers.py:103]   [60/69]  eta: 0:00:25    time: 2.664620  data: 2.645383  max mem: 9036
I20240730 15:44:32 2789766 dinov2 helpers.py:103]   [68/69]  eta: 0:00:02    time: 3.013911  data: 2.840259  max mem: 9036
I20240730 15:44:33 2789766 dinov2 helpers.py:132]  Total time: 0:03:17 (2.867225 s / it)
I20240730 15:44:33 2789766 dinov2 utils.py:140] Features shape: (17563, 768)
I20240730 15:44:33 2789766 dinov2 utils.py:141] Labels shape: (17563,)
I20240730 15:44:33 2789766 dinov2 knn.py:272] Train features created, shape torch.Size([17563, 768]).
I20240730 15:44:33 2789766 dinov2 loaders.py:155] sampler: distributed
I20240730 15:44:33 2789766 dinov2 loaders.py:214] using PyTorch data loader
I20240730 15:44:33 2789766 dinov2 loaders.py:227] # of batches: 69
I20240730 15:44:34 2789766 dinov2 knn.py:309] Start the k-NN classification.
I20240730 15:44:49 2789766 dinov2 helpers.py:103] Test:  [ 0/69]  eta: 0:17:35    time: 15.295529  data: 13.748194  max mem: 9036
I20240730 15:47:22 2792869 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240730 15:47:22 2792869 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240730 15:47:22 2792869 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240730 15:47:22 2792869 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240730 15:47:22 2792869 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240730 15:47:23 2792869 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240730 15:47:23 2792869 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240730 15:47:23 2792869 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 15:47:23 2792869 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 15:47:23 2792869 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 15:47:23 2792869 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 15:47:23 2792869 dinov2 knn.py:268] Extracting features for train set...
I20240730 15:47:23 2792869 dinov2 loaders.py:155] sampler: distributed
I20240730 15:47:23 2792869 dinov2 loaders.py:214] using PyTorch data loader
I20240730 15:47:23 2792869 dinov2 loaders.py:227] # of batches: 69
I20240730 16:47:33 2792869 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240730 16:47:33 2792869 dinov2 helpers.py:103]   [ 0/69]  eta: 2 days, 21:11:02    time: 3609.601074  data: 15.364176  max mem: 8979
I20240730 16:50:32 2808280 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240730 16:50:32 2808280 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240730 16:50:32 2808280 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240730 16:50:32 2808280 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240730 16:50:32 2808280 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240730 16:50:34 2808280 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240730 16:50:34 2808280 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240730 16:50:34 2808280 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 16:50:34 2808280 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 16:50:34 2808280 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240730 16:50:34 2808280 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240730 16:50:34 2808280 dinov2 knn.py:268] Extracting features for train set...
I20240730 16:50:34 2808280 dinov2 loaders.py:155] sampler: distributed
I20240730 16:50:34 2808280 dinov2 loaders.py:214] using PyTorch data loader
I20240730 16:50:34 2808280 dinov2 loaders.py:227] # of batches: 69
I20240730 17:17:43 2808280 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([17563, 768])
I20240730 17:17:43 2808280 dinov2 helpers.py:103]   [ 0/69]  eta: 1 day, 7:12:53    time: 1628.594849  data: 15.457943  max mem: 26586
I20240802 12:13:28 2713472 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240802 12:13:28 2713472 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
I20240802 12:13:28 2713472 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240802 12:13:28 2713472 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240802 12:13:34 2713472 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240802 12:13:36 2713472 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240802 12:13:36 2713472 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240802 12:15:46 2714751 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240802 12:15:46 2714751 dinov2 config.py:60] config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
I20240802 12:15:46 2714751 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240802 12:15:46 2714751 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240802 12:15:46 2714751 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240802 12:15:48 2714751 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240802 12:15:48 2714751 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240802 12:15:48 2714751 root load_pretrained_model.py:15] Success!
I20240803 16:24:02 3455862 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240803 16:24:02 3455862 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 0
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: SengmentationSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: SengmentationSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/:extra=/NAS6/Members/linchenxi/ILSVRC
I20240803 16:24:02 3455862 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240803 16:24:02 3455862 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240803 16:24:02 3455862 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240803 16:24:04 3455862 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240803 16:24:04 3455862 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
