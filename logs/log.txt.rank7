I20240613 14:33:54 3867792 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240613 14:33:54 3867792 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: dinov2/configs/eval/vits14_pretrain.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
local_rank: 7
no_resume: False
num_workers: 8
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_class_mapping_fpath: None
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_metric_type: mean_accuracy
I20240613 14:33:54 3867792 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0028284271247461905
I20240614 10:11:53 43743 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240614 10:11:53 43743 dinov2 config.py:60] batch_size: 256
config_file: dinov2/configs/eval/vits14_pretrain.yaml
gather_on_cpu: False
local_rank: 7
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth
temperature: 0.07
train_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC
I20240614 10:11:53 43743 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0028284271247461905
I20240614 10:11:53 43743 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: ImageNet:split=TRAIN
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 14
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0028284271247461905
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 518
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500

I20240614 10:11:53 43743 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240614 10:11:54 43743 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/dinov2/pretrained_models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>
I20240614 10:11:54 43743 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:11:54 43743 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:11:54 43743 dinov2 loaders.py:84] using dataset: "ImageNet:split=TRAIN:root=/NAS6/Members/linchenxi/ILSVRC:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240614 10:11:54 43743 dinov2 loaders.py:89] # of dataset samples: 1,281,167
I20240614 10:11:54 43743 dinov2 knn.py:262] Extracting features for train set...
I20240614 10:11:54 43743 dinov2 loaders.py:147] sampler: distributed
I20240614 10:11:54 43743 dinov2 loaders.py:206] using PyTorch data loader
I20240614 10:11:54 43743 dinov2 loaders.py:219] # of batches: 626
I20240614 10:12:00 43743 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([1281167, 384])
I20240614 10:12:00 43743 dinov2 helpers.py:102]   [  0/626]  eta: 1:05:57    time: 6.321832  data: 4.849707  max mem: 2178
I20240614 10:12:24 43743 dinov2 helpers.py:102]   [ 10/626]  eta: 0:27:59    time: 2.725787  data: 2.570659  max mem: 2850
I20240614 10:12:30 43743 dinov2 helpers.py:102]   [ 20/626]  eta: 0:17:17    time: 1.481031  data: 1.455251  max mem: 2850
I20240614 10:12:35 43743 dinov2 helpers.py:102]   [ 30/626]  eta: 0:13:21    time: 0.584582  data: 0.555188  max mem: 2850
I20240614 10:12:41 43743 dinov2 helpers.py:102]   [ 40/626]  eta: 0:11:21    time: 0.588694  data: 0.560401  max mem: 2850
I20240614 10:12:46 43743 dinov2 helpers.py:102]   [ 50/626]  eta: 0:09:56    time: 0.558738  data: 0.533633  max mem: 2850
I20240614 10:12:52 43743 dinov2 helpers.py:102]   [ 60/626]  eta: 0:09:02    time: 0.535920  data: 0.513677  max mem: 2850
I20240614 10:12:58 43743 dinov2 helpers.py:102]   [ 70/626]  eta: 0:08:21    time: 0.557972  data: 0.536160  max mem: 2850
I20240614 10:13:03 43743 dinov2 helpers.py:102]   [ 80/626]  eta: 0:07:47    time: 0.545815  data: 0.521695  max mem: 2850
I20240614 10:13:09 43743 dinov2 helpers.py:102]   [ 90/626]  eta: 0:07:23    time: 0.563310  data: 0.538361  max mem: 2850
I20240614 10:13:13 43743 dinov2 helpers.py:102]   [100/626]  eta: 0:06:55    time: 0.520591  data: 0.495212  max mem: 2850
I20240614 10:13:18 43743 dinov2 helpers.py:102]   [110/626]  eta: 0:06:33    time: 0.472616  data: 0.436805  max mem: 2850
I20240614 10:13:23 43743 dinov2 helpers.py:102]   [120/626]  eta: 0:06:14    time: 0.495457  data: 0.451126  max mem: 2850
I20240614 10:13:29 43743 dinov2 helpers.py:102]   [130/626]  eta: 0:06:01    time: 0.532728  data: 0.498683  max mem: 2850
I20240614 10:13:35 43743 dinov2 helpers.py:102]   [140/626]  eta: 0:05:47    time: 0.564084  data: 0.538006  max mem: 2850
I20240614 10:13:40 43743 dinov2 helpers.py:102]   [150/626]  eta: 0:05:34    time: 0.537887  data: 0.512607  max mem: 2850
I20240614 10:13:45 43743 dinov2 helpers.py:102]   [160/626]  eta: 0:05:23    time: 0.533743  data: 0.509062  max mem: 2850
I20240614 10:13:51 43743 dinov2 helpers.py:102]   [170/626]  eta: 0:05:13    time: 0.566041  data: 0.538788  max mem: 2850
I20240614 10:13:56 43743 dinov2 helpers.py:102]   [180/626]  eta: 0:05:01    time: 0.536059  data: 0.506853  max mem: 2850
I20240614 10:14:02 43743 dinov2 helpers.py:102]   [190/626]  eta: 0:04:54    time: 0.568000  data: 0.539076  max mem: 2850
I20240614 10:14:09 43743 dinov2 helpers.py:102]   [200/626]  eta: 0:04:46    time: 0.647290  data: 0.620185  max mem: 2850
I20240614 10:14:15 43743 dinov2 helpers.py:102]   [210/626]  eta: 0:04:37    time: 0.604250  data: 0.580506  max mem: 2850
I20240614 10:14:20 43743 dinov2 helpers.py:102]   [220/626]  eta: 0:04:29    time: 0.578157  data: 0.555640  max mem: 2850
I20240614 10:14:26 43743 dinov2 helpers.py:102]   [230/626]  eta: 0:04:21    time: 0.577842  data: 0.552486  max mem: 2850
I20240614 10:14:32 43743 dinov2 helpers.py:102]   [240/626]  eta: 0:04:13    time: 0.560438  data: 0.536504  max mem: 2850
I20240614 10:14:38 43743 dinov2 helpers.py:102]   [250/626]  eta: 0:04:06    time: 0.595883  data: 0.575320  max mem: 2850
I20240614 10:14:44 43743 dinov2 helpers.py:102]   [260/626]  eta: 0:03:58    time: 0.604966  data: 0.581596  max mem: 2850
I20240614 10:14:50 43743 dinov2 helpers.py:102]   [270/626]  eta: 0:03:51    time: 0.590763  data: 0.563661  max mem: 2850
I20240614 10:14:55 43743 dinov2 helpers.py:102]   [280/626]  eta: 0:03:43    time: 0.563202  data: 0.537476  max mem: 2850
I20240614 10:15:01 43743 dinov2 helpers.py:102]   [290/626]  eta: 0:03:36    time: 0.547350  data: 0.523735  max mem: 2850
I20240614 10:15:06 43743 dinov2 helpers.py:102]   [300/626]  eta: 0:03:28    time: 0.558071  data: 0.534031  max mem: 2850
I20240614 10:15:12 43743 dinov2 helpers.py:102]   [310/626]  eta: 0:03:21    time: 0.539111  data: 0.517318  max mem: 2850
I20240614 10:15:17 43743 dinov2 helpers.py:102]   [320/626]  eta: 0:03:14    time: 0.555195  data: 0.525438  max mem: 2850
I20240614 10:15:23 43743 dinov2 helpers.py:102]   [330/626]  eta: 0:03:07    time: 0.593016  data: 0.549379  max mem: 2850
I20240614 10:15:30 43743 dinov2 helpers.py:102]   [340/626]  eta: 0:03:01    time: 0.616150  data: 0.579926  max mem: 2850
I20240614 10:15:35 43743 dinov2 helpers.py:102]   [350/626]  eta: 0:02:54    time: 0.596645  data: 0.571168  max mem: 2850
I20240614 10:15:42 43743 dinov2 helpers.py:102]   [360/626]  eta: 0:02:48    time: 0.603071  data: 0.579829  max mem: 2850
I20240614 10:15:47 43743 dinov2 helpers.py:102]   [370/626]  eta: 0:02:40    time: 0.577164  data: 0.553708  max mem: 2850
I20240614 10:15:53 43743 dinov2 helpers.py:102]   [380/626]  eta: 0:02:34    time: 0.548864  data: 0.523920  max mem: 2850
I20240614 10:15:59 43743 dinov2 helpers.py:102]   [390/626]  eta: 0:02:27    time: 0.593760  data: 0.568802  max mem: 2850
I20240614 10:16:05 43743 dinov2 helpers.py:102]   [400/626]  eta: 0:02:21    time: 0.602587  data: 0.576364  max mem: 2850
I20240614 10:16:11 43743 dinov2 helpers.py:102]   [410/626]  eta: 0:02:15    time: 0.620288  data: 0.596312  max mem: 2850
I20240614 10:16:18 43743 dinov2 helpers.py:102]   [420/626]  eta: 0:02:09    time: 0.650035  data: 0.626846  max mem: 2850
I20240614 10:16:23 43743 dinov2 helpers.py:102]   [430/626]  eta: 0:02:02    time: 0.612004  data: 0.589159  max mem: 2850
I20240614 10:16:30 43743 dinov2 helpers.py:102]   [440/626]  eta: 0:01:56    time: 0.591214  data: 0.568941  max mem: 2850
I20240614 10:16:36 43743 dinov2 helpers.py:102]   [450/626]  eta: 0:01:50    time: 0.612096  data: 0.590555  max mem: 2850
I20240614 10:16:42 43743 dinov2 helpers.py:102]   [460/626]  eta: 0:01:43    time: 0.617368  data: 0.595969  max mem: 2850
I20240614 10:16:48 43743 dinov2 helpers.py:102]   [470/626]  eta: 0:01:37    time: 0.618546  data: 0.595065  max mem: 2850
I20240614 10:16:53 43743 dinov2 helpers.py:102]   [480/626]  eta: 0:01:30    time: 0.567668  data: 0.542901  max mem: 2850
I20240614 10:16:59 43743 dinov2 helpers.py:102]   [490/626]  eta: 0:01:24    time: 0.557391  data: 0.530351  max mem: 2850
I20240614 10:17:05 43743 dinov2 helpers.py:102]   [500/626]  eta: 0:01:18    time: 0.582347  data: 0.554628  max mem: 2850
I20240614 10:17:11 43743 dinov2 helpers.py:102]   [510/626]  eta: 0:01:11    time: 0.570431  data: 0.543755  max mem: 2850
I20240723 23:31:35 3558509 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240723 23:31:35 3558509 dinov2 config.py:60] batch_size: 256
config_file: /NAS6/Members/linchenxi/projects/DINOV2/model8/config.yaml
gather_on_cpu: False
local_rank: 7
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/NAS6/Members/linchenxi/dinov2']
output_dir: /NAS6/Members/linchenxi/dinov2
pretrained_weights: /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
val_dataset_str: ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC
I20240723 23:31:35 3558509 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.002
I20240723 23:31:35 3558509 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.3
  mask_ratio_min_max:
  - 0.1
  - 0.3
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: Sentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas:extra=/NAS6/Members/linchenxi/ILSVRC
  output_dir: /NAS6/Members/linchenxi/dinov2
  saveckp_freq: 20
  seed: 0
  num_workers: 5
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_base
  patch_size: 16
  in_chans: 9
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 2
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.002
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 368
  local_crops_size: 192
evaluation:
  eval_period_iterations: 12500

I20240723 23:31:35 3558509 dinov2 vision_transformer.py:126] using MLP layer as FFN
I20240723 23:31:37 3558509 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20240723 23:31:37 3558509 dinov2 utils.py:33] Pretrained weights found at /NAS6/Members/linchenxi/projects/DINOV2/model8/eval/training_24999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20240723 23:31:37 3558509 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TRAIN:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:31:39 3558509 dinov2 loaders.py:97] # of dataset samples: 164,544
I20240723 23:31:39 3558509 dinov2 loaders.py:92] using dataset: "ClusterSentinel2:split=TEST:root=/NAS6/Members/linchenxi/projects/RS_foundation_model/satlas/clusters:extra=/NAS6/Members/linchenxi/ILSVRC"
I20240723 23:31:39 3558509 dinov2 loaders.py:97] # of dataset samples: 17,563
I20240723 23:31:39 3558509 dinov2 knn.py:262] Extracting features for train set...
I20240723 23:31:39 3558509 dinov2 loaders.py:155] sampler: distributed
I20240723 23:31:39 3558509 dinov2 loaders.py:214] using PyTorch data loader
I20240723 23:31:39 3558509 dinov2 loaders.py:227] # of batches: 81
W20240723 23:32:01 3559261 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:06 3559418 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:08 3559634 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:09 3559722 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

W20240723 23:32:10 3559725 py.warnings warnings.py:109] /NAS6/Members/linchenxi/dinov2/dinov2_venv/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.
  warnings.warn(

